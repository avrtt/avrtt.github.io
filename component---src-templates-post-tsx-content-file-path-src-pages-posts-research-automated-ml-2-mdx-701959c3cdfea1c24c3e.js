"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[7899],{2394:function(e,t,a){a.r(t),a.d(t,{Head:function(){return M},PostTemplate:function(){return _},default:function(){return z}});var n=a(28453),i=a(96540),r=(a(61992),a(62087)),l=a(90548);function o(e){const t=Object.assign({p:"p",hr:"hr",h2:"h2",a:"a",span:"span",h3:"h3",ol:"ol",li:"li",strong:"strong",ul:"ul"},(0,n.RP)(),e.components),{Image:a}=t;return a||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),i.createElement(i.Fragment,null,"\n",i.createElement("br"),"\n",i.createElement(t.p,null,"In this second installment of our deep dive into automated machine learning, I will explore more advanced topics and concepts that build upon the foundations introduced in the previous article. While the first part focused on the full automl workflow — spanning automated data preparation, feature engineering, model selection, hyperparameter optimization, pipeline construction, and other essential dimensions — this deeper discussion will shed light on meta-learning, neural architecture search, state-of-the-art methodologies in hyperparameter tuning, key frameworks and libraries, as well as emerging challenges and possible future trajectories. I will also include various mathematical formulations, code snippets, and detailed conceptual diagrams to ensure that you have a well-rounded understanding of these advanced automl strategies. Throughout, I will blend references to cutting-edge research and real-world examples to substantiate the theoretical constructs."),"\n",i.createElement(t.p,null,"Though these topics can be quite intricate, I intend to maintain an approachable tone. My goal is for you to perceive the interplay between the subfields that power automl systems, grasp their theoretical underpinnings, and recognize their practical implications in industry and research contexts. By the end of this article, you should be able to appreciate how such advanced automl methods can drastically reduce the complexities of building effective machine learning solutions, even in high-dimensional, multimodal, or rapidly evolving contexts."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"meta-learning-in-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#meta-learning-in-automl","aria-label":"meta learning in automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Meta-learning in automl"),"\n",i.createElement(t.h3,{id:"conceptual-overview-of-meta-learning",style:{position:"relative"}},i.createElement(t.a,{href:"#conceptual-overview-of-meta-learning","aria-label":"conceptual overview of meta learning permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Conceptual overview of meta-learning"),"\n",i.createElement(t.p,null,'Meta-learning, often described as "learning to learn," is a technique in which an algorithm leverages knowledge acquired from previous learning tasks to accelerate learning on new tasks. In the context of automl, meta-learning plays a crucial role by enabling systems to transfer insights gained from historical data sets and model configurations. The fundamental idea revolves around constructing a higher-level model (the meta-learner) that observes many base-level learning processes (e.g., training different classification or regression models) and captures patterns about which hyperparameters, architectures, or preprocessing routines work well for specific types of tasks and data distributions.'),"\n",i.createElement(t.p,null,'Because automl systems typically explore vast spaces of algorithm and hyperparameter configurations, any shortcut that enables "intelligent" search can be extremely valuable. Meta-learning is thus poised to reduce the search time and computational resources required by automl, since the meta-learner can reduce the need for brute-force approaches. Instead, it provides informed guesses about promising areas of the solution space.'),"\n",i.createElement(t.h3,{id:"how-meta-learning-benefits-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#how-meta-learning-benefits-automl","aria-label":"how meta learning benefits automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"How meta-learning benefits automl"),"\n",i.createElement(t.p,null,"From a practical perspective, meta-learning benefits automl pipelines in several ways:"),"\n",i.createElement(t.ol,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Faster convergence"),": Rather than starting every training procedure from scratch, meta-learning reuses knowledge gleaned from prior tasks, leading to significant speed-ups in certain scenarios."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Improved generalization"),': Because meta-learning algorithms have effectively "seen" similar problems before, they can discover hyperparameters and architectures with robust generalization properties for tasks in related domains.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Reduction in search space"),": By preemptively ruling out unproductive algorithmic configurations, meta-learning can limit the exploration space for subsequent tasks, making the automl process more efficient."),"\n"),"\n",i.createElement(t.p,null,"Systems like auto-sklearn (Feurer and gang, JMLR 2019) were among the first frameworks to incorporate meta-learning. The approach typically involves using data set meta-features (like the number of features, number of instances, class distribution statistics, etc.) to guess which combination of algorithms and hyperparameters might be successful."),"\n",i.createElement(t.h3,{id:"few-shot-learning-and-rapid-adaptation",style:{position:"relative"}},i.createElement(t.a,{href:"#few-shot-learning-and-rapid-adaptation","aria-label":"few shot learning and rapid adaptation permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Few-shot learning and rapid adaptation"),"\n",i.createElement(t.p,null,"In tasks where data is scarce, meta-learning can help automl frameworks perform few-shot or even one-shot learning. Such capabilities are often seen in advanced frameworks that rely on prototypes or optimization-based meta-learning (e.g., MAML — Model-Agnostic Meta-Learning). The ability to run a partial search on limited data has compelling applications in industries where data collection is slow or expensive (such as healthcare or specialized manufacturing)."),"\n",i.createElement(t.h3,{id:"a-simplified-mathematical-formulation",style:{position:"relative"}},i.createElement(t.a,{href:"#a-simplified-mathematical-formulation","aria-label":"a simplified mathematical formulation permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"A simplified mathematical formulation"),"\n",i.createElement(t.p,null,"An automl system harnessing meta-learning might do the following: let ",i.createElement(l.A,{text:"\\( \\theta_{m} \\)"})," be the parameters of the meta-learner. Over a set of historical tasks ",i.createElement(l.A,{text:"\\( \\{ \\mathcal{T}_i \\}_{i=1}^N \\)"}),", each with data ",i.createElement(l.A,{text:"\\( \\mathcal{D}_i \\)"})," and labels ",i.createElement(l.A,{text:"\\( \\mathcal{Y}_i \\)"}),", the meta-learner identifies patterns of best hyperparameters or model configurations ",i.createElement(l.A,{text:"\\( \\eta_i \\)"}),". The objective might be something like:"),"\n",i.createElement(l.A,{text:"\\[\n\\theta_{m}^* = \\underset{\\theta_{m}}{\\mathrm{argmin}} \\sum_{i=1}^N \\mathcal{L}\\big(f(\\mathcal{X}_i, \\eta_i; \\theta_{m}), \\mathcal{Y}_i\\big)\n\\]"}),"\n",i.createElement(t.p,null,"where ",i.createElement(l.A,{text:"\\( f \\)"})," is the meta-learning function that, conditioned on ",i.createElement(l.A,{text:"\\( \\theta_m \\)"}),", predicts or refines the best hyperparameters ",i.createElement(l.A,{text:"\\( \\eta_i \\)"})," for task ",i.createElement(l.A,{text:"\\( \\mathcal{T}_i \\)"}),". Once ",i.createElement(l.A,{text:"\\( \\theta_{m} \\)"})," is learned, each new task ",i.createElement(l.A,{text:"\\( \\mathcal{T}_{new} \\)"})," can quickly be addressed by producing a strong initialization or by directly proposing the best hyperparameters. This is, of course, a highly abstracted view, but it conveys the conceptual essence."),"\n",i.createElement(t.p,null,"The variables:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\theta_m \\)"}),': Parameters of the meta-learner (e.g., the "brain" that suggests or refines configurations).'),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\eta_i \\)"}),": The hyperparameters or model configurations that are used at the base level for each task."),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathcal{L} \\)"}),": A loss function measuring performance (lower is better)."),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( f \\)"}),": A function that maps from task data + meta-learner parameters to model hyperparameters or configurations."),"\n"),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"advanced-hyperparameter-optimization",style:{position:"relative"}},i.createElement(t.a,{href:"#advanced-hyperparameter-optimization","aria-label":"advanced hyperparameter optimization permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Advanced hyperparameter optimization"),"\n",i.createElement(t.h3,{id:"revisiting-the-role-of-hpo-in-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#revisiting-the-role-of-hpo-in-automl","aria-label":"revisiting the role of hpo in automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Revisiting the role of hpo in automl"),"\n",i.createElement(t.p,null,"Hyperparameter optimization (hpo) is the process of finding a hyperparameter configuration that yields the best performance for a given machine learning model on a specific data set. Automl frameworks typically incorporate hpo as a core mechanism, because suboptimal hyperparameters routinely lead to suboptimal performance. Traditional approaches rely on grid or random search, but these can be inefficient for high-dimensional problems or complex model families."),"\n",i.createElement(t.h3,{id:"bayesian-optimization-for-complex-search-spaces",style:{position:"relative"}},i.createElement(t.a,{href:"#bayesian-optimization-for-complex-search-spaces","aria-label":"bayesian optimization for complex search spaces permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Bayesian optimization for complex search spaces"),"\n",i.createElement(t.p,null,"A widely adopted strategy in advanced automl systems is bayesian optimization (Snoek and gang, ICML 2012). The idea is to build a probabilistic surrogate model — typically a Gaussian process (gp) or a tree-based model — that approximates the relationship between hyperparameter settings and validation performance. By iteratively updating this surrogate as new hyperparameters are evaluated, it becomes possible to target the regions of hyperparameter space that are most promising."),"\n",i.createElement(t.p,null,"To illustrate, let ",i.createElement(l.A,{text:"\\( \\mathbf{x} \\)"})," represent a hyperparameter configuration (e.g., learning rate, regularization strength, or tree depth), and ",i.createElement(l.A,{text:"\\( y \\)"})," represent the validation performance. In bo, we learn a model (often denoted ",i.createElement(l.A,{text:"\\( m(\\mathbf{x}) \\)"}),"), that approximates ",i.createElement(l.A,{text:"\\( y \\)"}),". The next hyperparameter set to evaluate is chosen by an acquisition function ",i.createElement(l.A,{text:"\\( \\alpha(\\mathbf{x}; m) \\)"}),", which balances exploration (trying uncertain hyperparameter regions) with exploitation (focusing on promising areas)."),"\n",i.createElement(l.A,{text:"\\[\n\\mathbf{x}_{n+1} = \\underset{\\mathbf{x}}{\\mathrm{argmax}} \\; \\alpha(\\mathbf{x}; m)\n\\]"}),"\n",i.createElement(t.p,null,"where:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathbf{x}_{n+1} \\)"})," is the hyperparameter set to try next,"),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\alpha \\)"})," is an acquisition function such as expected improvement or upper confidence bound,"),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( m \\)"})," is the surrogate model (GP, random forest, etc.)."),"\n"),"\n",i.createElement(t.p,null,"This iterative framework continues until a stopping criterion is reached (e.g., time budget or convergence)."),"\n",i.createElement(t.h3,{id:"multi-fidelity-and-multi-objective-optimization",style:{position:"relative"}},i.createElement(t.a,{href:"#multi-fidelity-and-multi-objective-optimization","aria-label":"multi fidelity and multi objective optimization permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Multi-fidelity and multi-objective optimization"),"\n",i.createElement(t.p,null,"Many automl systems face scenarios where evaluating a single hyperparameter configuration can be extremely time-consuming (think of training a large neural network on a massive data set). Multi-fidelity approaches (e.g., Hyperband, BOHB) attempt to address this by training models on progressively larger subsets of data or for fewer epochs initially, pruning poor configurations early. This way, resources are allocated more efficiently to configurations that show greater potential."),"\n",i.createElement(t.p,null,"Additionally, real-world problems may impose multiple objectives (e.g., optimizing for accuracy and inference speed simultaneously). In these multi-objective contexts, automl frameworks use specialized search methods that find Pareto-optimal solutions, which represent configurations that cannot be improved on any one objective without sacrificing performance on another."),"\n",i.createElement(t.h3,{id:"sample-code-for-bayesian-optimization",style:{position:"relative"}},i.createElement(t.a,{href:"#sample-code-for-bayesian-optimization","aria-label":"sample code for bayesian optimization permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Sample code for bayesian optimization"),"\n",i.createElement(t.p,null,"Below is a simplified Python snippet using a hypothetical bayesian optimization library for automl:"),"\n",i.createElement(r.A,{text:'\nimport numpy as np\nfrom hypothetical_bo_library import BayesianOptimizer, GPModel, ExpectedImprovement\n\n# Suppose we have a function that trains a model with hyperparameters x\n# and returns validation performance\ndef training_function(x):\n    # x is a dictionary or array of hyperparameters\n    # In practice, this function would train a model and return the performance\n    performance = complex_model_training_and_evaluation(x)\n    return performance\n\n# Let\'s define the search space\nparam_bounds = {\n    "learning_rate": (1e-5, 1e-1),\n    "num_layers": (1, 10),\n    "dropout_rate": (0.0, 0.5)\n}\n\n# Initialize the Bayesian Optimization\nmodel = GPModel()\nacquisition_fn = ExpectedImprovement(model=model)\noptimizer = BayesianOptimizer(model=model, acquisition=acquisition_fn, bounds=param_bounds)\n\n# Run the optimization\nbest_hparams, best_perf = optimizer.optimize(\n    objective_function=training_function,\n    init_points=5,\n    n_iter=30\n)\n\nprint(f"Best hyperparams: {best_hparams}, with performance: {best_perf}")\n'}),"\n",i.createElement(t.p,null,"While hypothetical, the snippet highlights how one might structurally incorporate Bayesian optimization in an automl context, automatically iterating over hyperparameters, updating the surrogate model, and converging on strong configurations."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"neural-architecture-search-nas",style:{position:"relative"}},i.createElement(t.a,{href:"#neural-architecture-search-nas","aria-label":"neural architecture search nas permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Neural architecture search (nas)"),"\n",i.createElement(t.h3,{id:"why-nas-matters",style:{position:"relative"}},i.createElement(t.a,{href:"#why-nas-matters","aria-label":"why nas matters permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Why nas matters"),"\n",i.createElement(t.p,null,"Neural networks continue to dominate numerous machine learning applications, from computer vision to natural language processing. However, designing an optimal deep learning architecture is a notoriously complex task that hinges on factors like layer sizes, connectivity patterns, and specialized module choices (e.g., attention mechanisms or gating networks). Neural architecture search (nas) attempts to automate this process by exploring a vast design space of possible neural network topologies with minimal human intervention. This can be particularly valuable in automl if we want to integrate deep learning solutions for tasks like image classification or text generation."),"\n",i.createElement(t.h3,{id:"search-strategies-and-algorithms",style:{position:"relative"}},i.createElement(t.a,{href:"#search-strategies-and-algorithms","aria-label":"search strategies and algorithms permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Search strategies and algorithms"),"\n",i.createElement(t.p,null,"There are various nas approaches, each aiming to navigate the large combinatorial search space in a tractable manner:"),"\n",i.createElement(t.ol,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Evolutionary algorithms"),': Inspired by biological evolution, these methods iteratively evolve populations of network architectures. Poorly performing networks are removed, while better-performing ones are "mutated" or "crossovered" to spawn new architectures.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Reinforcement learning"),": First pioneered by Zoph and Le (ICLR 2017), an rl-based controller samples possible architectures, observes their performance, and adjusts its sampling strategy based on a reward signal."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Gradient-based nas"),": Explored in methods like DARTS (Liu and gang, ICLR 2019), these techniques treat architecture selection as a continuous optimization problem, learning architecture parameters via backpropagation."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Bayesian approaches"),": Less common but emerging methods rely on surrogate models to predict performance from architecture descriptors, building an iterative search similar to Bayesian optimization for hyperparameters."),"\n"),"\n",i.createElement(t.h3,{id:"popular-nas-frameworks",style:{position:"relative"}},i.createElement(t.a,{href:"#popular-nas-frameworks","aria-label":"popular nas frameworks permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Popular nas frameworks"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Auto-Keras"),": Provides a high-level api for automatically searching neural architectures for tasks like classification and regression in the Keras/TensorFlows ecosystem."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"ENAS"),": A more efficient version of reinforcement learning-based nas, focusing on parameter sharing across candidate architectures."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"NAS-Bench"),": A set of benchmarks like nas-bench-101, nas-bench-201, which offer standardized search spaces and precomputed performance data, thus enabling more efficient nas research and fair comparisons."),"\n"),"\n",i.createElement(t.h3,{id:"enhanced-nas-strategies-within-automl-pipelines",style:{position:"relative"}},i.createElement(t.a,{href:"#enhanced-nas-strategies-within-automl-pipelines","aria-label":"enhanced nas strategies within automl pipelines permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Enhanced nas strategies within automl pipelines"),"\n",i.createElement(t.p,null,"When integrated with an automl pipeline, nas might coordinate with meta-learning or hyperparameter optimization techniques. For example, Bayesian optimization might be used to determine macro-level architectural parameters (like the number of layers or the type of recurrent cell in an RNN), while meta-learning might propose effective initial weight configurations."),"\n",i.createElement(t.p,null,"Below is a greatly simplified representation of the nas inner-loop process:"),"\n",i.createElement(l.A,{text:"\\[\n\\mathcal{A}^* = \\underset{\\mathcal{A} \\in \\mathcal{S}}{\\mathrm{argmin}} \\; \\mathcal{L}\\big(\\mathrm{Train}(\\mathcal{A}), \\mathcal{Y}\\big)\n\\]"}),"\n",i.createElement(t.p,null,"where:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathcal{A} \\)"})," denotes a candidate architecture from the search space ",i.createElement(l.A,{text:"\\( \\mathcal{S} \\)"}),","),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathrm{Train}(\\mathcal{A}) \\)"})," is the function that trains the architecture ",i.createElement(l.A,{text:"\\( \\mathcal{A} \\)"}),","),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathcal{L} \\)"})," is the validation or test loss used to evaluate the candidate design,"),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mathcal{A}^* \\)"})," is the optimal architecture found after the search procedure."),"\n"),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"popular-automl-frameworks-and-algorithms",style:{position:"relative"}},i.createElement(t.a,{href:"#popular-automl-frameworks-and-algorithms","aria-label":"popular automl frameworks and algorithms permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Popular automl frameworks and algorithms"),"\n",i.createElement(t.h3,{id:"auto-sklearn",style:{position:"relative"}},i.createElement(t.a,{href:"#auto-sklearn","aria-label":"auto sklearn permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Auto-sklearn"),"\n",i.createElement(t.p,null,"Auto-sklearn extends scikit-learn by integrating Bayesian optimization, meta-learning, and ensemble construction. It builds on top of the existing scikit-learn ecosystem, containing dozens of algorithms from classical machine learning to ensemble-based methods. Importantly, auto-sklearn uses a meta-learning module to warm-start its Bayesian optimization, drastically cutting down the initial overhead for new tasks."),"\n",i.createElement(t.h3,{id:"tpot-tree-based-pipeline-optimization-tool",style:{position:"relative"}},i.createElement(t.a,{href:"#tpot-tree-based-pipeline-optimization-tool","aria-label":"tpot tree based pipeline optimization tool permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"TPOT (tree-based pipeline optimization tool)"),"\n",i.createElement(t.p,null,"TPOT uses genetic programming to construct pipelines that combine feature preprocessing, feature selection, and model training steps. Each pipeline is represented as a symbolic tree, which is evolved over successive generations aiming to maximize a performance metric. Despite sometimes requiring significant computational effort, tpot's interpretability in pipeline structure has garnered popularity."),"\n",i.createElement(t.h3,{id:"h2o-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#h2o-automl","aria-label":"h2o automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"H2O automl"),"\n",i.createElement(t.p,null,"H2O automl is a commercial-friendly framework that focuses on distributed computing and large-scale data. It iterates over a library of algorithms (like GLM, gbm, deep learning models) and can also construct stacked ensembles. It's particularly well-regarded for tackling large data sets within a cluster environment."),"\n",i.createElement(t.h3,{id:"google-cloud-automl-and-other-cloud-based-solutions",style:{position:"relative"}},i.createElement(t.a,{href:"#google-cloud-automl-and-other-cloud-based-solutions","aria-label":"google cloud automl and other cloud based solutions permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Google cloud automl and other cloud-based solutions"),"\n",i.createElement(t.p,null,"Cloud-based automl solutions (e.g., Google Cloud AutoML, Azure Machine Learning's automated ml, Amazon sagemaker autopilot) offer streamlined user interfaces and scalable backends, making them enticing for enterprise users who want fast results without extensive management of infrastructure. However, one common trade-off is reduced flexibility and interpretability, since many of the details of the search process are abstracted away from the user."),"\n",i.createElement(t.h3,{id:"comparison-of-features-and-performance",style:{position:"relative"}},i.createElement(t.a,{href:"#comparison-of-features-and-performance","aria-label":"comparison of features and performance permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Comparison of features and performance"),"\n",i.createElement(t.p,null,"Each framework has its strengths:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"auto-sklearn"),": Strong meta-learning, advanced ensembling, good for tabular data."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"tpot"),": Genetic programming approach with a very intuitive pipeline representation."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"h2o automl"),": Scalable, enterprise-oriented, strong ensembling, supports large data."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"cloud solutions"),": Convenient, often well-tuned for certain tasks, but can be a black box."),"\n"),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"practical-integration-of-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#practical-integration-of-automl","aria-label":"practical integration of automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Practical integration of automl"),"\n",i.createElement(t.h3,{id:"workflow-orchestration-and-pipeline-design",style:{position:"relative"}},i.createElement(t.a,{href:"#workflow-orchestration-and-pipeline-design","aria-label":"workflow orchestration and pipeline design permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Workflow orchestration and pipeline design"),"\n",i.createElement(t.p,null,"Practitioners often integrate automl steps into broader data pipelines using workflow orchestration tools like Apache Airflow or Kubeflow. The automl step is usually invoked after data ingestion and preprocessing tasks in the pipeline. The final chosen model or pipeline might then be passed to a model serving environment, integrated with business logic, or retrained regularly (e.g., nightly or weekly) using newly arrived data."),"\n",i.createElement(t.h3,{id:"model-interpretability-and-explainability",style:{position:"relative"}},i.createElement(t.a,{href:"#model-interpretability-and-explainability","aria-label":"model interpretability and explainability permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Model interpretability and explainability"),"\n",i.createElement(t.p,null,"One potential shortcoming of automl procedures is the complexity of final solutions. That is, after a pipeline is optimized or an ensemble is formed, it may be non-trivial to provide interpretability. Hence, advanced automl frameworks are now starting to incorporate explainable ai (xai) techniques — for example, computing feature importance, analyzing shap values, or constructing rule-based surrogates that approximate the final model's behavior. This is critical in regulated industries like finance or healthcare, where trust and transparency are paramount."),"\n",i.createElement(t.h3,{id:"real-time-inference-and-deployment",style:{position:"relative"}},i.createElement(t.a,{href:"#real-time-inference-and-deployment","aria-label":"real time inference and deployment permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Real-time inference and deployment"),"\n",i.createElement(t.p,null,"Automl often yields resource-intensive models. Another important step is to compress or distill these models for efficient deployment — especially if predictions must be served in near real time. Techniques such as knowledge distillation, quantization, or model pruning can be integrated within automl frameworks. The pipeline can automatically incorporate these steps if the user indicates constraints such as maximum latency or memory usage."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"challenges-and-considerations-in-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#challenges-and-considerations-in-automl","aria-label":"challenges and considerations in automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Challenges and considerations in automl"),"\n",i.createElement(t.p,null,"Despite remarkable progress, automl still faces a variety of significant challenges:"),"\n",i.createElement(t.h3,{id:"data-privacy-and-governance",style:{position:"relative"}},i.createElement(t.a,{href:"#data-privacy-and-governance","aria-label":"data privacy and governance permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Data privacy and governance"),"\n",i.createElement(t.p,null,"When using data from multiple sources, especially in regulated sectors, data security and compliance with rules like gdpr or hipaa become paramount. Some workflows incorporate federated learning to sidestep direct data sharing; however, it remains non-trivial to integrate robust privacy measures into a typical automl pipeline."),"\n",i.createElement(t.h3,{id:"scalability-and-computational-costs",style:{position:"relative"}},i.createElement(t.a,{href:"#scalability-and-computational-costs","aria-label":"scalability and computational costs permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Scalability and computational costs"),"\n",i.createElement(t.p,null,"Many automl methods rely on large-scale search processes or repeated training. This can be computationally demanding, especially on big data sets or complex model families. To combat this, parallelization strategies, distributed computing frameworks (e.g., Spark), or approximate early-stopping methods are often mandatory."),"\n",i.createElement(t.h3,{id:"interpretability-and-transparency-of-automated-systems",style:{position:"relative"}},i.createElement(t.a,{href:"#interpretability-and-transparency-of-automated-systems","aria-label":"interpretability and transparency of automated systems permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Interpretability and transparency of automated systems"),"\n",i.createElement(t.p,null,"When an external system is automatically building the pipeline, it can become elusive to trace the decisions made, or to fully understand why certain models are chosen. This is an area where domain experts might struggle to incorporate domain knowledge if the automl system does not provide sufficient customization or interpretability hooks."),"\n",i.createElement(t.h3,{id:"domain-specific-requirements",style:{position:"relative"}},i.createElement(t.a,{href:"#domain-specific-requirements","aria-label":"domain specific requirements permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Domain-specific requirements"),"\n",i.createElement(t.p,null,"Generic automl solutions may fail to address specialized domain constraints (e.g., real-time embedded systems for iot or purely on-device learning for mobile applications). Domain-specific automl frameworks are emerging to handle such constraints, but this is still an active area of development."),"\n",i.createElement(t.h3,{id:"ethical-and-social-implications",style:{position:"relative"}},i.createElement(t.a,{href:"#ethical-and-social-implications","aria-label":"ethical and social implications permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Ethical and social implications"),"\n",i.createElement(t.p,null,"Automating machine learning at scale can lead to repercussions if issues like bias, fairness, or representativeness of training data are not handled carefully. If an automl system blindly optimizes for a single metric, it may yield models that disproportionately impact certain demographic groups. Building in checks and balances for fairness is an ongoing and essential research topic."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"future-trends-in-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#future-trends-in-automl","aria-label":"future trends in automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Future trends in automl"),"\n",i.createElement(t.h3,{id:"advances-in-nas",style:{position:"relative"}},i.createElement(t.a,{href:"#advances-in-nas","aria-label":"advances in nas permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Advances in nas"),"\n",i.createElement(t.p,null,"We can expect the synergy between nas and other techniques (like meta-learning or multi-task learning) to intensify. The next frontier includes approaches that automatically discover novel neural operator types, specialized activation functions, or domain-specific architecture modules. Combining nas with large-scale pretraining or foundation models is also an intriguing possibility."),"\n",i.createElement(t.h3,{id:"real-time-automated-ml-pipelines",style:{position:"relative"}},i.createElement(t.a,{href:"#real-time-automated-ml-pipelines","aria-label":"real time automated ml pipelines permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Real-time automated ml pipelines"),"\n",i.createElement(t.p,null,"While many current automl workflows focus on batch processes, there's a growing demand for real-time or online automl. This scenario is relevant for streaming data or incremental learning. Methods that adapt their model choices on the fly, possibly leveraging streaming evaluations or ephemeral data sets, will be critical in applications like dynamic recommendation systems or risk management in finance."),"\n",i.createElement(t.h3,{id:"federated-learning-and-distributed-systems",style:{position:"relative"}},i.createElement(t.a,{href:"#federated-learning-and-distributed-systems","aria-label":"federated learning and distributed systems permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Federated learning and distributed systems"),"\n",i.createElement(t.p,null,"As data remains scattered across multiple data silos (e.g., mobile devices, different branches of an enterprise, or various hospitals), distributed or federated automl frameworks are becoming prominent. They must coordinate local training runs and model selection decisions while respecting data privacy constraints and network limitations."),"\n",i.createElement(t.h3,{id:"potential-for-fully-autonomous-data-science-workflows",style:{position:"relative"}},i.createElement(t.a,{href:"#potential-for-fully-autonomous-data-science-workflows","aria-label":"potential for fully autonomous data science workflows permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Potential for fully autonomous data science workflows"),"\n",i.createElement(t.p,null,"Finally, the ultimate aspiration is an end-to-end system that can handle the entire data science lifecycle with minimal human oversight: from data ingestion and cleaning to model deployment and monitoring, continuously improving itself. While we are moving closer to that vision, it raises questions of accountability, interpretability, and relevant domain knowledge integration that fully autonomous automl workflows must address."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"extended-deep-dive-advanced-theoretical-frameworks",style:{position:"relative"}},i.createElement(t.a,{href:"#extended-deep-dive-advanced-theoretical-frameworks","aria-label":"extended deep dive advanced theoretical frameworks permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Extended deep dive: advanced theoretical frameworks"),"\n",i.createElement(t.h3,{id:"bayesian-perspective-on-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#bayesian-perspective-on-automl","aria-label":"bayesian perspective on automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Bayesian perspective on automl"),"\n",i.createElement(t.p,null,"Consider an automl pipeline searching over a space of pipeline configurations ",i.createElement(l.A,{text:"\\( \\mathcal{P} \\)"}),". Suppose for a given pipeline ",i.createElement(l.A,{text:"\\( p \\in \\mathcal{P} \\)"})," with hyperparameters ",i.createElement(l.A,{text:"\\( \\mathbf{x} \\)"}),", we have a prior ",i.createElement(l.A,{text:"\\( p(p, \\mathbf{x} ) \\)"}),". We observe the performance data ",i.createElement(l.A,{text:"\\( D \\)"}),", typically validation metrics. Using a Bayesian lens, we want the posterior:"),"\n",i.createElement(l.A,{text:"\\[\np(p, \\mathbf{x} \\mid D) = \\frac{p(D \\mid p, \\mathbf{x}) \\; p(p, \\mathbf{x})}{p(D)}.\n\\]"}),"\n",i.createElement(t.p,null,"Maximizing this posterior or integrating out ",i.createElement(l.A,{text:"\\( p \\)"})," to get a posterior on ",i.createElement(l.A,{text:"\\( \\mathbf{x} \\)"})," is conceptually feasible but extremely challenging in practice because of the high dimensionality of the pipeline space. Approximations via Bayesian optimization or partial Monte Carlo methods are typically used."),"\n",i.createElement(t.h3,{id:"multi-armed-bandits-approach",style:{position:"relative"}},i.createElement(t.a,{href:"#multi-armed-bandits-approach","aria-label":"multi armed bandits approach permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Multi-armed bandits approach"),"\n",i.createElement(t.p,null,'Another theoretical backbone for automl can be framed as a multi-armed bandit or reinforcement learning problem. Each pipeline template or model configuration is an "arm" to pull, and the reward is the validation performance. The automl system tries to optimize its cumulative reward over time, employing exploration-exploitation strategies. Techniques like Thompson sampling or upper confidence bound (ucb) can be adapted to this end.'),"\n",i.createElement(t.h3,{id:"the-notion-of-regret-minimization",style:{position:"relative"}},i.createElement(t.a,{href:"#the-notion-of-regret-minimization","aria-label":"the notion of regret minimization permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"The notion of regret minimization"),"\n",i.createElement(t.p,null,"In online or iterative automl, the goal can often be phrased in terms of minimizing cumulative regret:"),"\n",i.createElement(l.A,{text:"\\[\nR(N) = \\sum_{t=1}^N \\big( \\mu^* - \\mu_{i_t} \\big),\n\\]"}),"\n",i.createElement(t.p,null,"where:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mu^* \\)"})," is the best possible expected model performance,"),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( \\mu_{i_t} \\)"})," is the performance of the chosen configuration at iteration ",i.createElement(l.A,{text:"\\( t \\)"}),","),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( i_t \\)"})," is the index of the chosen pipeline or arm at iteration ",i.createElement(l.A,{text:"\\( t \\)"}),","),"\n",i.createElement(t.li,null,i.createElement(l.A,{text:"\\( R(N) \\)"})," is the regret after ",i.createElement(l.A,{text:"\\( N \\)"})," trials."),"\n"),"\n",i.createElement(t.p,null,"Minimizing regret translates to rapidly finding and exploiting good pipelines, ensembling strategies, or hyperparameter sets."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"advanced-use-cases-and-case-studies",style:{position:"relative"}},i.createElement(t.a,{href:"#advanced-use-cases-and-case-studies","aria-label":"advanced use cases and case studies permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Advanced use cases and case studies"),"\n",i.createElement(t.h3,{id:"industry-use-finance-and-cybersecurity",style:{position:"relative"}},i.createElement(t.a,{href:"#industry-use-finance-and-cybersecurity","aria-label":"industry use finance and cybersecurity permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Industry use: finance and cybersecurity"),"\n",i.createElement(t.p,null,"In sectors like finance, automl is employed for tasks such as credit scoring, fraud detection, and risk assessment. Given the range of data from structured tabular records to textual documents, a broad set of models is tested, from tree-based ensembles to deep networks for textual analysis. The advantage is that automl can unify these disparate tasks under a single system that tries an array of pipelines and chooses the best approach."),"\n",i.createElement(t.p,null,"Cybersecurity, with its dynamic threat landscapes, also benefits. Automl solutions retrain detection models periodically, adapt to new threat signatures, and test data streams from various sources. Meta-learning can accelerate adaptation since prior threat detection tasks inform the system of critical patterns indicative of malicious behavior."),"\n",i.createElement(t.h3,{id:"healthcare-analytics",style:{position:"relative"}},i.createElement(t.a,{href:"#healthcare-analytics","aria-label":"healthcare analytics permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Healthcare analytics"),"\n",i.createElement(t.p,null,"Healthcare data often comes with constraints like small sample sizes, missing values, and privacy regulations. Automl frameworks can handle these complexities by automating the search for robust imputation methods, data augmentation strategies, and clinically interpretable feature transformations. The real-world significance is substantial: improved detection of diseases and earlier predictions leading to more effective patient management."),"\n",i.createElement(t.h3,{id:"accelerated-rd-for-machine-learning-research",style:{position:"relative"}},i.createElement(t.a,{href:"#accelerated-rd-for-machine-learning-research","aria-label":"accelerated rd for machine learning research permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Accelerated r&d for machine learning research"),"\n",i.createElement(t.p,null,"Automl significantly reduces r&d friction for ml researchers exploring new algorithms. By wrapping experimental code in an automl-friendly format, a broad search can be done quickly over multiple benchmarks. This standardization fosters reproducibility and speeds up the iteration cycle, allowing researchers to focus more on conceptual advances than on repetitive pipeline engineering."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"in-depth-tips-and-recommendations",style:{position:"relative"}},i.createElement(t.a,{href:"#in-depth-tips-and-recommendations","aria-label":"in depth tips and recommendations permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"In-depth tips and recommendations"),"\n",i.createElement(t.h3,{id:"balancing-resource-allocation",style:{position:"relative"}},i.createElement(t.a,{href:"#balancing-resource-allocation","aria-label":"balancing resource allocation permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Balancing resource allocation"),"\n",i.createElement(t.p,null,"When employing automl at scale, you have to manage cluster resources judiciously. Certain frameworks let you specify time or memory budgets. It's wise to start with shorter training cycles or smaller data subsets to get a sense of which configurations are most promising, then ramp up to full training for the top contenders."),"\n",i.createElement(t.h3,{id:"interpreting-complex-ensembles",style:{position:"relative"}},i.createElement(t.a,{href:"#interpreting-complex-ensembles","aria-label":"interpreting complex ensembles permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Interpreting complex ensembles"),"\n",i.createElement(t.p,null,"Automl systems often produce ensembles of models. While these can deliver higher performance, it can be difficult to parse how each model contributes. Some interpretability approaches break down the ensemble's decisions. For instance, local surrogate modeling or integrated gradients might be used to glean insights into which features consistently drive predictions across ensemble members."),"\n",i.createElement(t.h3,{id:"domain-knowledge-integration",style:{position:"relative"}},i.createElement(t.a,{href:"#domain-knowledge-integration","aria-label":"domain knowledge integration permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Domain knowledge integration"),"\n",i.createElement(t.p,null,'Fully automated workflows might ignore domain-specific constraints or prior knowledge. For instance, if certain transformations are known to be beneficial given domain expertise, it\'s prudent to incorporate them as a "mandatory pipeline step" in your automl system. This ensures that automl still has freedom to explore other steps but remains grounded in proven domain best practices.'),"\n",i.createElement(t.h3,{id:"monitoring-drift-and-re-triggering-automl",style:{position:"relative"}},i.createElement(t.a,{href:"#monitoring-drift-and-re-triggering-automl","aria-label":"monitoring drift and re triggering automl permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Monitoring drift and re-triggering automl"),"\n",i.createElement(t.p,null,"Over time, real-world data distribution may drift, degrading model performance. Automl pipelines can be scheduled to periodically monitor performance metrics and automatically re-trigger the search or hyperparameter tuning if performance falls below a threshold. This approach fosters continuous improvement without requiring constant manual oversight."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"demonstration-code-snippet-automl-pipeline-assembly",style:{position:"relative"}},i.createElement(t.a,{href:"#demonstration-code-snippet-automl-pipeline-assembly","aria-label":"demonstration code snippet automl pipeline assembly permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Demonstration code snippet: automl pipeline assembly"),"\n",i.createElement(t.p,null,"Below is a more comprehensive Python snippet that outlines how one might orchestrate an automl pipeline search, from data ingestion to final model selection, using a hypothetical automl library:"),"\n",i.createElement(r.A,{text:'\nimport pandas as pd\nfrom hypothetical_automl_lib import DataPrep, AutoFeatureEngine, AutoModelSearch, Evaluate\n\n# Step 1: Load data\ndata = pd.read_csv("training_dataset.csv")\ntest_data = pd.read_csv("test_dataset.csv")\n\n# Step 2: Automatic data preparation\nprep = DataPrep()\ncleaned_data = prep.fit_transform(data)\n\n# Step 3: Auto feature engineering\nfe = AutoFeatureEngine()\nfeatures, target = fe.fit_transform(cleaned_data, target_column="label")\n\n# Step 4: Auto model selection, HPO, and ensembling\nams = AutoModelSearch(time_budget=3600, max_models=50)\nams.fit(features, target)\n\n# Step 5: Evaluate on test data\ncleaned_test_data = prep.transform(test_data)\ntest_features, test_target = fe.transform(cleaned_test_data, target_column="label")\nresults = Evaluate(ams.best_pipeline_, test_features, test_target)\n\nprint("Best pipeline performance:", results["metrics"])\n'}),"\n",i.createElement(t.p,null,"Although this code is purely illustrative, it shows how each step of the pipeline can be automated. In real implementations, you would see additional options for controlling data splitting strategies, advanced hyperparameter search methods, or meta-learning warm starts."),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"illustrative-placeholders-for-images",style:{position:"relative"}},i.createElement(t.a,{href:"#illustrative-placeholders-for-images","aria-label":"illustrative placeholders for images permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Illustrative placeholders for images"),"\n",i.createElement(t.p,null,"Below are some recommended images you might add to an article or lecture deck to facilitate comprehension:"),"\n",i.createElement(a,{alt:"automl_overall_workflow",path:"",caption:"A conceptual diagram of a full automl workflow, showcasing data ingestion, automated feature selection, model selection, and final pipeline creation",zoom:"false"}),"\n",i.createElement(a,{alt:"meta_learning_flowchart",path:"",caption:"A flowchart highlighting how meta-learning draws knowledge from previous tasks to optimize hyperparameter selection in new tasks",zoom:"false"}),"\n",i.createElement(a,{alt:"nas_search_space",path:"",caption:"A high-level view of the neural architecture search space, showcasing the myriad of possible layer connections and parameter choices",zoom:"false"}),"\n",i.createElement(t.hr),"\n",i.createElement(t.h2,{id:"concluding-insights",style:{position:"relative"}},i.createElement(t.a,{href:"#concluding-insights","aria-label":"concluding insights permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Concluding insights"),"\n",i.createElement(t.p,null,"Over the course of these two articles on automated machine learning, I have endeavored to illustrate how automl frameworks unify multiple advanced ml concepts — data preprocessing, feature engineering, meta-learning, hyperparameter optimization, neural architecture search, and even ensembling — under one integrated system. Today's second installment zoomed in on the more specialized mechanisms that augment an automl system's capacity to handle the complexities of real-world use cases: meta-learning, advanced hpo methods, nas, interpretability, and domain-specific constraints."),"\n",i.createElement(t.p,null,"Still, the automl landscape is rapidly evolving. We see leaps in computational efficiency, the rise of federated or distributed automl to handle data at scale, and an ongoing drive to incorporate fairness and ethical considerations natively into automl pipelines. For practitioners, the payoff is clear: less time spent on repetitive tasks, more consistent performance across a variety of data sets, and an astonishing capacity to discover novel architectures or hyperparameter configurations — all while ensuring minimal oversight once properly configured."),"\n",i.createElement(t.p,null,"As you venture further, consider questions like the following:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,"How can you incorporate domain experts' tacit knowledge into the automl pipeline?"),"\n",i.createElement(t.li,null,"Which interpretability tools can help you justify automatically discovered pipelines to stakeholders?"),"\n",i.createElement(t.li,null,"In what ways might online or incremental variants of automl be beneficial for your organization's real-time data challenges?"),"\n"),"\n",i.createElement(t.p,null,'The question of how far automl can go in fully automating the machine learning process remains open. Many claim that "human-in-the-loop" designs will always be critical to ensure alignment with domain requirements and ethical oversight. Regardless, the synergy between advanced algorithms, meta-learning strategies, robust software frameworks, and distributed hardware architectures suggests that the future of automl will dramatically shape how we build, deploy, and monitor machine learning solutions in the coming years.'))}var s=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,n.RP)(),e.components);return t?i.createElement(t,e,i.createElement(o,e)):o(e)};var c=a(54506),m=a(88864),h=a(58481),d=a.n(h),p=a(5984),u=a(43672),g=a(27042),f=a(72031),v=a(81817),y=a(27105),b=a(17265),E=a(2043),w=a(95751),S=a(94328),x=a(80791),H=a(78137);const k=e=>{let{toc:t}=e;if(!t||!t.items)return null;return i.createElement("nav",{className:x.R},i.createElement("ul",null,t.items.map(((e,t)=>i.createElement("li",{key:t},i.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const a=t.replace("#",""),n=document.getElementById(a);n&&n.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&i.createElement(k,{toc:{items:e.items}}))))))};function _(e){let{data:{mdx:t,allMdx:r,allPostImages:l},children:o}=e;const{frontmatter:s,body:m,tableOfContents:h}=t,f=s.index,x=s.slug.split("/")[1],_=r.nodes.filter((e=>e.frontmatter.slug.includes(`/${x}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),z=_.findIndex((e=>e.frontmatter.index===f)),M=_[z+1],C=_[z-1],T=s.slug.replace(/\/$/,""),A=/[^/]*$/.exec(T)[0],V=`posts/${x}/content/${A}/`,{0:I,1:B}=(0,i.useState)(s.flagWideLayoutByDefault),{0:L,1:N}=(0,i.useState)(!1);var P;(0,i.useEffect)((()=>{N(!0);const e=setTimeout((()=>N(!1)),340);return()=>clearTimeout(e)}),[I]),"adventures"===x?P=b.cb:"research"===x?P=b.Qh:"thoughts"===x&&(P=b.T6);const O=d()(m).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,q=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),a=e%60;return a<=30?`~${t}${a>0?".5":""} h`:`~${t+1} h`}(Math.ceil(O/P)+(s.extraReadTimeMin||0)),R=[{flag:s.flagDraft,component:()=>Promise.all([a.e(5850),a.e(9833)]).then(a.bind(a,49833))},{flag:s.flagMindfuckery,component:()=>Promise.all([a.e(5850),a.e(7805)]).then(a.bind(a,27805))},{flag:s.flagRewrite,component:()=>Promise.all([a.e(5850),a.e(8916)]).then(a.bind(a,78916))},{flag:s.flagOffensive,component:()=>Promise.all([a.e(5850),a.e(6731)]).then(a.bind(a,49112))},{flag:s.flagProfane,component:()=>Promise.all([a.e(5850),a.e(3336)]).then(a.bind(a,83336))},{flag:s.flagMultilingual,component:()=>Promise.all([a.e(5850),a.e(2343)]).then(a.bind(a,62343))},{flag:s.flagUnreliably,component:()=>Promise.all([a.e(5850),a.e(6865)]).then(a.bind(a,11627))},{flag:s.flagPolitical,component:()=>Promise.all([a.e(5850),a.e(4417)]).then(a.bind(a,24417))},{flag:s.flagCognitohazard,component:()=>Promise.all([a.e(5850),a.e(8669)]).then(a.bind(a,18669))},{flag:s.flagHidden,component:()=>Promise.all([a.e(5850),a.e(8124)]).then(a.bind(a,48124))}],{0:G,1:D}=(0,i.useState)([]);return(0,i.useEffect)((()=>{R.forEach((e=>{let{flag:t,component:a}=e;t&&a().then((e=>{D((t=>[].concat((0,c.A)(t),[e.default])))}))}))}),[]),i.createElement(g.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},i.createElement(v.A,{postNumber:s.index,date:s.date,updated:s.updated,readTime:q,difficulty:s.difficultyLevel,title:s.title,desc:s.desc,banner:s.banner,section:x,postKey:A,isMindfuckery:s.flagMindfuckery,mainTag:s.mainTag}),i.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},s.otherTags.map(((e,t)=>i.createElement("span",{key:t,className:`noselect ${H.MW}`,style:{margin:"0 5px 5px 0"}},e)))),i.createElement("div",{className:"postBody"},i.createElement(k,{toc:h})),i.createElement("br",null),i.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},i.createElement(g.P.button,{className:`noselect ${S.pb}`,id:S.xG,onClick:()=>{B(!I)},whileTap:{scale:.93}},i.createElement(g.P.div,{className:w.DJ,key:I,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},I?"Switch to default layout":"Switch to wide layout"))),i.createElement("br",null),i.createElement("div",{className:"postBody",style:{margin:I?"0 -14%":"",maxWidth:I?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},i.createElement("div",{className:`${S.P_} ${L?S.Xn:S.qG}`},G.map(((e,t)=>i.createElement(e,{key:t}))),s.indexCourse?i.createElement(E.A,{index:s.indexCourse,category:s.courseCategoryName}):"",i.createElement(p.Z.Provider,{value:{images:l.nodes,basePath:V.replace(/\/$/,"")+"/"}},i.createElement(n.xA,{components:{Image:u.A}},o)))),i.createElement(y.A,{nextPost:M,lastPost:C,keyCurrent:A,section:x}))}function z(e){return i.createElement(_,e,i.createElement(s,e))}function M(e){var t,a,n,r,l;let{data:o}=e;const{frontmatter:s}=o.mdx,c=s.titleSEO||s.title,h=s.titleOG||c,d=s.titleTwitter||c,p=s.descSEO||s.desc,u=s.descOG||p,g=s.descTwitter||p,v=s.schemaType||"BlogPosting",y=s.keywordsSEO,b=s.date,E=s.updated||b,w=s.imageOG||(null===(t=s.banner)||void 0===t||null===(a=t.childImageSharp)||void 0===a||null===(n=a.gatsbyImageData)||void 0===n||null===(r=n.images)||void 0===r||null===(l=r.fallback)||void 0===l?void 0:l.src),S=s.imageAltOG||u,x=s.imageTwitter||w,H=s.imageAltTwitter||g,k=s.canonicalURL,_=s.flagHidden||!1,z=s.mainTag||"Posts",M=s.slug.split("/")[1]||"posts",{siteUrl:C}=(0,m.Q)(),T={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:C},{"@type":"ListItem",position:2,name:z,item:`${C}/${s.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${C}${s.slug}`}]};return i.createElement(f.A,{title:c+" - avrtt.blog",titleOG:h,titleTwitter:d,description:p,descriptionOG:u,descriptionTwitter:g,schemaType:v,keywords:y,datePublished:b,dateModified:E,imageOG:w,imageAltOG:S,imageTwitter:x,imageAltTwitter:H,canonicalUrl:k,flagHidden:_,mainTag:z,section:M,type:"article"},i.createElement("script",{type:"application/ld+json"},JSON.stringify(T)))}},90548:function(e,t,a){var n=a(96540),i=a(7978);t.A=e=>{let{text:t}=e;return n.createElement(i.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-pages-posts-research-automated-ml-2-mdx-701959c3cdfea1c24c3e.js.map