"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[3962],{54327:function(e,t,n){n.r(t),n.d(t,{Head:function(){return A},PostTemplate:function(){return H},default:function(){return k}});var a=n(54506),i=n(28453),l=n(96540),r=n(16886),s=(n(46295),n(96098));function o(e){const t=Object.assign({p:"p",h2:"h2",a:"a",span:"span",h3:"h3",ol:"ol",li:"li",ul:"ul",strong:"strong",hr:"hr"},(0,i.RP)(),e.components),{Image:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),l.createElement(l.Fragment,null,"\n",l.createElement("br"),"\n","\n","\n","\n",l.createElement(t.p,null,"Gradient optimization lies at the heart of nearly all modern machine learning (ML) methods, powering everything from classical linear regression models to massive deep neural networks. When we train a model — be it a simple regression model or a state-of-the-art Transformer — our objective is to adjust the model's internal parameters in a way that minimizes some loss or cost function. This minimization is rarely performed analytically, as exact solutions often do not exist for complex models or might be computationally intractable. Instead, we rely on iterative optimization procedures that exploit the gradient of the loss with respect to the model parameters."),"\n",l.createElement(t.p,null,"A major reason gradient optimization has become so ubiquitous is that it scales relatively well to high-dimensional parameter spaces and large datasets. This is particularly crucial in today's world of deep learning, where models may consist of hundreds of millions (or even billions) of parameters. As a result, expertise in gradient-based optimization is essential for designing, training, and understanding a broad range of machine learning algorithms."),"\n",l.createElement(t.p,null,'In this article, we will dive into the fundamentals of gradient optimization, revisit the basics of loss minimization in ML, explore gradient descent (the most widely used gradient optimization algorithm), and then examine its three main variants: batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. Along the way, we will study both theoretical underpinnings and practical considerations. Our focus here is on the "classical" versions of gradient-based optimization. In a subsequent article, we will discuss advanced modifications, including adaptive learning rate methods (e.g., Adam, RMSProp, Adagrad) and second-order approaches (e.g., Newton\'s method, quasi-Newton methods).'),"\n",l.createElement(t.p,null,"Whether you come from a background in machine learning, data science, or a related field, understanding the core mechanics and nuances of gradient optimization is foundational. By the end of this piece, you should have a deeper grasp of how gradient-based optimizers work, why they are used, and how to implement and tune them in practice."),"\n",l.createElement(t.h2,{id:"2-revisiting-the-basics-of-ml-optimization",style:{position:"relative"}},l.createElement(t.a,{href:"#2-revisiting-the-basics-of-ml-optimization","aria-label":"2 revisiting the basics of ml optimization permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2. Revisiting the basics of ml optimization"),"\n",l.createElement(t.p,null,"In machine learning, a model is typically defined by a set of parameters (weights, biases, coefficients, or any other internal variables) that we wish to learn from data. For a supervised learning problem, we often have a labeled dataset ",l.createElement(s.A,{text:"\\( \\{(x_1, y_1), (x_2, y_2), \\ldots, (x_m, y_m)\\} \\)"}),". Each ",l.createElement(s.A,{text:"\\(x_i\\)"})," denotes the features for the ",l.createElement(s.A,{text:"\\(i\\)"}),"-th instance, and ",l.createElement(s.A,{text:"\\(y_i\\)"})," denotes the corresponding target (e.g., a class label or a continuous value)."),"\n",l.createElement(t.h3,{id:"the-objective-function-loss-or-cost-function",style:{position:"relative"}},l.createElement(t.a,{href:"#the-objective-function-loss-or-cost-function","aria-label":"the objective function loss or cost function permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"The objective function (loss or cost function)"),"\n",l.createElement(t.p,null,"A core piece of machine learning is defining how we measure the performance of a model's parameters on the given data. This is typically done via a loss (or cost) function. For example, in linear regression with mean squared error (MSE) as the loss, our goal is to minimize:"),"\n",l.createElement(s.A,{text:"\\[\nL(\\mathbf{w}) = \\frac{1}{m} \\sum_{i=1}^{m} \\bigl(y_i - \\hat{y}_i(\\mathbf{w})\\bigr)^2,\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(s.A,{text:"\\( \\hat{y}_i(\\mathbf{w}) \\)"})," is the model's prediction for the ",l.createElement(s.A,{text:"\\(i\\)"}),"-th data point, and ",l.createElement(s.A,{text:"\\(\\mathbf{w}\\)"})," represents the model parameters (weights). In classification tasks, one might use a cross-entropy loss, hinge loss, or another appropriate objective."),"\n",l.createElement(t.h3,{id:"parameter-space-and-searching-for-minima",style:{position:"relative"}},l.createElement(t.a,{href:"#parameter-space-and-searching-for-minima","aria-label":"parameter space and searching for minima permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Parameter space and searching for minima"),"\n",l.createElement(t.p,null,"For many models, the parameter space can be extremely large (sometimes millions of dimensions). Directly solving for the global optimum can be very difficult or impossible in closed form. Instead, we rely on numerical optimization methods that iteratively refine an initial guess."),"\n",l.createElement(t.h3,{id:"significance-of-gradients-in-optimization",style:{position:"relative"}},l.createElement(t.a,{href:"#significance-of-gradients-in-optimization","aria-label":"significance of gradients in optimization permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Significance of gradients in optimization"),"\n",l.createElement(t.p,null,"The gradient of the loss function with respect to the parameters tells us the local direction of steepest ascent in the loss landscape. To minimize the loss, we want to step in the opposite direction of that gradient. This insight underpins gradient descent: if the gradient of ",l.createElement(s.A,{text:"\\(L(\\mathbf{w})\\)"})," at step ",l.createElement(s.A,{text:"\\(t\\)"})," is ",l.createElement(s.A,{text:"\\(\\nabla L(\\mathbf{w}^{(t)})\\)"}),", we update our parameters as:"),"\n",l.createElement(s.A,{text:"\\( \\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\eta \\,\\nabla L(\\mathbf{w}^{(t)}) \\)"}),"\n",l.createElement(t.p,null,"where ",l.createElement(s.A,{text:"\\(\\eta\\)"})," is the learning rate. While conceptually simple, properly tuning the gradient descent procedure can be an art in itself. Learning rate choice, initialization strategies, and iteration scheduling all factor into the final performance of our model."),"\n",l.createElement(t.h2,{id:"3-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#3-gradient-descent","aria-label":"3 gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3. Gradient descent"),"\n",l.createElement(t.p,null,"Gradient descent (GD) is one of the most fundamental and well-known optimization algorithms in machine learning. Its basic premise is:"),"\n",l.createElement(t.ol,null,"\n",l.createElement(t.li,null,"Start with an initial guess for the parameters (e.g., random initialization)."),"\n",l.createElement(t.li,null,"Compute the gradient of the objective function (the cost or loss) with respect to the parameters."),"\n",l.createElement(t.li,null,"Update the parameters by moving a small step against the gradient (the direction of steepest descent)."),"\n",l.createElement(t.li,null,"Repeat steps 2 and 3 until convergence or until a stopping criterion is met."),"\n"),"\n",l.createElement(t.p,null,l.createElement(r.A,null,"Key Terms")," to keep in mind:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Cost function (Loss function)"),": The function you want to minimize (e.g., MSE, cross-entropy)."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Gradient"),": The vector of partial derivatives of the cost function with respect to all parameters."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Convergence"),": A state where the parameters are no longer changing meaningfully, or a defined stopping criterion is met."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Learning rate"),": A hyperparameter (",l.createElement(s.A,{text:"\\(\\eta\\)"}),") that controls the size of the step in the direction of the negative gradient."),"\n"),"\n",l.createElement(t.p,null,"Gradient descent's concept is straightforward, yet the practical details — especially regarding convergence speed and numerical stability — are crucial to making it work effectively. For example, setting the learning rate too high can cause the parameters to oscillate wildly or diverge, while a too-small learning rate can lead to painfully slow training."),"\n",l.createElement(t.h2,{id:"4-math-behind-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#4-math-behind-gradient-descent","aria-label":"4 math behind gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4. Math behind gradient descent"),"\n",l.createElement(t.p,null,"The mathematics of gradient descent can be understood by looking at how we compute partial derivatives of a chosen loss function and update the model parameters accordingly. In machine learning, these partial derivatives often correspond to how each weight in a neural network or a linear model influences the overall cost."),"\n",l.createElement(t.h3,{id:"41-deriving-the-gradient-descent-formula",style:{position:"relative"}},l.createElement(t.a,{href:"#41-deriving-the-gradient-descent-formula","aria-label":"41 deriving the gradient descent formula permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.1 deriving the gradient descent formula"),"\n",l.createElement(t.p,null,"Suppose we have a cost function ",l.createElement(s.A,{text:"\\(L(\\mathbf{w})\\)"}),". The gradient ",l.createElement(s.A,{text:"\\(\\nabla L(\\mathbf{w})\\)"})," is the vector of partial derivatives:"),"\n",l.createElement(s.A,{text:"\\[\n\\nabla L(\\mathbf{w}) =\n\\begin{bmatrix}\n\\frac{\\partial L(\\mathbf{w})}{\\partial w_1} \\\\\n\\frac{\\partial L(\\mathbf{w})}{\\partial w_2} \\\\\n\\vdots \\\\\n\\frac{\\partial L(\\mathbf{w})}{\\partial w_n}\n\\end{bmatrix}.\n\\]"}),"\n",l.createElement(t.p,null,"Intuitively, each component of ",l.createElement(s.A,{text:"\\(\\nabla L(\\mathbf{w})\\)"})," measures how sensitive the loss is to changes in a particular parameter ",l.createElement(s.A,{text:"\\(w_j\\)"}),". Moving against the gradient — i.e., subtracting a small multiple of the gradient from the current parameter vector — lowers the value of the cost function, at least in a local sense."),"\n",l.createElement(t.p,null,"Mathematically, the update rule for gradient descent can be written as:"),"\n",l.createElement(s.A,{text:"\\[\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\eta \\,\\nabla L(\\mathbf{w}^{(t)}),\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(s.A,{text:"\\(\\mathbf{w}^{(t)}\\)"})," is the parameter vector at iteration ",l.createElement(s.A,{text:"\\(t\\)"}),", and ",l.createElement(s.A,{text:"\\(\\eta\\)"})," is the learning rate."),"\n",l.createElement(t.h3,{id:"42-calculating-partial-derivatives-and-their-importance",style:{position:"relative"}},l.createElement(t.a,{href:"#42-calculating-partial-derivatives-and-their-importance","aria-label":"42 calculating partial derivatives and their importance permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.2 calculating partial derivatives and their importance"),"\n",l.createElement(t.p,null,"For many ML models — like linear or logistic regression — the partial derivatives of the loss function can be computed analytically. For instance, in linear regression with mean squared error, one can derive a closed-form gradient expression:"),"\n",l.createElement(s.A,{text:"\\[\n\\nabla L(\\mathbf{w}) = \\frac{2}{m} \\mathbf{X}^T (\\mathbf{X} \\mathbf{w} - \\mathbf{y}),\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(s.A,{text:"\\(\\mathbf{X}\\)"})," is the design matrix of input features, ",l.createElement(s.A,{text:"\\(\\mathbf{y}\\)"})," is the vector of target values, and ",l.createElement(s.A,{text:"\\(m\\)"})," is the number of training samples."),"\n",l.createElement(t.p,null,"In other models, especially neural networks, we often use backpropagation (the chain rule) to compute partial derivatives. Regardless of the model, calculating partial derivatives accurately and efficiently is essential to applying gradient descent."),"\n",l.createElement(t.h3,{id:"43-convergence-criteria",style:{position:"relative"}},l.createElement(t.a,{href:"#43-convergence-criteria","aria-label":"43 convergence criteria permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.3 convergence criteria"),"\n",l.createElement(t.p,null,'Determining when gradient descent "converges" can be somewhat subjective or dependent on application-specific needs. Common criteria include:'),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Parameter change"),": Stop when the difference ",l.createElement(s.A,{text:"\\( \\|\\mathbf{w}^{(t+1)} - \\mathbf{w}^{(t)}\\|\\)"})," is below a certain threshold."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Gradient magnitude"),": Stop when ",l.createElement(s.A,{text:"\\(\\|\\nabla L(\\mathbf{w}^{(t)})\\|\\)"})," becomes very small."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Maximum iterations"),": Stop after a fixed number of iterations or epochs."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Validation metric"),": In practice, we often monitor a validation set's performance. If it stops improving (or worsens), we may reduce the learning rate or halt entirely (early stopping)."),"\n"),"\n",l.createElement(t.p,null,"In many real-world ML applications, early stopping based on validation performance is especially common, since it helps prevent overfitting."),"\n",l.createElement(t.h3,{id:"44-learning-rate-and-its-impact",style:{position:"relative"}},l.createElement(t.a,{href:"#44-learning-rate-and-its-impact","aria-label":"44 learning rate and its impact permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.4 learning rate and its impact"),"\n",l.createElement(t.p,null,"The learning rate ",l.createElement(s.A,{text:"\\(\\eta\\)"})," is arguably the single most important hyperparameter in gradient descent. Its role is to determine how big a step we take in the negative gradient direction each time we update the parameters."),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Too large ",l.createElement(s.A,{text:"\\(\\eta\\)"})),": The parameter updates might overshoot the minimum. Loss values can explode or fluctuate drastically, resulting in divergence or chaotic behavior."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Too small ",l.createElement(s.A,{text:"\\(\\eta\\)"})),": Convergence becomes very slow, potentially requiring an impractically large number of updates."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Variable learning rate"),': Many training regimens feature learning rate "decay" or scheduling, in which ',l.createElement(s.A,{text:"\\(\\eta\\)"})," is reduced over time to refine the convergence process. A common schedule might be a simple decay: ",l.createElement(s.A,{text:"\\(\\eta^{(t)} = \\frac{\\eta_0}{1 + kt}\\)"}),", or an exponential decay like ",l.createElement(s.A,{text:"\\(\\eta^{(t)} = \\eta_0 \\cdot \\alpha^t\\)"}),", where ",l.createElement(s.A,{text:"\\(k\\)"})," or ",l.createElement(s.A,{text:"\\(\\alpha\\)"})," is some constant chosen by the researcher."),"\n"),"\n",l.createElement(t.p,null,"In practice, the learning rate can be tuned by trial and error, grid search, random search, or more sophisticated automated hyperparameter optimization. The perfect setting is highly model- and dataset-dependent, making this a critical point of experimentation in real-world ML pipelines."),"\n",l.createElement(t.h2,{id:"5-main-types-of-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#5-main-types-of-gradient-descent","aria-label":"5 main types of gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5. main types of gradient descent"),"\n",l.createElement(t.p,null,"While the classical idea of gradient descent updates is straightforward, the exact mechanism by which we compute the gradient (and the portion of the dataset used) can vary significantly. This gives rise to three main variants:"),"\n",l.createElement(t.ol,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Batch gradient descent (BGD)"),": Uses the entire training set to compute the gradient at each step."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Stochastic gradient descent (SGD)"),": Uses one training example (or sometimes a very small subset) per gradient update."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Mini-batch gradient descent (MBGD)"),": Uses a small batch of training examples (e.g., 32, 64, or 256 samples) at each iteration."),"\n"),"\n",l.createElement(t.p,null,"Each approach has advantages and drawbacks, influencing how it handles large datasets, converges to minima, and generalizes to new data."),"\n",l.createElement(t.h3,{id:"51-batch-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#51-batch-gradient-descent","aria-label":"51 batch gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.1 batch gradient descent"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Batch gradient descent")," computes the gradient of the cost function by summing or averaging over all training examples before performing a single update. That is:"),"\n",l.createElement(s.A,{text:"\\[\n\\nabla L(\\mathbf{w}) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla L_i(\\mathbf{w}),\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(s.A,{text:"\\(L_i(\\mathbf{w})\\)"})," is the loss contribution from the ",l.createElement(s.A,{text:"\\(i\\)"}),"-th example, and ",l.createElement(s.A,{text:"\\(m\\)"})," is the total number of training examples."),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Pros"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"The gradient computation is exact for the current set of parameters (assuming no sampling, the entire dataset is used)."),"\n",l.createElement(t.li,null,"Often yields stable and predictable updates."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Cons"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Very slow for large datasets, as each update requires a pass over all the training data."),"\n",l.createElement(t.li,null,"Consumes significant memory if the dataset does not fit comfortably in RAM or GPU memory."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Use cases"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Datasets that are moderately sized (where computing the gradient over the entire set is not prohibitively expensive)."),"\n",l.createElement(t.li,null,"Problems where stable, more deterministic updates are preferable."),"\n"),"\n",l.createElement(t.h3,{id:"52-stochastic-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#52-stochastic-gradient-descent","aria-label":"52 stochastic gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.2 stochastic gradient descent"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Stochastic gradient descent (SGD)")," picks one training example (or sometimes a single random subset) at each iteration to compute an approximate gradient. Formally, if ",l.createElement(s.A,{text:"\\(i\\)"})," is chosen randomly from ",l.createElement(s.A,{text:"\\(\\{1, 2, \\ldots, m\\}\\)"}),", then:"),"\n",l.createElement(s.A,{text:"\\[\n\\nabla L(\\mathbf{w}) \\approx \\nabla L_i(\\mathbf{w}).\n\\]"}),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Pros"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Can be extremely fast and memory efficient, as it processes one example at a time (in the purest form)."),"\n",l.createElement(t.li,null,'Potentially escapes local minima more easily, because the gradient is "noisy."'),"\n",l.createElement(t.li,null,"Scales well to massive datasets (common in online learning scenarios)."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Cons"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"High variance in updates can result in an erratic convergence path."),"\n",l.createElement(t.li,null,"Requires more careful tuning of the learning rate, often with a decay schedule."),"\n",l.createElement(t.li,null,"The objective function does not necessarily decrease at every iteration (due to the sampling noise)."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Use cases"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Very large datasets or streaming data."),"\n",l.createElement(t.li,null,"Online or real-time machine learning applications where data arrives continuously."),"\n",l.createElement(t.li,null,"Situations where memory resources are limited."),"\n"),"\n",l.createElement(t.h3,{id:"53-mini-batch-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#53-mini-batch-gradient-descent","aria-label":"53 mini batch gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.3 mini-batch gradient descent"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Mini-batch gradient descent")," is in many ways a middle ground between batch and stochastic methods. It processes a small batch of training data (say ",l.createElement(s.A,{text:"\\(b\\)"})," examples) at each iteration:"),"\n",l.createElement(s.A,{text:"\\[\n\\nabla L(\\mathbf{w}) \\approx \\frac{1}{b} \\sum_{i \\in \\text{batch}} \\nabla L_i(\\mathbf{w}),\n\\]"}),"\n",l.createElement(t.p,null,'where "batch" is a small random subset of the training set. For instance, if ',l.createElement(s.A,{text:"\\(m = 60,000\\)"})," and the chosen mini-batch size is 64, each update uses 64 examples out of the 60,000."),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Pros"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Less computationally heavy than full batch descent, since it only processes a small subset at a time."),"\n",l.createElement(t.li,null,"Reduces variance compared to pure SGD, since multiple examples smooth out the gradient estimate."),"\n",l.createElement(t.li,null,"Efficiently vectorizable on modern hardware (GPUs often favor certain batch sizes)."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Cons"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Slightly more memory-intensive than pure SGD if the mini-batch is large, but typically not as large as full batch."),"\n",l.createElement(t.li,null,"Still introduces some noise in the gradient, although less than SGD."),"\n"),"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Use cases"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"The most common approach in modern deep learning, as it balances computational efficiency with convergence stability."),"\n",l.createElement(t.li,null,"Works well with GPU-based acceleration."),"\n",l.createElement(t.li,null,"Generally recommended for medium to large datasets in practical ML scenarios."),"\n"),"\n",l.createElement(t.p,null,"Most deep learning frameworks default to mini-batch training. Researchers often tune the mini-batch size based on hardware constraints (e.g., GPU VRAM) and find that certain batch sizes can lead to better (or faster) convergence, depending on the problem and architecture."),"\n",l.createElement(t.h2,{id:"6-practical-implementation-considerations",style:{position:"relative"}},l.createElement(t.a,{href:"#6-practical-implementation-considerations","aria-label":"6 practical implementation considerations permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6. practical implementation considerations"),"\n",l.createElement(t.p,null,"The success of gradient-based methods depends on several practical details that go beyond the core update rule. Here are a few key considerations:"),"\n",l.createElement(t.ol,null,"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Data preprocessing"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Normalization or standardization"),": Bringing all features to a similar scale speeds up convergence by avoiding extremely elongated or skewed loss landscapes."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Shuffling"),": It is typically beneficial to shuffle the training data (or shuffle it in mini-batches) to avoid unwanted ordering effects."),"\n"),"\n"),"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Monitoring convergence and validation performance"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Track the training loss and validation loss over iterations or epochs."),"\n",l.createElement(t.li,null,"Consider using early stopping when the validation performance stops improving."),"\n"),"\n"),"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Hyperparameter tuning"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Learning rate"),": Often the single most important parameter; must be chosen carefully."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Batch size"),": For mini-batch methods, the size of each batch can significantly affect both speed and performance."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Regularization"),": Methods like ",l.createElement(s.A,{text:"\\(L_2\\)"})," (ridge) or ",l.createElement(s.A,{text:"\\(L_1\\)"})," (lasso) can be integrated with gradient descent simply by adjusting the loss function to include regularization terms."),"\n"),"\n"),"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Exploding/vanishing gradients"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"In deep neural networks, the gradient can sometimes become extremely large or extremely small, causing numerical issues and hampering learning. Various techniques (e.g., gradient clipping, careful initialization, batch normalization, or sophisticated architectures) are used to mitigate these issues."),"\n"),"\n"),"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Efficient computation"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Tools like vectorization (in NumPy, PyTorch, TensorFlow) can dramatically speed up gradient computations."),"\n",l.createElement(t.li,null,"GPUs or TPUs excel at mini-batch gradient computations for deep learning tasks."),"\n"),"\n"),"\n",l.createElement(t.li,null,"\n",l.createElement(t.p,null,l.createElement(t.strong,null,"Heuristic improvements"),":"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Using momentum-based methods (to be discussed in detail in subsequent articles) can smooth out noisy updates."),"\n",l.createElement(t.li,null,"Advanced learning rate schedules (e.g., warm restarts, cyclical learning rates) can sometimes yield better results than static schedules."),"\n"),"\n"),"\n"),"\n",l.createElement(t.h2,{id:"7-implementations",style:{position:"relative"}},l.createElement(t.a,{href:"#7-implementations","aria-label":"7 implementations permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7. implementations"),"\n",l.createElement(t.p,null,"Below are two sample implementations that demonstrate how gradient descent might be coded from scratch in Python, focusing on a simple linear regression scenario. Following that, we'll briefly illustrate how one might use scikit-learn's ",l.createElement(r.A,null,"SGDClassifier")," for classification tasks."),"\n",l.createElement(t.hr),"\n",l.createElement(t.h3,{id:"71-example-batch-gradient-descent-for-linear-regression-numpy",style:{position:"relative"}},l.createElement(t.a,{href:"#71-example-batch-gradient-descent-for-linear-regression-numpy","aria-label":"71 example batch gradient descent for linear regression numpy permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1 example: batch gradient descent for linear regression (numpy)"),"\n",l.createElement(t.p,null,"Here, we demonstrate how to implement ",l.createElement(t.strong,null,"batch gradient descent")," to learn the parameters of a simple linear regression model. Suppose we have a design matrix ",l.createElement(s.A,{text:"\\(\\mathbf{X}\\)"})," (dimension ",l.createElement(s.A,{text:"\\(m \\times n\\)"}),") and a target vector ",l.createElement(s.A,{text:"\\(\\mathbf{y}\\)"})," of dimension ",l.createElement(s.A,{text:"\\(m\\)"}),"."),"\n",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\nimport numpy as np\n\ndef batch_gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):\n    """\n    Perform batch gradient descent for a linear regression model.\n    X is an m x n matrix of features.\n    y is an m-dimensional vector of targets.\n    """\n    m, n = X.shape\n    # Initialize parameters (weights) randomly or with zeros\n    w = np.zeros(n)\n    \n    # Optionally, you can add a column of 1s to X externally for the intercept\n    # or manage it separately. We\'ll assume X is already preprocessed.\n    \n    for iteration in range(n_iterations):\n        # Predictions\n        y_pred = X.dot(w)\n        \n        # Compute the gradient of the MSE cost function\n        # L(w) = (1/m) * sum((y_pred - y)^2)\n        # Gradient: (2/m) * X.T.dot(y_pred - y)\n        \n        gradient = (2.0 / m) * X.T.dot(y_pred - y)\n        \n        # Update rule\n        w = w - learning_rate * gradient\n        \n        # (Optional) Monitor the loss\n        if iteration % 100 == 0:\n            loss = np.mean((y_pred - y) ** 2)\n            print(f"Iteration {iteration}, Loss: {loss:.5f}")\n    \n    return w\n`}/></code></pre></div>'}}),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Initialization"),": We set the initial parameter vector ",l.createElement(s.A,{text:"\\(w\\)"})," to zeros (or random small values)."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Learning rate"),": Default is ",l.createElement(s.A,{text:"\\(0.01\\)"}),"."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Gradient computation"),": Uses the entire dataset on each update (batch GD)."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Update step"),": ",l.createElement(s.A,{text:"\\( w \\leftarrow w - \\eta \\, \\nabla L(w)\\)"}),"."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Output"),": Returns the final learned weights."),"\n"),"\n",l.createElement(t.p,null,"In practice, you might add advanced features like dynamic learning rate schedules or early stopping. You would also preprocess the input data (e.g., normalization, mean-centering) before calling this function."),"\n",l.createElement(t.h3,{id:"72-example-stochastic-gradient-descent-for-linear-regression-numpy",style:{position:"relative"}},l.createElement(t.a,{href:"#72-example-stochastic-gradient-descent-for-linear-regression-numpy","aria-label":"72 example stochastic gradient descent for linear regression numpy permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2 example: stochastic gradient descent for linear regression (numpy)"),"\n",l.createElement(t.p,null,"Below is a simplistic code snippet for ",l.createElement(t.strong,null,"stochastic gradient descent"),". Each iteration uses exactly one randomly chosen data point to update the weights. This can converge quickly in practice but is often noisy."),"\n",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\nimport numpy as np\n\ndef stochastic_gradient_descent(X, y, learning_rate=0.01, n_epochs=5):\n    """\n    Perform stochastic gradient descent for a linear regression model.\n    X is an m x n matrix of features.\n    y is an m-dimensional vector of targets.\n    """\n    m, n = X.shape\n    w = np.zeros(n)\n    \n    for epoch in range(n_epochs):\n        # Shuffle the data to avoid cycles\n        indices = np.random.permutation(m)\n        X_shuffled = X[indices]\n        y_shuffled = y[indices]\n        \n        for i in range(m):\n            # Pick one example\n            xi = X_shuffled[i, :].reshape(1, -1)\n            yi = y_shuffled[i]\n            \n            # Predict\n            y_pred = xi.dot(w)\n            \n            # Compute the gradient for this single example\n            gradient = 2.0 * xi.T.dot(y_pred - yi)\n            \n            # Update\n            w = w - learning_rate * gradient.flatten()\n        \n        # (Optional) Monitoring the overall loss at the end of each epoch\n        total_loss = np.mean((X.dot(w) - y) ** 2)\n        print(f"Epoch {epoch+1}, Loss: {total_loss:.5f}")\n    \n    return w\n`}/></code></pre></div>'}}),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Epoch"),": A single pass through all ",l.createElement(s.A,{text:"\\(m\\)"})," training samples."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Shuffle"),": We shuffle ",l.createElement(s.A,{text:"\\(X\\)"})," and ",l.createElement(s.A,{text:"\\(y\\)"})," each epoch for better convergence properties."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"One-sample update"),": The gradient is computed using just one sample (",l.createElement(s.A,{text:"\\(i\\)"}),")."),"\n"),"\n",l.createElement(t.p,null,"Here, the parameters get updated ",l.createElement(s.A,{text:"\\(m\\)"})," times per epoch, one per training sample. This often allows faster initial progress but can be quite noisy, necessitating learning rate schedules or other smoothing techniques."),"\n",l.createElement(t.h3,{id:"73-mini-batch-gradient-descent",style:{position:"relative"}},l.createElement(t.a,{href:"#73-mini-batch-gradient-descent","aria-label":"73 mini batch gradient descent permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3 mini-batch gradient descent"),"\n",l.createElement(t.p,null,"A ",l.createElement(t.strong,null,"mini-batch approach")," is usually more efficient on modern hardware (particularly GPUs), especially for deep learning tasks. Conceptually, it is halfway between the above two approaches, so the implementation is similar; the main difference is that we pick (say) 32 or 64 samples at a time rather than 1 or ",l.createElement(s.A,{text:"\\(m\\)"}),"."),"\n",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\nimport numpy as np\n\ndef mini_batch_gradient_descent(X, y, learning_rate=0.01, n_epochs=5, batch_size=32):\n    """\n    Perform mini-batch gradient descent for a linear regression model.\n    X is an m x n matrix of features.\n    y is an m-dimensional vector of targets.\n    """\n    m, n = X.shape\n    w = np.zeros(n)\n    n_batches_per_epoch = m // batch_size\n    \n    for epoch in range(n_epochs):\n        # Shuffle the data\n        indices = np.random.permutation(m)\n        X_shuffled = X[indices]\n        y_shuffled = y[indices]\n        \n        for b in range(n_batches_per_epoch):\n            start = b * batch_size\n            end = start + batch_size\n            \n            X_batch = X_shuffled[start:end, :]\n            y_batch = y_shuffled[start:end]\n            \n            # Predictions\n            y_pred = X_batch.dot(w)\n            \n            # Compute gradient on the mini-batch\n            gradient = (2.0 / batch_size) * X_batch.T.dot(y_pred - y_batch)\n            \n            # Update\n            w = w - learning_rate * gradient\n        \n        # At the end of each epoch, you could measure the global training loss\n        total_loss = np.mean((X.dot(w) - y) ** 2)\n        print(f"Epoch {epoch+1}, Loss: {total_loss:.5f}")\n    \n    return w\n`}/></code></pre></div>'}}),"\n",l.createElement(t.p,null,"This approach typically converges more smoothly than pure stochastic gradient descent and more quickly than batch gradient descent (especially for large ",l.createElement(s.A,{text:"\\(m\\)"}),")."),"\n",l.createElement(t.h3,{id:"74-example-using-scikit-learns-sgdclassifier",style:{position:"relative"}},l.createElement(t.a,{href:"#74-example-using-scikit-learns-sgdclassifier","aria-label":"74 example using scikit learns sgdclassifier permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4 example: using scikit-learn's sgdclassifier"),"\n",l.createElement(t.p,null,"Many frameworks provide ready-made SGD-based estimators. Below is a short example using ",l.createElement(t.strong,null,"scikit-learn"),"'s ",l.createElement(r.A,null,"SGDClassifier")," on the classic Iris dataset:"),"\n",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\n# Load the iris dataset\niris = datasets.load_iris()\nX = iris.data  # shape (150, 4)\ny = iris.target  # shape (150,)\n\n# Split into train/test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\n# Create and fit an SGD classifier\nclf = SGDClassifier(\n    loss=\'hinge\',      # The \'hinge\' loss gives a linear SVM\n    penalty=\'l2\',      # L2 regularization\n    alpha=0.0001,      # Regularization parameter\n    learning_rate=\'optimal\',\n    max_iter=1000,\n    shuffle=True,\n    random_state=42\n)\n\nclf.fit(X_train, y_train)\n\n# Evaluate\naccuracy = clf.score(X_test, y_test)\nprint(f"Test set accuracy with SGDClassifier: {accuracy * 100:.2f}%")\n`}/></code></pre></div>'}}),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"loss"),": By default, ",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:"<code class=\"language-text\">'hinge'</code>"}})," is used, which corresponds to a linear SVM approach."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"penalty"),": Regularization method (",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:"<code class=\"language-text\">'l2'</code>"}}),", ",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:"<code class=\"language-text\">'l1'</code>"}}),", or ",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:"<code class=\"language-text\">'elasticnet'</code>"}}),")."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"alpha"),": The coefficient of regularization."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"learning_rate"),": ",l.createElement(t.span,{dangerouslySetInnerHTML:{__html:"<code class=\"language-text\">'optimal'</code>"}})," is an adaptive method that scikit-learn uses to help with convergence."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"shuffle"),": We usually shuffle data each epoch to improve performance."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"random_state"),": Ensures reproducible results."),"\n"),"\n",l.createElement(t.p,null,"Because ",l.createElement(r.A,null,"SGDClassifier")," is integrated into scikit-learn, it can handle the details of iteration, convergence detection, and even partial fitting on streaming data if necessary."),"\n",l.createElement(t.h2,{id:"optional-additional-illustrations",style:{position:"relative"}},l.createElement(t.a,{href:"#optional-additional-illustrations","aria-label":"optional additional illustrations permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"(optional) additional illustrations"),"\n",l.createElement(t.p,null,"Below are a few conceptual image placeholders that can be very helpful for visualizing gradient descent, especially for those who are more visually inclined:"),"\n",l.createElement(n,{alt:"Illustration of gradient descent on a contour plot",path:"",caption:"A contour plot of a cost function in 2D parameter space, showing iterative steps moving downhill toward the minimum.",zoom:"false"}),"\n",l.createElement(n,{alt:"Effect of different learning rates",path:"",caption:"Depiction of how a small vs. large learning rate can either converge slowly or overshoot the minimum, respectively.",zoom:"false"}),"\n",l.createElement(n,{alt:"Batch vs. Stochastic vs. Mini-batch updates",path:"",caption:"Comparison of the three approaches: batch (large stable updates), stochastic (small noisy updates), and mini-batch (balanced approach).",zoom:"false"}),"\n",l.createElement(t.h2,{id:"putting-it-all-together",style:{position:"relative"}},l.createElement(t.a,{href:"#putting-it-all-together","aria-label":"putting it all together permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"putting it all together"),"\n",l.createElement(t.p,null,"Gradient descent in its many forms is an indispensable tool in the modern machine learning toolbox. While simple on the surface, mastering the intricacies of gradient-based optimization can elevate the performance and stability of your models in real-world contexts. Key points to remember:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Choice of variant"),": Decide which gradient descent approach best suits your dataset size, memory constraints, and hardware. Mini-batch is the de facto standard in deep learning, whereas batch or even pure stochastic gradient descent might be more fitting in smaller-scale or streaming applications."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Learning rate"),": Tune it carefully. Experiment with different schedules and watch for signs of divergence or overly slow convergence."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Implementation details"),": Proper data preprocessing, random shuffling, regularization, and gradient checks can drastically improve training outcomes."),"\n",l.createElement(t.li,null,l.createElement(t.strong,null,"Further enhancements"),": Momentum, adaptive gradient methods (e.g., Adam, RMSProp), and second-order approaches can lead to faster or more robust convergence. We will discuss these methods in a subsequent article."),"\n"),"\n",l.createElement(t.p,null,"Modern ML practitioners often take these fundamentals for granted, but understanding precisely how gradients are computed and used for parameter updates gives you deeper insight into why certain methods and heuristics work as they do. It also opens the door to creative experimentation and innovation, whether you're tackling a standard classification task or pushing the boundaries of deep learning research."),"\n",l.createElement(t.p,null,"Gradient optimization is a cornerstone — once you grasp it, you're better positioned to tackle everything from logistic regression to large-scale deep networks, from simple academic examples to real-time streaming data scenarios. Moreover, the same principles carry over when you move into advanced concepts: adaptive optimizers, large-batch training for supercomputing clusters, distributed gradient computations, and more."),"\n",l.createElement(t.p,null,"Finally, keep in mind that while gradient descent is ubiquitous, it isn't always a panacea. Certain classes of problems may be amenable to specialized solvers or alternative optimization strategies. Nonetheless, for the vast majority of machine learning tasks, gradient-based optimization (in one form or another) is the proven workhorse driving model training from start to finish."))}var c=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,i.RP)(),e.components);return t?l.createElement(t,e,l.createElement(o,e)):o(e)};var m=n(36710),d=n(58481),h=n.n(d),u=n(36310),p=n(87245),g=n(27042),f=n(59849),E=n(5591),v=n(61122),b=n(9219),y=n(33203),w=n(95751),x=n(94328),S=n(80791),_=n(78137);const z=e=>{let{toc:t}=e;if(!t||!t.items)return null;return l.createElement("nav",{className:S.R},l.createElement("ul",null,t.items.map(((e,t)=>l.createElement("li",{key:t},l.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const n=t.replace("#",""),a=document.getElementById(n);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&l.createElement(z,{toc:{items:e.items}}))))))};function H(e){let{data:{mdx:t,allMdx:r,allPostImages:s},children:o}=e;const{frontmatter:c,body:m,tableOfContents:d}=t,f=c.index,S=c.slug.split("/")[1],H=r.nodes.filter((e=>e.frontmatter.slug.includes(`/${S}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),k=H.findIndex((e=>e.frontmatter.index===f)),A=H[k+1],M=H[k-1],T=c.slug.replace(/\/$/,""),L=/[^/]*$/.exec(T)[0],C=`posts/${S}/content/${L}/`,{0:I,1:P}=(0,l.useState)(c.flagWideLayoutByDefault),{0:V,1:G}=(0,l.useState)(!1);var B;(0,l.useEffect)((()=>{G(!0);const e=setTimeout((()=>G(!1)),340);return()=>clearTimeout(e)}),[I]),"adventures"===S?B=b.cb:"research"===S?B=b.Qh:"thoughts"===S&&(B=b.T6);const N=h()(m).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,X=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),n=e%60;return n<=30?`~${t}${n>0?".5":""} h`:`~${t+1} h`}(Math.ceil(N/B)+(c.extraReadTimeMin||0)),D=[{flag:c.flagDraft,component:()=>Promise.all([n.e(3231),n.e(8809)]).then(n.bind(n,28809))},{flag:c.flagMindfuckery,component:()=>Promise.all([n.e(3231),n.e(2471)]).then(n.bind(n,67709))},{flag:c.flagRewrite,component:()=>Promise.all([n.e(3231),n.e(6764)]).then(n.bind(n,62002))},{flag:c.flagOffensive,component:()=>Promise.all([n.e(3231),n.e(2443)]).then(n.bind(n,17681))},{flag:c.flagProfane,component:()=>Promise.all([n.e(3231),n.e(8048)]).then(n.bind(n,53286))},{flag:c.flagMultilingual,component:()=>Promise.all([n.e(3231),n.e(4069)]).then(n.bind(n,78831))},{flag:c.flagUnreliably,component:()=>Promise.all([n.e(3231),n.e(3417)]).then(n.bind(n,8179))},{flag:c.flagPolitical,component:()=>Promise.all([n.e(3231),n.e(5195)]).then(n.bind(n,30433))},{flag:c.flagCognitohazard,component:()=>Promise.all([n.e(3231),n.e(3175)]).then(n.bind(n,8413))},{flag:c.flagHidden,component:()=>Promise.all([n.e(3231),n.e(9556)]).then(n.bind(n,14794))}],{0:O,1:U}=(0,l.useState)([]);return(0,l.useEffect)((()=>{D.forEach((e=>{let{flag:t,component:n}=e;t&&n().then((e=>{U((t=>[].concat((0,a.A)(t),[e.default])))}))}))}),[]),l.createElement(g.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},l.createElement(E.A,{postNumber:c.index,date:c.date,updated:c.updated,readTime:X,difficulty:c.difficultyLevel,title:c.title,desc:c.desc,banner:c.banner,section:S,postKey:L,isMindfuckery:c.flagMindfuckery,mainTag:c.mainTag}),l.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},c.otherTags.map(((e,t)=>l.createElement("span",{key:t,className:`noselect ${_.MW}`,style:{margin:"0 5px 5px 0"}},e)))),l.createElement("div",{className:"postBody"},l.createElement(z,{toc:d})),l.createElement("br"),l.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},l.createElement(g.P.button,{className:`noselect ${x.pb}`,id:x.xG,onClick:()=>{P(!I)},whileTap:{scale:.93}},l.createElement(g.P.div,{className:w.DJ,key:I,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},I?"Switch to default layout":"Switch to wide layout"))),l.createElement("br"),l.createElement("div",{className:"postBody",style:{margin:I?"0 -14%":"",maxWidth:I?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},l.createElement("div",{className:`${x.P_} ${V?x.Xn:x.qG}`},O.map(((e,t)=>l.createElement(e,{key:t}))),c.indexCourse?l.createElement(y.A,{index:c.indexCourse,category:c.courseCategoryName}):"",l.createElement(u.Z.Provider,{value:{images:s.nodes,basePath:C.replace(/\/$/,"")+"/"}},l.createElement(i.xA,{components:{Image:p.A}},o)))),l.createElement(v.A,{nextPost:A,lastPost:M,keyCurrent:L,section:S}))}function k(e){return l.createElement(H,e,l.createElement(c,e))}function A(e){var t,n,a,i,r;let{data:s}=e;const{frontmatter:o}=s.mdx,c=o.titleSEO||o.title,d=o.titleOG||c,h=o.titleTwitter||c,u=o.descSEO||o.desc,p=o.descOG||u,g=o.descTwitter||u,E=o.schemaType||"BlogPosting",v=o.keywordsSEO,b=o.date,y=o.updated||b,w=o.imageOG||(null===(t=o.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.gatsbyImageData)||void 0===a||null===(i=a.images)||void 0===i||null===(r=i.fallback)||void 0===r?void 0:r.src),x=o.imageAltOG||p,S=o.imageTwitter||w,_=o.imageAltTwitter||g,z=o.canonicalURL,H=o.flagHidden||!1,k=o.mainTag||"Posts",A=o.slug.split("/")[1]||"posts",{siteUrl:M}=(0,m.Q)(),T={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:M},{"@type":"ListItem",position:2,name:k,item:`${M}/${o.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${M}${o.slug}`}]};return l.createElement(f.A,{title:c+" - avrtt.blog",titleOG:d,titleTwitter:h,description:u,descriptionOG:p,descriptionTwitter:g,schemaType:E,keywords:v,datePublished:b,dateModified:y,imageOG:w,imageAltOG:x,imageTwitter:S,imageAltTwitter:_,canonicalUrl:z,flagHidden:H,mainTag:k,section:A,type:"article"},l.createElement("script",{type:"application/ld+json"},JSON.stringify(T)))}},96098:function(e,t,n){var a=n(96540),i=n(7978);t.A=e=>{let{text:t}=e;return a.createElement(i.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-js-content-file-path-src-pages-posts-research-gradient-optimization-mdx-d23971cd8106f0e635b4.js.map