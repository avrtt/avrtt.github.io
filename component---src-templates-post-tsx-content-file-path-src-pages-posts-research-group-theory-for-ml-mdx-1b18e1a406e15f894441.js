"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[7305],{3962:function(e,t){t.A="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pgo8IS0tIEdlbmVyYXRvcjogQWRvYmUgSWxsdXN0cmF0b3IgMTYuMC4wLCBTVkcgRXhwb3J0IFBsdWctSW4gLiBTVkcgVmVyc2lvbjogNi4wMCBCdWlsZCAwKSAgLS0+CjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+CjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iQ2FwYV8xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB4PSIwcHgiIHk9IjBweCIKCSB3aWR0aD0iNDE2Ljk3OXB4IiBoZWlnaHQ9IjQxNi45NzlweCIgdmlld0JveD0iMCAwIDQxNi45NzkgNDE2Ljk3OSIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNDE2Ljk3OSA0MTYuOTc5OyIKCSB4bWw6c3BhY2U9InByZXNlcnZlIj4KPGc+Cgk8cGF0aCBkPSJNMzU2LjAwNCw2MS4xNTZjLTgxLjM3LTgxLjQ3LTIxMy4zNzctODEuNTUxLTI5NC44NDgtMC4xODJjLTgxLjQ3LDgxLjM3MS04MS41NTIsMjEzLjM3OS0wLjE4MSwyOTQuODUKCQljODEuMzY5LDgxLjQ3LDIxMy4zNzgsODEuNTUxLDI5NC44NDksMC4xODFDNDM3LjI5MywyNzQuNjM2LDQzNy4zNzUsMTQyLjYyNiwzNTYuMDA0LDYxLjE1NnogTTIzNy42LDM0MC43ODYKCQljMCwzLjIxNy0yLjYwNyw1LjgyMi01LjgyMiw1LjgyMmgtNDYuNTc2Yy0zLjIxNSwwLTUuODIyLTIuNjA1LTUuODIyLTUuODIyVjE2Ny44ODVjMC0zLjIxNywyLjYwNy01LjgyMiw1LjgyMi01LjgyMmg0Ni41NzYKCQljMy4yMTUsMCw1LjgyMiwyLjYwNCw1LjgyMiw1LjgyMlYzNDAuNzg2eiBNMjA4LjQ5LDEzNy45MDFjLTE4LjYxOCwwLTMzLjc2Ni0xNS4xNDYtMzMuNzY2LTMzLjc2NQoJCWMwLTE4LjYxNywxNS4xNDctMzMuNzY2LDMzLjc2Ni0zMy43NjZjMTguNjE5LDAsMzMuNzY2LDE1LjE0OCwzMy43NjYsMzMuNzY2QzI0Mi4yNTYsMTIyLjc1NSwyMjcuMTA3LDEzNy45MDEsMjA4LjQ5LDEzNy45MDF6Ii8+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPC9zdmc+Cg=="},9360:function(e,t,n){n.d(t,{A:function(){return o}});var a=n(96540),r=n(3962),i="styles-module--tooltiptext--a263b";var o=e=>{let{text:t,isBadge:n=!1}=e;const{0:o,1:s}=(0,a.useState)(!1),l=(0,a.useRef)(null);return(0,a.useEffect)((()=>{function e(e){l.current&&e.target instanceof Node&&!l.current.contains(e.target)&&s(!1)}return document.addEventListener("click",e),()=>{document.removeEventListener("click",e)}}),[]),a.createElement("span",{className:"styles-module--tooltipWrapper--75ebf",ref:l},a.createElement("img",{id:n?"styles-module--infoBadge--e3d66":"styles-module--info--26c1f",src:r.A,alt:"info",onClick:e=>{e.stopPropagation(),s((e=>!e))}}),a.createElement("span",{className:o?`${i} styles-module--visible--c063c`:i},t))}},85441:function(e,t,n){n.r(t),n.d(t,{Head:function(){return T},PostTemplate:function(){return _},default:function(){return L}});var a=n(28453),r=n(96540),i=n(9360),o=n(61992),s=n(62087),l=n(90548);function c(e){const t=Object.assign({p:"p",h3:"h3",a:"a",span:"span",h4:"h4",ul:"ul",li:"li",h2:"h2",ol:"ol",strong:"strong"},(0,a.RP)(),e.components),{Image:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),r.createElement(r.Fragment,null,"\n",r.createElement("br"),"\n","\n","\n",r.createElement(t.p,null,"Machine learning has seen tremendous growth over the last decade, in part because researchers have steadily incorporated an ever-expanding set of mathematical tools designed to capture the underlying structures and symmetries present in real-world data. One of the most powerful and elegant among these mathematical tools is ",r.createElement(o.A,null,"group theory"),". Group theory plays a critical role in modeling the ways that data can be transformed, rotated, reflected, permuted, or otherwise manipulated, while preserving essential structure or meaning. The capacity to handle symmetries effectively is central to many of the leading-edge machine learning architectures — especially in computer vision, robotics, molecular modeling, and other areas where transformations of the data (including rotations, translations, or permutations of elements) need to be taken into account in a mathematically principled way."),"\n",r.createElement(t.h3,{id:"motivation-for-group-theory-in-machine-learning",style:{position:"relative"}},r.createElement(t.a,{href:"#motivation-for-group-theory-in-machine-learning","aria-label":"motivation for group theory in machine learning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Motivation for group theory in machine learning"),"\n",r.createElement(t.p,null,"Group theory is sometimes seen as an esoteric branch of abstract algebra, but it has deep relevance to machine learning, especially in situations where one might expect or require certain invariances or equivariances of a model's output with respect to transformations of the input data. A typical example is in computer vision, where we want a classification system for images to be robust to certain transformations such as rotations or flips. If a system is trained to detect objects in images, we usually want it to classify an object the same way whether the image is rotated by 90 degrees or mirrored along some axis — unless there is a meaningful semantic distinction introduced by such a transformation (e.g., the difference between left-facing and right-facing text in optical character recognition could matter). The existence of these symmetries often means that we can reduce the effective complexity of a model, or that we can incorporate more knowledge about the data into the architecture of the network itself, thereby improving sample efficiency and generalization."),"\n",r.createElement(t.p,null,"The reason that group theory lies at the heart of such approaches is that ",r.createElement(i.A,{text:"a group is a set equipped with an operation that satisfies certain axioms (closure, associativity, identity, inverse)"}),'. In simpler terms, a group formalizes the notion of a "transformation set" that can be performed on an object, such that combining transformations in succession is still a valid transformation, there is a notion of doing "nothing" (the identity transformation), and each transformation has a corresponding inverse. This precisely corresponds to how we usually think about transformations like "rotate by 20° then rotate back by —20°", or "flip about a horizontal axis, then flip again about that same axis to recover the original". By modeling the transformations as elements of a group, we can exploit the rich theory of group actions, group representations, and related concepts from representation theory and harmonic analysis. These frameworks unify how transformations behave when applied to data, and how that behavior can be reflected in neural architectures or other machine learning models.'),"\n",r.createElement(t.h4,{id:"why-symmetries-and-transformations-are-central-in-modern-ml",style:{position:"relative"}},r.createElement(t.a,{href:"#why-symmetries-and-transformations-are-central-in-modern-ml","aria-label":"why symmetries and transformations are central in modern ml permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Why symmetries and transformations are central in modern ML"),"\n",r.createElement(t.p,null,"In many tasks, especially in vision and signal processing, data has inherent symmetries: an image of a cat remains an image of the same cat when the camera is slightly rotated or moved, a speech signal might be shifted in time without fundamentally changing the content, a 3D protein structure might be rotated in space, and so on. A hallmark of many successful ML architectures is leveraging such domain-specific symmetries:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(o.A,null,"Convolutional neural networks (CNNs)")," inherently incorporate translational symmetry by applying convolution filters across spatial or temporal dimensions."),"\n",r.createElement(t.li,null,r.createElement(o.A,null,"Group-equivariant neural networks (G-CNNs)")," extend this idea to additional transformations such as rotations and reflections (Cohen and Welling, ICML 2016)."),"\n",r.createElement(t.li,null,r.createElement(o.A,null,"Steerable filters")," (Freeman and Adelson, 1991) let a filter change orientation in a predictable way, which is closely related to group theory since the transformations of orientations can be modeled by certain subgroups of the continuous rotation group."),"\n"),"\n",r.createElement(t.p,null,"When the architecture aligns with the transformations that a dataset may undergo, the model can learn more efficiently, require fewer samples, and generalize in a more robust manner. From this perspective, group theory is the natural mathematical language to describe these transformations and to systematically exploit them."),"\n",r.createElement(t.h4,{id:"examples-of-rotationreflection-invariance-in-image-tasks",style:{position:"relative"}},r.createElement(t.a,{href:"#examples-of-rotationreflection-invariance-in-image-tasks","aria-label":"examples of rotationreflection invariance in image tasks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Examples of rotation/reflection invariance in image tasks"),"\n",r.createElement(t.p,null,"Computer vision applications often showcase how invariance to rotations or reflections can be vital. In digit classification on the MNIST dataset, a digit rotated by 30° or 90° is still the same digit. If we train a classifier from scratch on every possible rotation, we might need far more training examples, whereas a carefully crafted architecture that encodes rotational symmetry from the outset can generalize to those rotations right away."),"\n",r.createElement(t.p,null,"Even more complex tasks, like detecting tumors in medical images that might be oriented in arbitrary ways, benefit from the same principle. In such contexts, reflection invariance can also matter (e.g., flipping a scan left-to-right, which might not change the clinical significance of a tumor). These real-world examples underscore why machine learning researchers frequently turn to group theory: it offers a unified theoretical framework to encode the notion of symmetry, invariance, and related properties that can be exploited to reduce complexity and improve performance."),"\n",r.createElement(t.h2,{id:"fundamentals-of-group-theory",style:{position:"relative"}},r.createElement(t.a,{href:"#fundamentals-of-group-theory","aria-label":"fundamentals of group theory permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Fundamentals of group theory"),"\n",r.createElement(t.p,null,"To properly appreciate how group theory helps in ML contexts, it is helpful to have a thorough grounding in the basic concepts. Because many advanced and specialized results (like group representations and group convolutions) hinge on definitions of groups, subgroups, and group actions, I want to outline the core elements that define group theory and highlight the specific forms of groups commonly used in machine learning (ML) applications."),"\n",r.createElement(t.h3,{id:"basic-definitions",style:{position:"relative"}},r.createElement(t.a,{href:"#basic-definitions","aria-label":"basic definitions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Basic definitions"),"\n",r.createElement(t.p,null,"A ",r.createElement(o.A,null,"group")," is a set ",r.createElement(l.A,{text:"\\(G\\)"})," together with a binary operation, often denoted ",r.createElement(l.A,{text:"\\(\\cdot\\)"}),", that combines any two elements ",r.createElement(l.A,{text:"\\(g_1, g_2 \\in G\\)"})," to form another element of ",r.createElement(l.A,{text:"\\(G\\)"}),". The operation might also be expressed with juxtaposition (",r.createElement(l.A,{text:"\\(g_1 g_2\\)"}),") or with some symbol (like ",r.createElement(l.A,{text:"\\(+\\)"})," in the case of an additive group). For instance, in a rotation group, the operation is composition of rotations — rotating by 30° followed by 45° is the same as a single rotation by 75°."),"\n",r.createElement(t.p,null,"Formally, a structure ",r.createElement(l.A,{text:"\\((G, \\star)\\)"})," is a group if it satisfies the following axioms:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Closure"),": For all ",r.createElement(l.A,{text:"\\(g_1, g_2 \\in G\\)"}),", ",r.createElement(l.A,{text:"\\(g_1 \\star g_2\\)"})," is also in ",r.createElement(l.A,{text:"\\(G\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Associativity"),": For all ",r.createElement(l.A,{text:"\\(g_1, g_2, g_3 \\in G\\)"}),", ",r.createElement(l.A,{text:"\\((g_1 \\star g_2) \\star g_3 = g_1 \\star (g_2 \\star g_3)\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Identity element"),": There exists an identity element ",r.createElement(l.A,{text:"\\(e \\in G\\)"})," such that for all ",r.createElement(l.A,{text:"\\(g \\in G\\)"}),", ",r.createElement(l.A,{text:"\\(e \\star g = g \\star e = g\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Inverse elements"),": For every ",r.createElement(l.A,{text:"\\(g \\in G\\)"}),", there exists an inverse ",r.createElement(l.A,{text:"\\(g^{-1} \\in G\\)"})," such that ",r.createElement(l.A,{text:"\\(g \\star g^{-1} = g^{-1} \\star g = e\\)"}),"."),"\n"),"\n",r.createElement(t.p,null,'Conceptually, one can think of a group as the mathematical encapsulation of the idea of "transformations" or "symmetries" that can be composed in a consistent manner, with a do-nothing transformation (',r.createElement(l.A,{text:"\\(e\\)"}),") as identity, and the ability to undo every transformation (",r.createElement(l.A,{text:"\\(g^{-1}\\)"}),")."),"\n",r.createElement(t.h4,{id:"subgroups-and-cosets-brief-mention",style:{position:"relative"}},r.createElement(t.a,{href:"#subgroups-and-cosets-brief-mention","aria-label":"subgroups and cosets brief mention permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Subgroups and cosets (brief mention)"),"\n",r.createElement(t.p,null,"A ",r.createElement(o.A,null,"subgroup")," ",r.createElement(l.A,{text:"\\(H\\)"})," of a group ",r.createElement(l.A,{text:"\\(G\\)"})," is a subset of ",r.createElement(l.A,{text:"\\(G\\)"})," that itself forms a group under the inherited operation. For example, in the group of all integer additions ",r.createElement(l.A,{text:"\\((\\mathbb{Z}, +)\\)"}),", the set of even integers ",r.createElement(l.A,{text:"\\(2\\mathbb{Z}\\)"})," is a subgroup. Subgroups are important because they often represent restricted sets of transformations that still maintain closure under the operation."),"\n",r.createElement(t.p,null,"A related concept is the notion of a ",r.createElement(o.A,null,"coset"),". Given ",r.createElement(l.A,{text:"\\(H\\subseteq G\\)"})," a subgroup of ",r.createElement(l.A,{text:"\\(G\\)"})," and an element ",r.createElement(l.A,{text:"\\(g \\in G\\)"}),", the left coset of ",r.createElement(l.A,{text:"\\(H\\)"})," with respect to ",r.createElement(l.A,{text:"\\(g\\)"})," is ",r.createElement(l.A,{text:"\\(gH = \\{ g h : h \\in H \\}\\)"}),". Cosets arise often in group theory when analyzing factor groups, but here, it suffices to keep in mind that cosets let you partition a group into distinct equivalence classes under the subgroup ",r.createElement(l.A,{text:"\\(H\\)"}),". While subgroups and cosets are not the focus of typical ML-based group theory applications, they do play a role in certain advanced constructions (e.g., factor-group-based representations)."),"\n",r.createElement(t.h3,{id:"examples-of-groups",style:{position:"relative"}},r.createElement(t.a,{href:"#examples-of-groups","aria-label":"examples of groups permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Examples of groups"),"\n",r.createElement(t.p,null,"There are many classes of groups, but a few show up constantly in ML. One can categorize them by whether they are finite or infinite, abelian (commutative) or non-abelian (non-commutative), discrete or continuous (Lie groups), etc. Let me highlight some representative examples."),"\n",r.createElement(t.h4,{id:"cyclic-groups-eg-",style:{position:"relative"}},r.createElement(t.a,{href:"#cyclic-groups-eg-","aria-label":"cyclic groups eg  permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Cyclic groups (e.g., ",r.createElement(l.A,{text:"\\(C_n\\)"}),")"),"\n",r.createElement(t.p,null,"A ",r.createElement(o.A,null,"cyclic group")," is generated by a single element. A popular instance is ",r.createElement(l.A,{text:"\\(C_n\\)"}),", the group of ",r.createElement(i.A,{text:"rotations mod n"}),". If we imagine rotating a 2D object by ",r.createElement(l.A,{text:"\\(\\frac{360^\\circ}{n}\\)"})," increments, the group ",r.createElement(l.A,{text:"\\(C_n\\)"})," has exactly ",r.createElement(l.A,{text:"\\(n\\)"})," elements: 0°, ",r.createElement(l.A,{text:"\\( \\frac{360^\\circ}{n}\\)"}),", ",r.createElement(l.A,{text:"\\(2\\frac{360^\\circ}{n}\\)"}),", …, ",r.createElement(l.A,{text:"\\( (n-1)\\frac{360^\\circ}{n} \\)"}),". The group operation is composition of these rotations; closure follows from how angles add up mod ",r.createElement(l.A,{text:"\\(360^\\circ\\)"})," (or mod ",r.createElement(l.A,{text:"\\(2\\pi\\)"})," in radians). This is a finite, abelian group."),"\n",r.createElement(t.p,null,"Cyclic groups are conceptually among the easiest to understand. In ML contexts, one might consider ",r.createElement(l.A,{text:"\\(C_4\\)"})," to represent 90°-rotation symmetries of an image. If a network is designed to be invariant or equivariant under these transformations, it might be effectively encoding or learning a representation of the group ",r.createElement(l.A,{text:"\\(C_4\\)"}),"."),"\n",r.createElement(t.h4,{id:"dihedral-groups-",style:{position:"relative"}},r.createElement(t.a,{href:"#dihedral-groups-","aria-label":"dihedral groups  permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Dihedral groups (",r.createElement(l.A,{text:"\\(D_n\\)"}),")"),"\n",r.createElement(t.p,null,r.createElement(o.A,null,"Dihedral groups")," can be viewed as the symmetry groups of a regular n-gon, consisting of both rotations and reflections. ",r.createElement(l.A,{text:"\\(D_n\\)"})," has ",r.createElement(l.A,{text:"\\(2n\\)"})," elements: ",r.createElement(l.A,{text:"\\(n\\)"})," rotations and ",r.createElement(l.A,{text:"\\(n\\)"})," reflections. If you imagine a square, ",r.createElement(l.A,{text:"\\(D_4\\)"})," includes the identity (do nothing), rotate by 90°, rotate by 180°, rotate by 270°, and then reflections about axes (vertical, horizontal, main diagonal, secondary diagonal in the square case). This group is finite but not abelian (a reflection followed by a rotation does not produce the same transformation as the same rotation followed by that reflection)."),"\n",r.createElement(t.p,null,"In ML, dihedral group symmetries appear when both rotations and flips matter for a system (like an image classification model that needs to treat a shape or pattern the same under certain reflections). Depending on the domain, dihedral transformations can significantly reduce the effective variability in the data."),"\n",r.createElement(t.h4,{id:"special-orthogonal-groups-so2-so3",style:{position:"relative"}},r.createElement(t.a,{href:"#special-orthogonal-groups-so2-so3","aria-label":"special orthogonal groups so2 so3 permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Special orthogonal groups SO(2), SO(3)"),"\n",r.createElement(t.p,null,"A ",r.createElement(o.A,null,"special orthogonal group"),", ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(n)\\)"}),", consists of ",r.createElement(i.A,{text:"all n x n orthogonal matrices with determinant +1"}),". For instance, ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," is the group of all 2D rotation matrices"),"\n",r.createElement(l.A,{text:"\\[\nR(\\theta) = \\begin{pmatrix}\n\\cos(\\theta) & -\\sin(\\theta) \\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{pmatrix},\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(\\theta\\)"})," ranges over all real values (usually taken mod ",r.createElement(l.A,{text:"\\(2\\pi\\)"}),", but it is effectively a continuous parameter). ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"})," is the group of all 3D rotation matrices with determinant 1. These groups are ",r.createElement(o.A,null,"compact Lie groups")," and are extremely important in 2D and 3D geometry, robotics, and computer vision (where orientation and rotation in space is crucial)."),"\n",r.createElement(t.p,null,"Machine learning systems that involve rotational invariance in images or point clouds often revolve around ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," or ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),". These are infinite (and uncountable) groups, so the representation theory and analysis is necessarily more advanced than for finite groups."),"\n",r.createElement(t.h4,{id:"orthogonal-group-o2",style:{position:"relative"}},r.createElement(t.a,{href:"#orthogonal-group-o2","aria-label":"orthogonal group o2 permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Orthogonal group O(2)"),"\n",r.createElement(t.p,null,r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," is the group of all 2D orthogonal transformations, which include both rotations and reflections. Formally, ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," is the set of all matrices ",r.createElement(l.A,{text:"\\(M\\)"})," such that ",r.createElement(l.A,{text:"\\(M^\\top M = I\\)"}),", with determinant ±1. The subset with determinant +1 is ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),", so ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," is effectively ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\cup\\)"})," reflection transformations. The presence of reflections means ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," is also non-abelian, while ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," is abelian (rotations commute in 2D)."),"\n",r.createElement(t.p,null,"In computer vision, 2D reflection might correspond to flipping an image about an axis. If a problem demands invariance or equivariance to flips and rotations of the plane, ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," captures that entire continuous set of transformations."),"\n",r.createElement(t.h2,{id:"representation-theory-basics",style:{position:"relative"}},r.createElement(t.a,{href:"#representation-theory-basics","aria-label":"representation theory basics permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Representation theory basics"),"\n",r.createElement(t.p,null,"One of the crowning achievements of modern algebra is ",r.createElement(o.A,null,"representation theory"),", which lets one encode abstract groups as linear transformations on vector spaces. Representation theory provides a powerful handle on how to exploit symmetries and group structures in practical scenarios — especially relevant when building neural networks that need to respect certain invariances."),"\n",r.createElement(t.h3,{id:"what-is-a-representation",style:{position:"relative"}},r.createElement(t.a,{href:"#what-is-a-representation","aria-label":"what is a representation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"What is a representation?"),"\n",r.createElement(t.p,null,"A ",r.createElement(o.A,null,"representation")," of a group ",r.createElement(l.A,{text:"\\(G\\)"})," on a vector space ",r.createElement(l.A,{text:"\\(V\\)"})," (over the real or complex field, though complex fields are more standard in representation theory) is a group homomorphism"),"\n",r.createElement(l.A,{text:"\\[\n\\rho: G \\to GL(V),\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(GL(V)\\)"})," is the group of all invertible linear transformations on ",r.createElement(l.A,{text:"\\(V\\)"}),". Intuitively, each element of ",r.createElement(l.A,{text:"\\(G\\)"})," is mapped to an invertible linear operator on ",r.createElement(l.A,{text:"\\(V\\)"}),". The group homomorphism condition requires"),"\n",r.createElement(l.A,{text:"\\[\n\\rho(g_1 g_2) = \\rho(g_1) \\rho(g_2),\n\\]"}),"\n",r.createElement(t.p,null,"meaning that composing two group transformations corresponds to composing the linear transformations on the vector space."),"\n",r.createElement(t.p,null,"If ",r.createElement(l.A,{text:"\\(V\\)"})," is finite-dimensional, these linear transformations can be represented by invertible matrices, so we can think of a representation as a map from group elements to invertible matrices that respect the group operation. For infinite-dimensional scenarios (e.g., function spaces), the idea is analogous but the mathematics become more intricate."),"\n",r.createElement(t.h4,{id:"dimension-matrix-representations-and-change-of-basis",style:{position:"relative"}},r.createElement(t.a,{href:"#dimension-matrix-representations-and-change-of-basis","aria-label":"dimension matrix representations and change of basis permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Dimension, matrix representations, and change of basis"),"\n",r.createElement(t.p,null,"If ",r.createElement(l.A,{text:"\\(V\\)"})," has dimension ",r.createElement(l.A,{text:"\\(d\\)"}),", then ",r.createElement(l.A,{text:"\\(\\rho(g)\\)"})," is a ",r.createElement(l.A,{text:"\\(d \\times d\\)"})," invertible matrix for each ",r.createElement(l.A,{text:"\\(g\\)"}),". One must note that if we pick a different basis for ",r.createElement(l.A,{text:"\\(V\\)"}),", the matrices describing the same representation will look different, but they still represent the same homomorphism. In representation theory, a key concept is that two representations ",r.createElement(l.A,{text:"\\(\\rho_1\\)"})," and ",r.createElement(l.A,{text:"\\(\\rho_2\\)"})," are ",r.createElement(o.A,null,"equivalent")," (or isomorphic) if there is a change of basis in ",r.createElement(l.A,{text:"\\(V\\)"})," that transforms one into the other."),"\n",r.createElement(t.h3,{id:"key-types-of-representations",style:{position:"relative"}},r.createElement(t.a,{href:"#key-types-of-representations","aria-label":"key types of representations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Key types of representations"),"\n",r.createElement(t.p,null,"Several fundamental types of representations appear throughout mathematics and have direct analogies in ML contexts as well."),"\n",r.createElement(t.h4,{id:"trivial-representation",style:{position:"relative"}},r.createElement(t.a,{href:"#trivial-representation","aria-label":"trivial representation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Trivial representation"),"\n",r.createElement(t.p,null,"The ",r.createElement(o.A,null,"trivial representation")," maps every group element ",r.createElement(l.A,{text:"\\(g\\)"})," to the identity transformation on ",r.createElement(l.A,{text:"\\(V\\)"}),". In matrix form, that means ",r.createElement(l.A,{text:"\\(\\rho(g) = I\\)"})," for all ",r.createElement(l.A,{text:"\\(g\\)"}),'. This representation effectively "ignores" the group structure, but it is often a building block for more interesting representations or used as a baseline reference.'),"\n",r.createElement(t.h4,{id:"regular-representation",style:{position:"relative"}},r.createElement(t.a,{href:"#regular-representation","aria-label":"regular representation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Regular representation"),"\n",r.createElement(t.p,null,"The ",r.createElement(o.A,null,"regular representation")," is especially important for finite groups. Suppose ",r.createElement(l.A,{text:"\\(G\\)"})," is finite with ",r.createElement(l.A,{text:"\\(|G|\\)"})," elements, and we consider ",r.createElement(l.A,{text:"\\(\\mathbb{R}^{|G|}\\)"})," (or ",r.createElement(l.A,{text:"\\(\\mathbb{C}^{|G|}\\)"}),"). Label the coordinates of a vector in this space by the elements of ",r.createElement(l.A,{text:"\\(G\\)"}),". Then the regular representation ",r.createElement(l.A,{text:"\\(\\rho\\)"})," is defined by letting ",r.createElement(l.A,{text:"\\(g\\)"})," permute the coordinates according to left multiplication (or right multiplication) on the set ",r.createElement(l.A,{text:"\\(G\\)"}),". In other words, if ",r.createElement(l.A,{text:"\\(\\delta_h\\)"})," is the basis vector that is 1 in position ",r.createElement(l.A,{text:"\\(h\\)"})," and 0 elsewhere, then"),"\n",r.createElement(l.A,{text:"\\[\n\\rho(g)(\\delta_h) = \\delta_{g h}.\n\\]"}),"\n",r.createElement(t.p,null,"This representation is typically high-dimensional, but crucially it contains every possible irreducible representation of ",r.createElement(l.A,{text:"\\(G\\)"})," as a sub-representation. In ML, the regular representation can appear when we think of feature vectors indexed by group elements or data transformations."),"\n",r.createElement(t.h4,{id:"irreducible-representations-irreps",style:{position:"relative"}},r.createElement(t.a,{href:"#irreducible-representations-irreps","aria-label":"irreducible representations irreps permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Irreducible representations (irreps)"),"\n",r.createElement(t.p,null,"A representation is ",r.createElement(o.A,null,"irreducible")," (or ",r.createElement(o.A,null,"simple"),") if it contains no nontrivial sub-representations. By Maschke's theorem (for finite groups over ",r.createElement(l.A,{text:"\\(\\mathbb{C}\\)"})," and a broad class of other settings), every finite-dimensional representation of a finite group can be decomposed as a direct sum of irreducible representations (often abbreviated as irreps). This implies that understanding all irreps is paramount to understanding every possible representation of a group."),"\n",r.createElement(t.p,null,'From a machine learning vantage point, irreps are sometimes viewed as the fundamental "building blocks" of any representation. For continuous groups (like ',r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),", ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),"), the classification of irreps can be more complicated but still follows a systematic theory (e.g., spherical harmonics as irreps for ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),")."),"\n",r.createElement(t.h3,{id:"equivalence-of-representations",style:{position:"relative"}},r.createElement(t.a,{href:"#equivalence-of-representations","aria-label":"equivalence of representations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Equivalence of representations"),"\n",r.createElement(t.p,null,"As mentioned, two representations ",r.createElement(l.A,{text:"\\(\\rho_1, \\rho_2\\)"})," are called ",r.createElement(o.A,null,"equivalent")," if there is an invertible linear map ",r.createElement(l.A,{text:"\\(T\\)"})," such that"),"\n",r.createElement(l.A,{text:"\\[\n\\rho_2(g) = T \\rho_1(g) T^{-1}\n\\]"}),"\n",r.createElement(t.p,null,"for all ",r.createElement(l.A,{text:"\\(g \\in G\\)"}),". This ",r.createElement(l.A,{text:"\\(T\\)"}),' is effectively a change-of-basis transformation. If two representations are equivalent, they are essentially the "same" from the standpoint of group theory, just expressed in different coordinate systems.'),"\n",r.createElement(t.h4,{id:"isomorphic-vs-non-isomorphic-irreps",style:{position:"relative"}},r.createElement(t.a,{href:"#isomorphic-vs-non-isomorphic-irreps","aria-label":"isomorphic vs non isomorphic irreps permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Isomorphic vs. non-isomorphic irreps"),"\n",r.createElement(t.p,null,"If two irreps are equivalent, we say they are ",r.createElement(o.A,null,"isomorphic"),". If they are not, we say they are ",r.createElement(o.A,null,"non-isomorphic"),". Identifying all non-isomorphic irreps of a group ",r.createElement(l.A,{text:"\\(G\\)"})," is a major goal in classical representation theory and also emerges in advanced ML frameworks that utilize group-based transformations. Indeed, implementing group-equivariant architectures can involve selecting appropriate irreps for the group at hand so that one's network operations transform in a consistent manner."),"\n",r.createElement(t.h2,{id:"group-actions-on-functions",style:{position:"relative"}},r.createElement(t.a,{href:"#group-actions-on-functions","aria-label":"group actions on functions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Group actions on functions"),"\n",r.createElement(t.p,null,'The most ubiquitous way that a group can "show up" in a functional or ML context is by ',r.createElement(o.A,null,"acting")," on functions. In classical analysis, we often think of functions as living in a vector space (like ",r.createElement(l.A,{text:"\\(L^2(\\text{some domain})\\)"}),") and letting the group elements ",r.createElement(l.A,{text:"\\(g\\)"})," transform the input of these functions, thus yielding a new function. This perspective eventually ties into the concept of group convolution, group Fourier transforms, and more."),"\n",r.createElement(t.h3,{id:"left-regular-action",style:{position:"relative"}},r.createElement(t.a,{href:"#left-regular-action","aria-label":"left regular action permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Left-regular action"),"\n",r.createElement(t.p,null,"For a finite group ",r.createElement(l.A,{text:"\\(G\\)"}),", define a space of real-valued (or complex-valued) functions on ",r.createElement(l.A,{text:"\\(G\\)"})," by"),"\n",r.createElement(l.A,{text:"\\[\nV = \\{ f \\mid f : G \\to \\mathbb{R} \\}.\n\\]"}),"\n",r.createElement(t.p,null,"An element ",r.createElement(l.A,{text:"\\(g \\in G\\)"})," can act on a function ",r.createElement(l.A,{text:"\\(f\\)"})," by"),"\n",r.createElement(l.A,{text:"\\[\n(g \\cdot f)(x) = f(g^{-1} x).\n\\]"}),"\n",r.createElement(t.p,null,"This is known as the ",r.createElement(o.A,null,"left-regular action"),". In effect, we have a representation ",r.createElement(l.A,{text:"\\(\\rho\\)"})," of ",r.createElement(l.A,{text:"\\(G\\)"})," on ",r.createElement(l.A,{text:"\\(V\\)"})," given by"),"\n",r.createElement(l.A,{text:"\\[\n\\rho(g): V \\to V, \\quad [\\rho(g)(f)](x) = f(g^{-1} x).\n\\]"}),"\n",r.createElement(t.p,null,"One can check that ",r.createElement(l.A,{text:"\\(\\rho(g_1 g_2) = \\rho(g_1)\\rho(g_2)\\)"})," holds. This is the function-space version of the regular representation described earlier."),"\n",r.createElement(t.h3,{id:"functions-as-vectors",style:{position:"relative"}},r.createElement(t.a,{href:"#functions-as-vectors","aria-label":"functions as vectors permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Functions as vectors"),"\n",r.createElement(t.p,null,"When ",r.createElement(l.A,{text:"\\(G\\)"})," is finite, ",r.createElement(l.A,{text:"\\(\\mathbb{R}^{|G|}\\)"})," is isomorphic to the vector space of functions on ",r.createElement(l.A,{text:"\\(G\\)"})," (since a function ",r.createElement(l.A,{text:"\\(f\\)"})," on ",r.createElement(l.A,{text:"\\(G\\)"})," can be identified with a vector of length ",r.createElement(l.A,{text:"\\(|G|\\)"})," whose entries are ",r.createElement(l.A,{text:"\\(f(g)\\)"})," for each ",r.createElement(l.A,{text:"\\(g\\in G\\)"}),"). The left-regular action then becomes a permutation of coordinates, precisely the same as the regular representation in matrix form. This viewpoint is extremely helpful when building group-equivariant layers in neural networks, where each channel or index might correspond to a group element."),"\n",r.createElement(t.h3,{id:"extension-to-continuous-groups",style:{position:"relative"}},r.createElement(t.a,{href:"#extension-to-continuous-groups","aria-label":"extension to continuous groups permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Extension to continuous groups"),"\n",r.createElement(t.p,null,"For ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),", ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),", ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"}),", and other continuous (Lie) groups, the same idea holds conceptually:"),"\n",r.createElement(l.A,{text:"\\[\n(g \\cdot f)(x) = f(g^{-1} \\cdot x),\n\\]"}),"\n",r.createElement(t.p,null,"except now ",r.createElement(l.A,{text:"\\(f\\)"})," is usually defined on a continuous domain and ",r.createElement(l.A,{text:"\\(x\\)"})," might be a point in ",r.createElement(l.A,{text:"\\(\\mathbb{R}^n\\)"})," or on a manifold. Summations are replaced by integrals, and one has to deal with measure theory, completeness, or other functional-analytic details (which can become very rich). Nonetheless, the overarching concept — a group transforming the argument of a function — remains consistent. From the perspective of ML, if an image is a function ",r.createElement(l.A,{text:"\\(\\mathbb{R}^2 \\to \\mathbb{R}\\)"})," (or ",r.createElement(l.A,{text:"\\(\\mathbb{R}^2 \\to \\mathbb{R}^3\\)"})," for an RGB image), then a rotation ",r.createElement(l.A,{text:"\\(\\theta\\)"})," in ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," produces a new image ",r.createElement(l.A,{text:"\\(I'\\)"})," such that ",r.createElement(l.A,{text:"\\(I'(x) = I(R(\\theta)^{-1} x)\\)"}),"."),"\n",r.createElement(t.h2,{id:"fourier-theory-on-groups-peterweyl-theorem",style:{position:"relative"}},r.createElement(t.a,{href:"#fourier-theory-on-groups-peterweyl-theorem","aria-label":"fourier theory on groups peterweyl theorem permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Fourier theory on groups (Peter–Weyl theorem)"),"\n",r.createElement(t.h3,{id:"motivation-and-intuition",style:{position:"relative"}},r.createElement(t.a,{href:"#motivation-and-intuition","aria-label":"motivation and intuition permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Motivation and intuition"),"\n",r.createElement(t.p,null,"The classical Fourier transform decomposes periodic functions on the circle (",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," or the unit circle in the complex plane) into sums of sines and cosines. Likewise, the discrete Fourier transform decomposes functions on a finite cyclic group ",r.createElement(l.A,{text:"\\(C_n\\)"}),". But these ideas generalize dramatically: ",r.createElement(o.A,null,"Fourier theory on groups"),' is the framework by which one can decompose functions into "harmonic components" that correspond to irreducible representations of the group. This is often called ',r.createElement(i.A,{text:"Non-commutative harmonic analysis"})," when dealing with non-abelian groups."),"\n",r.createElement(t.p,null,"In machine learning, especially in architectures that strive to be ",r.createElement(o.A,null,"equivariant")," under group transformations, one frequently uses the fact that ",r.createElement(l.A,{text:"\\(G\\)"}),'-equivariant operations can be expressed in the "Fourier domain" on ',r.createElement(l.A,{text:"\\(G\\)"}),". For finite abelian groups, this is straightforward. For more complex or continuous groups, it can be more challenging but also quite powerful. The ",r.createElement(o.A,null,"Peter–Weyl theorem")," states that for compact groups, one obtains an orthonormal basis of ",r.createElement(l.A,{text:"\\(L^2(G)\\)"})," from the matrix entries of irreps of ",r.createElement(l.A,{text:"\\(G\\)"}),". This is a continuous analog of the idea that sums of exponentials (sines and cosines) can be used to expand periodic functions."),"\n",r.createElement(t.h3,{id:"finite-groups",style:{position:"relative"}},r.createElement(t.a,{href:"#finite-groups","aria-label":"finite groups permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Finite groups"),"\n",r.createElement(t.p,null,"For a finite group ",r.createElement(l.A,{text:"\\(G\\)"}),", the group algebra ",r.createElement(l.A,{text:"\\(\\mathbb{C}[G]\\)"})," is finite-dimensional, and the decomposition of ",r.createElement(l.A,{text:"\\(\\mathbb{C}[G]\\)"})," into irreps is effectively a direct sum of sub-representations. The ",r.createElement(o.A,null,"Fourier transform")," on ",r.createElement(l.A,{text:"\\(G\\)"})," is, in that sense, mapping a function ",r.createElement(l.A,{text:"\\(f\\)"})," on ",r.createElement(l.A,{text:"\\(G\\)"})," to its coefficients in each irreducible representation's coordinate system. Formally, for a function"),"\n",r.createElement(l.A,{text:"\\[\nf : G \\to \\mathbb{C},\n\\]"}),"\n",r.createElement(t.p,null,"its group Fourier transform is a collection of matrices (one per each irreducible representation) capturing how ",r.createElement(l.A,{text:"\\(f\\)"})," projects onto that irrep."),"\n",r.createElement(t.p,null,"An ",r.createElement(o.A,null,"inverse Fourier transform")," then reconstructs ",r.createElement(l.A,{text:"\\(f\\)"})," from these matrix coefficients. Orthogonality relations of characters (the trace of irreps) and other representation-theoretic facts supply the explicit formula. The net result is that for a function on a finite group ",r.createElement(l.A,{text:"\\(G\\)"}),', one can shift from the "time domain" (or direct domain) into the "frequency domain" given by irreps — exactly paralleling classical discrete Fourier analysis on ',r.createElement(l.A,{text:"\\(C_n\\)"}),"."),"\n",r.createElement(t.h3,{id:"continuous-compact-groups",style:{position:"relative"}},r.createElement(t.a,{href:"#continuous-compact-groups","aria-label":"continuous compact groups permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Continuous (compact) groups"),"\n",r.createElement(t.p,null,"For compact Lie groups like ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),", ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),", or more general ",r.createElement(l.A,{text:"\\(\\mathrm{SU}(n)\\)"}),", the ",r.createElement(o.A,null,"Peter–Weyl theorem")," states that the matrix coefficients of irreps span an orthonormal basis for ",r.createElement(l.A,{text:"\\(L^2(G)\\)"}),". Concretely, consider ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),": it is isomorphic to the unit circle, so the irreps are the standard one-dimensional representations ",r.createElement(l.A,{text:"\\(e^{ik\\theta}\\)"})," (with ",r.createElement(l.A,{text:"\\(k \\in \\mathbb{Z}\\)"}),"). Then the expansions become familiar Fourier series in sines and cosines. For ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),", the irreps are described by spherical harmonics on the 2-sphere in a certain manner, giving expansions in terms of spherical harmonics. All these expansions can be employed to handle integrals, convolutions, or define group-equivariant layers in neural networks."),"\n",r.createElement(t.h4,{id:"idea-of-band-limited-representations",style:{position:"relative"}},r.createElement(t.a,{href:"#idea-of-band-limited-representations","aria-label":"idea of band limited representations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Idea of band-limited representations"),"\n",r.createElement(t.p,null,"One intriguing notion in continuous groups is that of ",r.createElement(o.A,null,"band limitation"),": practically speaking, one never expands a function into all irreps up to infinite dimension but instead truncates at some finite set of frequencies or representation degrees. This approach is parallel to standard Fourier series where one only keeps frequencies ",r.createElement(l.A,{text:"\\(|k| \\leq K\\)"}),". In some ML contexts, especially in steerable CNNs for ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," or spherical CNNs for ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(3)\\)"}),", only a finite set of irreps is used, effectively applying a band-limited approach that often suffices for many tasks."),"\n",r.createElement(t.h3,{id:"examples",style:{position:"relative"}},r.createElement(t.a,{href:"#examples","aria-label":"examples permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Examples"),"\n",r.createElement(t.p,null,"A canonical example is the ",r.createElement(o.A,null,"Fourier series")," expansion on ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"}),". If ",r.createElement(l.A,{text:"\\(f(\\theta)\\)"})," is a function on the circle, it can be expanded as:"),"\n",r.createElement(l.A,{text:"\\[\nf(\\theta) = \\sum_{k \\in \\mathbb{Z}} a_k e^{i k \\theta},\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(a_k\\)"})," are Fourier coefficients. This is precisely the decomposition into 1D irreps of ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," (which is abelian), and these irreps are the exponentials ",r.createElement(l.A,{text:"\\(e^{i k \\theta}\\)"}),". For the ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," group (which includes reflections), the expansions become more complicated because it is non-abelian and reflection changes orientation, but the underlying principle remains that the irreps or certain sub-representations can be used to expand ",r.createElement(l.A,{text:"\\(f\\)"}),"."),"\n",r.createElement(t.h4,{id:"distinction-between--and-",style:{position:"relative"}},r.createElement(t.a,{href:"#distinction-between--and-","aria-label":"distinction between  and  permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Distinction between ",r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," and ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})),"\n",r.createElement(t.p,null,r.createElement(l.A,{text:"\\(\\mathrm{SO}(2)\\)"})," is isomorphic to the circle group, so it is abelian. ",r.createElement(l.A,{text:"\\(\\mathrm{O}(2)\\)"})," has a reflection component, making it non-abelian. For abelian groups, all irreps are 1-dimensional. For non-abelian groups, irreps have dimension > 1 (except for some special cases), so the group Fourier transform leads to matrix-valued coefficients rather than purely scalar exponentials. This difference has profound implications in how one builds group-equivariant neural networks, because the feature spaces can become multidimensional subspaces that transform according to these non-abelian irreps."),"\n",r.createElement(t.h2,{id:"connecting-to-machine-learning-theoretical-preview",style:{position:"relative"}},r.createElement(t.a,{href:"#connecting-to-machine-learning-theoretical-preview","aria-label":"connecting to machine learning theoretical preview permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Connecting to machine learning (theoretical preview)"),"\n",r.createElement(t.h3,{id:"symmetries-and-data",style:{position:"relative"}},r.createElement(t.a,{href:"#symmetries-and-data","aria-label":"symmetries and data permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Symmetries and data"),"\n",r.createElement(t.p,null,"In a typical supervised learning problem, we might collect a training set ",r.createElement(l.A,{text:"\\(\\{(x_i, y_i)\\}_{i=1}^N\\)"}),". If there is a group ",r.createElement(l.A,{text:"\\(G\\)"})," of transformations such that ",r.createElement(l.A,{text:"\\(g \\cdot x_i\\)"})," has the same label as ",r.createElement(l.A,{text:"\\(x_i\\)"})," (invariance) or at least transforms in a predictable manner (equivariance), then the learning algorithm can exploit this knowledge. For instance, if ",r.createElement(l.A,{text:"\\(G\\)"})," is a group of rotations of the plane and ",r.createElement(l.A,{text:"\\(\\phi\\)"})," is a classifier, then:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(o.A,null,"Invariance")," would mean ",r.createElement(l.A,{text:"\\(\\phi(g \\cdot x) = \\phi(x)\\)"})," for all ",r.createElement(l.A,{text:"\\(g\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(o.A,null,"Equivariance")," would mean ",r.createElement(l.A,{text:"\\(\\phi(g \\cdot x) = g' \\cdot \\phi(x)\\)"})," for some action of ",r.createElement(l.A,{text:"\\(G\\)"})," on the output space as well."),"\n"),"\n",r.createElement(t.p,null,"These properties reflect the notion that the group transformations do not fundamentally alter or do alter in a known manner the underlying semantic content or structure. In simpler terms, if a dog remains a dog upon rotation, then a dog classifier can be made rotation-invariant. Or if rotating a vector field in the input domain also rotates some vector features in the output domain, that is an equivariance property."),"\n",r.createElement(t.h3,{id:"data-augmentation-vs-group-based-model-design",style:{position:"relative"}},r.createElement(t.a,{href:"#data-augmentation-vs-group-based-model-design","aria-label":"data augmentation vs group based model design permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Data augmentation vs. group-based model design"),"\n",r.createElement(t.p,null,"One might achieve a certain invariance or robustness to transformations in a more brute-force way: ",r.createElement(o.A,null,"data augmentation"),". This is where one artificially enlarges the training set by including transformations of the data. While this approach often works well in practice, it can be data-intensive and might not fully leverage the underlying group structure in a theoretically optimal way."),"\n",r.createElement(t.p,null,"In contrast, ",r.createElement(o.A,null,"group-based model design")," tries to encode the transformations directly into the structure of the model. Convolutional neural networks, for instance, are automatically equivariant to translations. Similarly, ",r.createElement(l.A,{text:"G\\)"}),"-CNNs (Cohen and Welling, 2016) build in equivariance to a broader group ",r.createElement(l.A,{text:"\\(G\\)"})," (like rotations + flips, or more exotic transformations). Such an approach can lead to more parameter-efficient architectures, less reliance on extensive augmentation, and potentially better generalization to transformations unseen in the training set. This is a major reason why group theory has gained prominence in advanced ML research."),"\n",r.createElement(t.h3,{id:"preview-of-equivariance-and-invariance",style:{position:"relative"}},r.createElement(t.a,{href:"#preview-of-equivariance-and-invariance","aria-label":"preview of equivariance and invariance permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Preview of equivariance and invariance"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(o.A,null,"Invariance"),": A function ",r.createElement(l.A,{text:"\\(\\phi : X \\to Y\\)"})," is invariant to ",r.createElement(l.A,{text:"\\(G\\)"})," if ",r.createElement(l.A,{text:"\\(\\phi(g \\cdot x) = \\phi(x)\\)"})," for all ",r.createElement(l.A,{text:"\\(g\\)"})," in ",r.createElement(l.A,{text:"\\(G\\)"})," and for all ",r.createElement(l.A,{text:"\\(x\\)"})," in ",r.createElement(l.A,{text:"\\(X\\)"}),". In classification tasks, the model output is the same no matter how the input is transformed, which is often desired for transformations that do not alter semantic class identity."),"\n"),"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(o.A,null,"Equivariance"),": A function ",r.createElement(l.A,{text:"\\(\\phi : X \\to Y\\)"})," is equivariant if there is a compatible group action on the output such that ",r.createElement(l.A,{text:"\\(\\phi(g \\cdot x) = g \\cdot \\phi(x)\\)"}),". This means transformations in input space map to corresponding transformations in the feature or output space. In certain tasks (e.g., segmentation or keypoint detection), it can be crucial for the model to maintain alignment under transformations of the input."),"\n"),"\n"),"\n",r.createElement(t.p,null,"In the upcoming part of this course (pt. 2), these notions are made operational in neural networks using the language of representation theory. One typically picks an appropriate set of irreps or representation spaces in which convolutional kernels or filters are defined, ensuring the entire network is ",r.createElement(l.A,{text:"\\(G\\)"}),"-equivariant by design."),"\n",r.createElement(t.h3,{id:"foundations-for-part-2",style:{position:"relative"}},r.createElement(t.a,{href:"#foundations-for-part-2","aria-label":"foundations for part 2 permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Foundations for part 2"),"\n",r.createElement(t.p,null,"The second part will dive deeper into how representation theory underpins group convolutions, as well as the concept of ",r.createElement(o.A,null,"steerable CNNs"),'. Steerability is a property wherein filters can be "steered" to arbitrary orientations or transformations by applying a small set of basis filters and combining their responses appropriately. This approach is deeply connected to the idea that a filter might transform according to some (usually low-dimensional) representation of the group. The subspace spanned by those basis filters forms an irrep or direct sum of irreps. Then, to get a rotated version of the filter, one applies a matrix from the representation. This is a practical manifestation of advanced group theoretic ideas.'),"\n",r.createElement(t.p,null,"Hence, everything from building group equivariant layers to analyzing how data transforms in these spaces relies on the fundamental knowledge covered in the present article: the concept of groups, their representations, and how they act on functions. Understanding these building blocks will make advanced group-based architectures more intuitive and reveal how they can drastically reduce the demands on data augmentation or brute-force enumerations of transformations."),"\n",r.createElement(t.h2,{id:"summary-and-transition",style:{position:"relative"}},r.createElement(t.a,{href:"#summary-and-transition","aria-label":"summary and transition permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Summary and transition"),"\n",r.createElement(t.p,null,"This article has explored the basic building blocks of group theory and representation theory, setting the stage for their application in modern machine learning contexts. By reviewing core definitions — closure, identity, inverses, associativity — and examining canonical examples like cyclic groups, dihedral groups, special orthogonal groups, and orthogonal groups, I have illustrated how symmetries and transformations naturally map onto group-theoretic structures. Representation theory then shows how to translate these symmetries into linear algebra operations, which is precisely the language of neural network layers and transformations in vector spaces. The discussion of group actions on functions further underscores how one passes from an abstract group definition to an actual operation on data."),"\n",r.createElement(t.p,null,'Finally, a brief tour of Fourier theory on groups (both finite and continuous) demonstrates how these transformations can be analyzed in a "frequency domain", analogously to classical Fourier analysis but generalized to non-abelian, higher-dimensional irreps. This perspective is central to certain advanced techniques in ML, such as building group-equivariant convolutional networks with a direct tie-in to irreps and non-commutative harmonic analysis.'),"\n",r.createElement(t.p,null,"Moving forward, the next steps (part 2) will expand these concepts to show how they concretely translate into group-based neural architectures, including group convolutional networks, steerable CNNs, and group equivariant autoencoders. The underlying theme remains that if the problem domain has known symmetries, harnessing group theory can fundamentally reshape how a model learns and generalizes, often leading to elegant, highly structured solutions that require fewer data and exhibit greater stability against transformations. This is one of the most exciting frontiers in theoretical and applied machine learning research, as recognized by many leading publications (e.g., Cohen and Welling, ICML 2016; Weiler and Cesa, NeurIPS 2019; Kondor and Trivedi, ICML 2018; Esteves, CVPR 2018) focusing on group equivariant network design."),"\n",r.createElement(t.p,null,"I recommend reflecting carefully on these theoretical underpinnings, because a deeper appreciation for the group-theoretic viewpoint unlocks a range of advanced architectural insights and fosters the creativity needed to design novel ML models aligned to domain symmetries."),"\n",r.createElement(n,{alt:"visual depiction of a dihedral group acting on a square",path:"",caption:"Illustration of the elements of D4 acting on a square, showing rotations and reflections.",zoom:"false"}),"\n",r.createElement(n,{alt:"diagram showing group representation as matrices",path:"",caption:"Representations map group elements to matrices that act on a vector space.",zoom:"false"}),"\n",r.createElement(s.A,{text:'\nimport numpy as np\n\ndef rotate_point_2d(x, y, theta):\n    """\n    Rotate a point (x, y) by angle theta (in radians) about the origin.\n    Returns the new coordinates (x\', y\').\n    """\n    cos_t = np.cos(theta)\n    sin_t = np.sin(theta)\n    x_new = x*cos_t - y*sin_t\n    y_new = x*sin_t + y*cos_t\n    return x_new, y_new\n\ndef dihedral_group_actions(square_points):\n    """\n    Given four points of a square (in CCW order),\n    return all the transformations from the dihedral group D4\n    (the symmetry group of a square).\n    Each transformation is represented as a list of points after transformation.\n    """\n    transformations = []\n    # Rotations: 0, 90, 180, 270\n    for r in [0, np.pi/2, np.pi, 3*np.pi/2]:\n        rot_points = [rotate_point_2d(px, py, r) for (px, py) in square_points]\n        transformations.append(rot_points)\n    # Reflections: reflect over x-axis, y-axis, y=x, y=-x (for example)\n    # x-axis reflection\n    refl_x = [(px, -py) for (px, py) in square_points]\n    transformations.append(refl_x)\n    # y-axis reflection\n    refl_y = [(-px, py) for (px, py) in square_points]\n    transformations.append(refl_y)\n    # reflection over y=x\n    refl_diag1 = [(py, px) for (px, py) in square_points]\n    transformations.append(refl_diag1)\n    # reflection over y=-x\n    refl_diag2 = [(-py, -px) for (px, py) in square_points]\n    transformations.append(refl_diag2)\n    \n    return transformations\n\n# Example usage:\nsquare = [(1,1), (1,-1), (-1,-1), (-1,1)]  # corners of a square\nd4_actions = dihedral_group_actions(square)\n\nprint("All D4 transformations of the square (each element is a list of points):")\nfor i, t in enumerate(d4_actions):\n    print(f"Transformation {i}: {t}")\n'}),"\n",r.createElement(t.p,null,"In the snippet above, I provide a quick demonstration of how one might generate all transformations in the dihedral group ",r.createElement(l.A,{text:"\\(D_4\\)"})," (symmetries of a square) in a simple Python setting. Although this example is purely geometric, it reflects the fundamental operations that more advanced group-aware ML models will rely upon — but often in a more algebraic or representation-theoretic guise. By bridging geometry and algebra, group theory remains a unifying theme in the modern machine learning toolbox."))}var m=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,a.RP)(),e.components);return t?r.createElement(t,e,r.createElement(c,e)):c(e)};var h=n(54506),p=n(88864),u=n(58481),d=n.n(u),f=n(5984),g=n(43672),v=n(27042),y=n(72031),E=n(81817),b=n(27105),x=n(17265),w=n(2043),A=n(95751),S=n(94328),M=n(80791),C=n(78137);const H=e=>{let{toc:t}=e;if(!t||!t.items)return null;return r.createElement("nav",{className:M.R},r.createElement("ul",null,t.items.map(((e,t)=>r.createElement("li",{key:t},r.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const n=t.replace("#",""),a=document.getElementById(n);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&r.createElement(H,{toc:{items:e.items}}))))))};function _(e){let{data:{mdx:t,allMdx:i,allPostImages:o},children:s}=e;const{frontmatter:l,body:c,tableOfContents:m}=t,p=l.index,u=l.slug.split("/")[1],y=i.nodes.filter((e=>e.frontmatter.slug.includes(`/${u}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),M=y.findIndex((e=>e.frontmatter.index===p)),_=y[M+1],L=y[M-1],T=l.slug.replace(/\/$/,""),k=/[^/]*$/.exec(T)[0],z=`posts/${u}/content/${k}/`,{0:I,1:N}=(0,r.useState)(l.flagWideLayoutByDefault),{0:V,1:G}=(0,r.useState)(!1);var j;(0,r.useEffect)((()=>{G(!0);const e=setTimeout((()=>G(!1)),340);return()=>clearTimeout(e)}),[I]),"adventures"===u?j=x.cb:"research"===u?j=x.Qh:"thoughts"===u&&(j=x.T6);const O=d()(c).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,D=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),n=e%60;return n<=30?`~${t}${n>0?".5":""} h`:`~${t+1} h`}(Math.ceil(O/j)+(l.extraReadTimeMin||0)),B=[{flag:l.flagDraft,component:()=>Promise.all([n.e(5850),n.e(9833)]).then(n.bind(n,49833))},{flag:l.flagMindfuckery,component:()=>Promise.all([n.e(5850),n.e(7805)]).then(n.bind(n,27805))},{flag:l.flagRewrite,component:()=>Promise.all([n.e(5850),n.e(8916)]).then(n.bind(n,78916))},{flag:l.flagOffensive,component:()=>Promise.all([n.e(5850),n.e(6731)]).then(n.bind(n,49112))},{flag:l.flagProfane,component:()=>Promise.all([n.e(5850),n.e(3336)]).then(n.bind(n,83336))},{flag:l.flagMultilingual,component:()=>Promise.all([n.e(5850),n.e(2343)]).then(n.bind(n,62343))},{flag:l.flagUnreliably,component:()=>Promise.all([n.e(5850),n.e(6865)]).then(n.bind(n,11627))},{flag:l.flagPolitical,component:()=>Promise.all([n.e(5850),n.e(4417)]).then(n.bind(n,24417))},{flag:l.flagCognitohazard,component:()=>Promise.all([n.e(5850),n.e(8669)]).then(n.bind(n,18669))},{flag:l.flagHidden,component:()=>Promise.all([n.e(5850),n.e(8124)]).then(n.bind(n,48124))}],{0:q,1:F}=(0,r.useState)([]);return(0,r.useEffect)((()=>{B.forEach((e=>{let{flag:t,component:n}=e;t&&n().then((e=>{F((t=>[].concat((0,h.A)(t),[e.default])))}))}))}),[]),r.createElement(v.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},r.createElement(E.A,{postNumber:l.index,date:l.date,updated:l.updated,readTime:D,difficulty:l.difficultyLevel,title:l.title,desc:l.desc,banner:l.banner,section:u,postKey:k,isMindfuckery:l.flagMindfuckery,mainTag:l.mainTag}),r.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},l.otherTags.map(((e,t)=>r.createElement("span",{key:t,className:`noselect ${C.MW}`,style:{margin:"0 5px 5px 0"}},e)))),r.createElement("div",{className:"postBody"},r.createElement(H,{toc:m})),r.createElement("br",null),r.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},r.createElement(v.P.button,{className:`noselect ${S.pb}`,id:S.xG,onClick:()=>{N(!I)},whileTap:{scale:.93}},r.createElement(v.P.div,{className:A.DJ,key:I,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},I?"Switch to default layout":"Switch to wide layout"))),r.createElement("br",null),r.createElement("div",{className:"postBody",style:{margin:I?"0 -14%":"",maxWidth:I?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},r.createElement("div",{className:`${S.P_} ${V?S.Xn:S.qG}`},q.map(((e,t)=>r.createElement(e,{key:t}))),l.indexCourse?r.createElement(w.A,{index:l.indexCourse,category:l.courseCategoryName}):"",r.createElement(f.Z.Provider,{value:{images:o.nodes,basePath:z.replace(/\/$/,"")+"/"}},r.createElement(a.xA,{components:{Image:g.A}},s)))),r.createElement(b.A,{nextPost:_,lastPost:L,keyCurrent:k,section:u}))}function L(e){return r.createElement(_,e,r.createElement(m,e))}function T(e){var t,n,a,i,o;let{data:s}=e;const{frontmatter:l}=s.mdx,c=l.titleSEO||l.title,m=l.titleOG||c,h=l.titleTwitter||c,u=l.descSEO||l.desc,d=l.descOG||u,f=l.descTwitter||u,g=l.schemaType||"BlogPosting",v=l.keywordsSEO,E=l.date,b=l.updated||E,x=l.imageOG||(null===(t=l.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.gatsbyImageData)||void 0===a||null===(i=a.images)||void 0===i||null===(o=i.fallback)||void 0===o?void 0:o.src),w=l.imageAltOG||d,A=l.imageTwitter||x,S=l.imageAltTwitter||f,M=l.canonicalURL,C=l.flagHidden||!1,H=l.mainTag||"Posts",_=l.slug.split("/")[1]||"posts",{siteUrl:L}=(0,p.Q)(),T={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:L},{"@type":"ListItem",position:2,name:H,item:`${L}/${l.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${L}${l.slug}`}]};return r.createElement(y.A,{title:c+" - avrtt.blog",titleOG:m,titleTwitter:h,description:u,descriptionOG:d,descriptionTwitter:f,schemaType:g,keywords:v,datePublished:E,dateModified:b,imageOG:x,imageAltOG:w,imageTwitter:A,imageAltTwitter:S,canonicalUrl:M,flagHidden:C,mainTag:H,section:_,type:"article"},r.createElement("script",{type:"application/ld+json"},JSON.stringify(T)))}},90548:function(e,t,n){var a=n(96540),r=n(7978);t.A=e=>{let{text:t}=e;return a.createElement(r.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-pages-posts-research-group-theory-for-ml-mdx-1b18e1a406e15f894441.js.map