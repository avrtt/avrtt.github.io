"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[2148],{65170:function(e,t,n){n.r(t),n.d(t,{Head:function(){return M},PostTemplate:function(){return k},default:function(){return z}});var a=n(28453),r=n(96540),l=(n(61992),n(62087)),i=n(90548);function s(e){const t=Object.assign({p:"p",ol:"ol",li:"li",h2:"h2",a:"a",span:"span",h3:"h3",ul:"ul",strong:"strong",br:"br",hr:"hr"},(0,a.RP)(),e.components),{Image:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),r.createElement(r.Fragment,null,"\n",r.createElement("br"),"\n","\n","\n","\n",r.createElement(t.p,null,"In this article, i will focus on the core concepts, theoretical underpinnings, and practical implementations of recurrent neural networks (rnns). this piece is intended for individuals with substantial machine learning experience who are looking to deeply understand not only the fundamental structures of rnns, but also the reasoning behind their design, their various important modifications, and the ways in which they can be used effectively in real-world applications. i will follow the general outline below, aiming to combine a thorough theoretical discussion with plenty of practical context and references to research:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"introduction"),"\n",r.createElement(t.li,null,"fundamentals of rnn"),"\n",r.createElement(t.li,null,"lstm: long short-term memory networks"),"\n",r.createElement(t.li,null,"gru: gated recurrent units"),"\n",r.createElement(t.li,null,"bidirectional rnn"),"\n",r.createElement(t.li,null,"embedding layer"),"\n",r.createElement(t.li,null,"training and optimization"),"\n",r.createElement(t.li,null,"advanced extensions"),"\n",r.createElement(t.li,null,"case studies and applications"),"\n"),"\n",r.createElement(t.p,null,"because recurrent neural networks underpin so many sequence-based learning tasks — from language modeling and machine translation to speech recognition and time series analysis — it is especially critical to explore them in detail. i'll begin by defining rnns and setting their historical context, then move into the intricacies of how they process sequence data, including a discussion of backpropagation through time (bptt). i'll dedicate several chapters to the modern variants of rnn, notably lstm and gru, which were introduced to address challenges like vanishing and exploding gradients. these challenges, in turn, limited the depth and sequence length that basic rnns could manage."),"\n",r.createElement(t.p,null,"the article also addresses advanced extensions such as attention mechanisms (briefly, because they become especially central in transformer-based models), and combinations of rnns with convolutional layers for multi-modal sequence data. i will close by discussing real-world use cases, relevant code snippets, and references to state-of-the-art research papers."),"\n",r.createElement(t.h2,{id:"2-fundamentals-of-rnn",style:{position:"relative"}},r.createElement(t.a,{href:"#2-fundamentals-of-rnn","aria-label":"2 fundamentals of rnn permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2. fundamentals of rnn"),"\n",r.createElement(t.h3,{id:"21-definition-and-historical-context-of-recurrent-neural-networks",style:{position:"relative"}},r.createElement(t.a,{href:"#21-definition-and-historical-context-of-recurrent-neural-networks","aria-label":"21 definition and historical context of recurrent neural networks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.1 definition and historical context of recurrent neural networks"),"\n",r.createElement(t.p,null,"recurrent neural networks are a class of artificial neural networks designed to capture temporal or sequential patterns in data. unlike feed-forward networks, where signals only travel in one direction (from input to hidden layers to output layers), rnns contain recurrent (or feedback) connections that can pass information from one time step to the next. this allows rnns to maintain a form of internal state that can, in principle, store information about previous inputs and thereby handle variable-length sequences."),"\n",r.createElement(t.p,null,"the earliest formulations of rnns date back to the 1980s and 1990s. two notable early architectures include:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"elman networks"),': introduced by jeff elman, these networks have a "context" layer that stores a copy of the hidden layer\'s previous state. the hidden state at time ',r.createElement(i.A,{text:"\\(t\\)"})," therefore depends on both the input at time ",r.createElement(i.A,{text:"\\(x_t\\)"})," and the hidden state at ",r.createElement(i.A,{text:"\\(t-1\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"jordan networks"),": introduced by michael jordan, these have recurrent connections from the output layer to a set of context units, which feed into the hidden layer."),"\n"),"\n",r.createElement(t.p,null,'in modern usage, these older forms of recurrent networks are collectively referred to as "simple rnns" or "vanilla rnns." while conceptually straightforward, they exhibit significant difficulties in practice when processing long sequences due to exploding and vanishing gradients (problems discussed more thoroughly in chapter 2.5). hence, later researchers, notably hochreiter and schmidhuber (1997), introduced the lstm architecture. cho and gang (2014) proposed the gated recurrent unit (gru) variant, which similarly addresses the limitations of simple rnns.'),"\n",r.createElement(t.h3,{id:"22-importance-of-sequence-modeling-in-machine-learning",style:{position:"relative"}},r.createElement(t.a,{href:"#22-importance-of-sequence-modeling-in-machine-learning","aria-label":"22 importance of sequence modeling in machine learning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.2 importance of sequence modeling in machine learning"),"\n",r.createElement(t.p,null,"sequence modeling is central to many tasks:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"language modeling"),": words or tokens in a text are processed sequentially."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"speech recognition"),": audio waveforms are inherently sequential in time."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"time series analysis"),": from financial forecasting to industrial sensor monitoring, the data are temporal."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"music generation"),": notes unfold over time, each depending on the context of preceding notes."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"video processing"),": frames in video are sequential with temporal dependencies, though many modern approaches rely on 3d convolutions or transformers as well."),"\n"),"\n",r.createElement(t.p,null,"the unique advantage of rnns is their parameter sharing across different time steps. in a feed-forward network, each input dimension might be associated with a separate set of weights, but in rnns, the same recurrent weight matrices are reused at each time step, capturing patterns that shift in time."),"\n",r.createElement(t.h3,{id:"23-core-rnn-architecture",style:{position:"relative"}},r.createElement(t.a,{href:"#23-core-rnn-architecture","aria-label":"23 core rnn architecture permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.3 core rnn architecture"),"\n",r.createElement(t.p,null,"a simple rnn cell transforms an input ",r.createElement(i.A,{text:"\\(x_t\\)"})," and a hidden state ",r.createElement(i.A,{text:"\\(h_{t-1}\\)"})," from the previous time step into the next hidden state ",r.createElement(i.A,{text:"\\(h_t\\)"})," using a function such as"),"\n",r.createElement(i.A,{text:"\\[\nh_t = \\sigma(W_{hh} \\, h_{t-1} + W_{xh} \\, x_t + b_h),\n\\]"}),"\n",r.createElement(t.p,null,"where:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(i.A,{text:"\\(W_{hh}\\)"})," is the recurrent weight matrix that connects the hidden state from ",r.createElement(i.A,{text:"\\(t-1\\)"})," to the hidden state at time ",r.createElement(i.A,{text:"\\(t\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(i.A,{text:"\\(W_{xh}\\)"})," is the input-to-hidden weight matrix."),"\n",r.createElement(t.li,null,r.createElement(i.A,{text:"\\(b_h\\)"})," is the bias vector."),"\n",r.createElement(t.li,null,r.createElement(i.A,{text:"\\(\\sigma(\\cdot)\\)"})," is typically a nonlinear activation function like ",r.createElement(i.A,{text:"(\\tanh)"})," or ",r.createElement(i.A,{text:"(\\mathrm{ReLU})"}),"."),"\n"),"\n",r.createElement(t.p,null,"this is the minimal building block. in a classification problem, the output at time step ",r.createElement(i.A,{text:"\\(t\\)"})," might be computed as:"),"\n",r.createElement(i.A,{text:"\\[\ny_t = \\mathrm{softmax}(W_{hy} \\, h_t + b_y),\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(i.A,{text:"\\(W_{hy}\\)"})," is the hidden-to-output weight matrix and ",r.createElement(i.A,{text:"\\(b_y\\)"})," is the bias for the output layer."),"\n",r.createElement(t.h3,{id:"24-forward-propagation-through-time",style:{position:"relative"}},r.createElement(t.a,{href:"#24-forward-propagation-through-time","aria-label":"24 forward propagation through time permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.4 forward propagation through time"),"\n",r.createElement(t.p,null,'in typical feed-forward networks, we apply transformations layer by layer. in rnns, we apply the same cell transformations across time steps. conceptually, we can "unfold" the rnn for ',r.createElement(i.A,{text:"\\(T\\)"})," steps. for a sequence ",r.createElement(i.A,{text:"\\(x_1, x_2, ..., x_T\\)"}),", the hidden state at each step is computed in a chain-like manner."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"unrolled representation"),r.createElement(t.br),"\n",'to visualize the recurrence properly, we often depict the network "unrolled" over time:'),"\n",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">x_1 ---\x3e [ RNN cell ] ---\x3e h_1 ---\x3e [ RNN cell ] ---\x3e h_2 ---\x3e ... ---\x3e [ RNN cell ] ---\x3e h_T</code></pre></div>'}}),"\n",r.createElement(t.p,null,"the important thing is that the same set of parameters (",r.createElement(i.A,{text:"\\(W_{hh}\\)"}),", ",r.createElement(i.A,{text:"\\(W_{xh}\\)"}),", etc.) is used at every time step. this drastically reduces the total number of parameters needed to process sequences of arbitrary length."),"\n",r.createElement(t.h3,{id:"25-backpropagation-through-time-bptt",style:{position:"relative"}},r.createElement(t.a,{href:"#25-backpropagation-through-time-bptt","aria-label":"25 backpropagation through time bptt permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.5 backpropagation through time (bptt)"),"\n",r.createElement(t.p,null,"training rnns typically involves ",r.createElement(t.strong,null,"backpropagation through time (bptt)"),", an extension of the standard backpropagation algorithm that accounts for the unrolled structure. to compute the gradients of a loss function with respect to the model parameters, we sum the contributions of each time step's partial gradients. in practice, we usually perform truncated bptt, limiting how far we go back in time before stopping gradient flow."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"vanishing and exploding gradients"),r.createElement(t.br),"\n","two significant training stability problems often occur during bptt:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"vanishing gradients"),": if the eigenvalues of the recurrent weight matrix ",r.createElement(i.A,{text:"\\(W_{hh}\\)"}),' (or effective jacobian) are less than 1 in magnitude, repeated multiplication over many time steps can shrink the gradients exponentially. that causes them to approach zero, thus "vanishing."'),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"exploding gradients"),': if the eigenvalues are greater than 1, repeated multiplication can cause gradients to grow exponentially large, "exploding" in magnitude and making training unstable.'),"\n"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"mitigation strategies")),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"gradient clipping"),": bounding the gradient norm to a fixed value to avoid exploding gradients."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"careful initialization"),": using orthogonal or identity initializations for ",r.createElement(i.A,{text:"\\(W_{hh}\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"gated architectures")," (discussed in chapters 3 and 4) that let the model learn to maintain stable long-range dependencies."),"\n"),"\n",r.createElement(t.h3,{id:"26-typical-use-cases-for-simple-rnns",style:{position:"relative"}},r.createElement(t.a,{href:"#26-typical-use-cases-for-simple-rnns","aria-label":"26 typical use cases for simple rnns permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.6 typical use cases for simple rnns"),"\n",r.createElement(t.p,null,"despite the issues of vanishing/exploding gradients, simple rnns can still be used effectively in tasks where sequences are not excessively long or complicated:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"basic sentiment classification where input sequences are typically short."),"\n",r.createElement(t.li,null,"certain straightforward time-series tasks with limited or short memory requirements."),"\n",r.createElement(t.li,null,"small prototype experiments or teaching demonstrations in academic contexts."),"\n"),"\n",r.createElement(t.p,null,"these simpler rnn variants remain conceptually valuable for building intuition about sequential processing."),"\n",r.createElement(t.h2,{id:"3-lstm-long-short-term-memory-networks",style:{position:"relative"}},r.createElement(t.a,{href:"#3-lstm-long-short-term-memory-networks","aria-label":"3 lstm long short term memory networks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3. lstm: long short-term memory networks"),"\n",r.createElement(t.h3,{id:"31-motivation",style:{position:"relative"}},r.createElement(t.a,{href:"#31-motivation","aria-label":"31 motivation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.1 motivation"),"\n",r.createElement(t.p,null,"as mentioned, a vanilla rnn struggles with learning dependencies across many time steps. once sequences become moderately long (e.g., 50–100 steps or more), standard rnns have difficulty propagating useful gradients back to the early part of the sequence."),"\n",r.createElement(t.p,null,"in response, ",r.createElement(t.strong,null,"hochreiter & schmidhuber (1997)")," introduced the ",r.createElement(t.strong,null,"long short-term memory"),' (lstm) architecture. by introducing carefully designed gating mechanisms and an internal "cell state," the lstm allows the model to selectively remember and forget information over potentially large time intervals. this effectively reduces the vanishing gradient problem and enables stable training over longer sequences.'),"\n",r.createElement(t.h3,{id:"32-architecture-of-the-lstm-cell",style:{position:"relative"}},r.createElement(t.a,{href:"#32-architecture-of-the-lstm-cell","aria-label":"32 architecture of the lstm cell permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.2 architecture of the lstm cell"),"\n",r.createElement(t.p,null,"the architecture of an lstm cell includes:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"cell state")," (",r.createElement(i.A,{text:"\\(C_t\\)"}),'): acts as an internal "conveyor belt" that can carry information across many time steps unchanged, subject only to minor linear interactions. this is the key to preserving long-range dependencies.'),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hidden state")," (",r.createElement(i.A,{text:"\\(h_t\\)"}),"): the traditional hidden state that is output to the next layer or next time step."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"three gates"),":","\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"forget gate")," (",r.createElement(i.A,{text:"\\(f_t\\)"}),"): decides which information to keep and which to discard from the cell state."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"input gate")," (",r.createElement(i.A,{text:"\\(i_t\\)"}),"): determines how much new information enters the cell state from the current input."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"output gate")," (",r.createElement(i.A,{text:"\\(o_t\\)"}),"): controls how much of the cell state flows into the hidden state at time ",r.createElement(i.A,{text:"\\(t\\)"}),"."),"\n"),"\n"),"\n"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"lstm equations"),r.createElement(t.br),"\n","the typical implementation of an lstm includes the following steps at time ",r.createElement(i.A,{text:"\\(t\\)"}),":"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"forget gate"),":","\n",r.createElement(i.A,{text:"\\(f_t = \\sigma(W_{xf} x_t + W_{hf} h_{t-1} + b_f)\\)"}),"\n",r.createElement("br"),"\n","determines which parts of the previous cell state ",r.createElement(i.A,{text:"\\(C_{t-1}\\)"})," to forget."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"input gate"),":","\n",r.createElement(i.A,{text:"\\(i_t = \\sigma(W_{xi} x_t + W_{hi} h_{t-1} + b_i)\\)"}),"\n",r.createElement("br"),"\n","decides how much of the candidate cell update ",r.createElement(i.A,{text:"\\(\\tilde{C}_t\\)"})," gets added to ",r.createElement(i.A,{text:"\\(C_{t-1}\\)"}),"."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"candidate cell state"),":","\n",r.createElement(i.A,{text:"\\(\\tilde{C}_t = \\tanh(W_{xC} x_t + W_{hC} h_{t-1} + b_C)\\)"}),"\n",r.createElement("br"),"\n","is a typical tanh layer that provides new candidate values that could be added to the cell state."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"update cell state"),":","\n",r.createElement(i.A,{text:"\\(C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t\\)"}),"\n",r.createElement("br"),"\n","merges the old cell state and the newly scaled candidate, controlling what to remember and what new information to add."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"output gate"),":","\n",r.createElement(i.A,{text:"\\(o_t = \\sigma(W_{xo} x_t + W_{ho} h_{t-1} + b_o)\\)"}),"\n",r.createElement("br"),"\n","is a gating factor for the final hidden state."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hidden state"),":","\n",r.createElement(i.A,{text:"\\(h_t = o_t \\odot \\tanh(C_t)\\)"}),"\n",r.createElement("br"),"\n","chooses how much of the updated cell state to reveal as hidden output."),"\n"),"\n",r.createElement(t.p,null,"above, ",r.createElement(i.A,{text:"\\(\\sigma(\\cdot)\\)"})," denotes the sigmoid function and ",r.createElement(i.A,{text:"\\(\\tanh(\\cdot)\\)"})," is the hyperbolic tangent function, each gate is pointwise multiplied (",r.createElement(i.A,{text:"\\(\\odot\\)"}),"), and ",r.createElement(i.A,{text:"\\(W_{x\\cdot}\\)"})," / ",r.createElement(i.A,{text:"\\(W_{h\\cdot}\\)"})," are parameter matrices."),"\n",r.createElement(t.h3,{id:"33-peephole-connections-and-other-lstm-variants",style:{position:"relative"}},r.createElement(t.a,{href:"#33-peephole-connections-and-other-lstm-variants","aria-label":"33 peephole connections and other lstm variants permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.3 peephole connections and other lstm variants"),"\n",r.createElement(t.p,null,'the "peephole" variant proposed by gers and schmidhuber (2000) adds direct connections from the cell state to each gate, letting gates access the exact cell state. other variations unify the forget and input gates. overall, the essential principle remains: an lstm cell has a carefully designed architecture for controlling how information is added to, retained in, and extracted from the cell state.'),"\n",r.createElement(t.h3,{id:"34-practical-advantages-of-lstm",style:{position:"relative"}},r.createElement(t.a,{href:"#34-practical-advantages-of-lstm","aria-label":"34 practical advantages of lstm permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.4 practical advantages of lstm"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"effective for long sequences"),": they can capture dependencies across hundreds of time steps."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"stable gradients"),": gating mechanisms largely mitigate the vanishing gradient problem."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"widespread empirical success"),": used extensively in machine translation (before transformers became the norm), speech recognition, text classification, etc."),"\n"),"\n",r.createElement(t.h3,{id:"35-limitations-of-lstm",style:{position:"relative"}},r.createElement(t.a,{href:"#35-limitations-of-lstm","aria-label":"35 limitations of lstm permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.5 limitations of lstm"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"computational cost"),": the gating mechanisms add more parameters."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"long inference times"),": longer sequences must be processed step by step."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"memory usage"),": storing states for all steps is more expensive."),"\n"),"\n",r.createElement(t.p,null,"nonetheless, lstms remain a proven architecture in many production systems and remain relevant, especially for tasks like smaller-scale language modeling or specialized rnn-based pipelines."),"\n",r.createElement(t.h2,{id:"4-gru-gated-recurrent-units",style:{position:"relative"}},r.createElement(t.a,{href:"#4-gru-gated-recurrent-units","aria-label":"4 gru gated recurrent units permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4. gru: gated recurrent units"),"\n",r.createElement(t.h3,{id:"41-motivation-and-background",style:{position:"relative"}},r.createElement(t.a,{href:"#41-motivation-and-background","aria-label":"41 motivation and background permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.1 motivation and background"),"\n",r.createElement(t.p,null,"the ",r.createElement(t.strong,null,"gated recurrent unit (gru)"),", introduced by ",r.createElement(t.strong,null,"cho and gang (2014)"),", is a simplification of the lstm architecture. it merges the forget and input gates into a single gate and combines the cell state and hidden state, yielding fewer parameters and sometimes equally strong performance. this was especially relevant in resource-constrained scenarios or when quick iteration is needed."),"\n",r.createElement(t.h3,{id:"42-architecture-of-the-gru-cell",style:{position:"relative"}},r.createElement(t.a,{href:"#42-architecture-of-the-gru-cell","aria-label":"42 architecture of the gru cell permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.2 architecture of the gru cell"),"\n",r.createElement(t.p,null,"in a gru, the gating system is conceptually simpler:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"update gate")," (",r.createElement(i.A,{text:"\\(z_t\\)"}),"): decides how much of the previous hidden state to keep around."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"reset gate")," (",r.createElement(i.A,{text:"\\(r_t\\)"}),"): decides how to combine the new input with the previous hidden state."),"\n"),"\n",r.createElement(t.p,null,"the hidden state ",r.createElement(i.A,{text:"\\(h_t\\)"})," serves a role similar to that of the lstm's cell state ",r.createElement(i.A,{text:"\\(C_t\\)"})," combined with the hidden state."),"\n",r.createElement(t.p,null,"the main equations are:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"update gate"),":","\n",r.createElement(i.A,{text:"\\(z_t = \\sigma(W_{xz} x_t + W_{hz} h_{t-1} + b_z)\\)"}),"\n"),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"reset gate"),":","\n",r.createElement(i.A,{text:"\\(r_t = \\sigma(W_{xr} x_t + W_{hr} h_{t-1} + b_r)\\)"}),"\n"),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"candidate hidden state"),":","\n",r.createElement(i.A,{text:"\\(\\tilde{h}_t = \\tanh(W_{xh} x_t + r_t \\odot (W_{hh} h_{t-1}) + b_h)\\)"}),"\n"),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"final hidden state"),":","\n",r.createElement(i.A,{text:"\\(h_t = z_t \\odot h_{t-1} + (1 - z_t) \\odot \\tilde{h}_t\\)"}),"\n"),"\n"),"\n",r.createElement(t.p,null,"intuitively, if ",r.createElement(i.A,{text:"\\(z_t\\)"})," is close to 1, the model largely retains the previous hidden state and ignores the candidate. if ",r.createElement(i.A,{text:"\\(z_t\\)"})," is close to 0, the model overwrites the previous hidden state with the new candidate. the reset gate ",r.createElement(i.A,{text:"\\(r_t\\)"})," determines how to blend old information into the candidate."),"\n",r.createElement(t.h3,{id:"43-comparison-between-gru-and-lstm",style:{position:"relative"}},r.createElement(t.a,{href:"#43-comparison-between-gru-and-lstm","aria-label":"43 comparison between gru and lstm permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.3 comparison between gru and lstm"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"parameters"),": grus have fewer parameters and are simpler to implement."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"memory usage"),": slightly lower for grus."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"expressive power"),": lstms can represent more intricate gating behaviors due to separate input and forget gates."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"empirical performance"),": can be similar, though details depend on the task and dataset specifics."),"\n"),"\n",r.createElement(t.h3,{id:"44-use-case-recommendations",style:{position:"relative"}},r.createElement(t.a,{href:"#44-use-case-recommendations","aria-label":"44 use case recommendations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.4 use-case recommendations"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"if memory or compute is constrained, a gru might be preferable."),"\n",r.createElement(t.li,null,"if you suspect your data requires a strong capacity for long-term memory, you might choose an lstm, though grus can also excel."),"\n",r.createElement(t.li,null,"many speech- and text-based tasks have historically found grus to be a sweet spot between performance and overhead."),"\n"),"\n",r.createElement(t.h3,{id:"45-variable-length-input-and-partial-sequences",style:{position:"relative"}},r.createElement(t.a,{href:"#45-variable-length-input-and-partial-sequences","aria-label":"45 variable length input and partial sequences permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.5 variable-length input and partial sequences"),"\n",r.createElement(t.p,null,"both lstm and gru can handle variable-length sequences natively by simply unrolling the recurrence as far as needed. for partial sequences or streaming data, one can maintain an internal hidden state and update the model step by step."),"\n",r.createElement(t.h2,{id:"5-bidirectional-rnn",style:{position:"relative"}},r.createElement(t.a,{href:"#5-bidirectional-rnn","aria-label":"5 bidirectional rnn permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5. bidirectional rnn"),"\n",r.createElement(t.h3,{id:"51-concept-of-forward-and-backward-passes",style:{position:"relative"}},r.createElement(t.a,{href:"#51-concept-of-forward-and-backward-passes","aria-label":"51 concept of forward and backward passes permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.1 concept of forward and backward passes"),"\n",r.createElement(t.p,null,"a ",r.createElement(t.strong,null,"bidirectional recurrent neural network")," processes the sequence in both directions: from ",r.createElement(i.A,{text:"\\(t=1\\)"})," to ",r.createElement(i.A,{text:"\\(t=T\\)"})," and from ",r.createElement(i.A,{text:"\\(t=T\\)"})," down to ",r.createElement(i.A,{text:"\\(t=1\\)"}),". the hidden states for the forward pass ",r.createElement(i.A,{text:"\\( \\overrightarrow{h}_t\\)"})," and backward pass ",r.createElement(i.A,{text:"\\(\\overleftarrow{h}_t\\)"})," are concatenated at each time step to form a combined representation:"),"\n",r.createElement(i.A,{text:"\\[\nh_t = [\\overrightarrow{h}_t; \\overleftarrow{h}_t].\n\\]"}),"\n",r.createElement(t.p,null,'the result is often richer, as each output state is informed not just by the current input and historical context, but also by "future" context.'),"\n",r.createElement(t.h3,{id:"52-integrating-bidirectional-layers-with-lstm-and-gru",style:{position:"relative"}},r.createElement(t.a,{href:"#52-integrating-bidirectional-layers-with-lstm-and-gru","aria-label":"52 integrating bidirectional layers with lstm and gru permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.2 integrating bidirectional layers with lstm and gru"),"\n",r.createElement(t.p,null,"bidirectional rnns are typically used in tasks such as speech recognition, machine translation (particularly when used as an encoder for a subsequent decoder), and question-answering, especially in tasks where the entire sequence is available. to build a bidirectional lstm or gru, one can simply place a forward lstm/gru and a backward lstm/gru side by side, then concatenate or add their outputs."),"\n",r.createElement(t.p,null,"practically, major frameworks (pytorch, tensorflow, keras) provide built-in layers like ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">bidirectional(lstm(...))</code>'}})," that handle the forward-backward unrolling behind the scenes."),"\n",r.createElement(t.h3,{id:"53-performance-improvements-and-trade-offs",style:{position:"relative"}},r.createElement(t.a,{href:"#53-performance-improvements-and-trade-offs","aria-label":"53 performance improvements and trade offs permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.3 performance improvements and trade-offs"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"pros"),": capturing context from both directions in a single pass can yield improved accuracy on tasks like part-of-speech tagging or sentiment classification where future context helps interpret the meaning of earlier tokens."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"cons"),": at inference time, you must wait to see the entire sequence to process it in reverse. it is thus not suitable for real-time streaming tasks. also, memory usage is higher."),"\n"),"\n",r.createElement(t.h3,{id:"54-real-world-use-cases",style:{position:"relative"}},r.createElement(t.a,{href:"#54-real-world-use-cases","aria-label":"54 real world use cases permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.4 real-world use cases"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"speech recognition"),": audio frames are often processed with a bidirectional rnn for transcription."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"machine translation"),": used on the encoder side if the entire source sentence is known in advance."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"question answering"),": capturing future context is beneficial for analyzing a question's structure and relevant context in the input text."),"\n"),"\n",r.createElement(t.h2,{id:"6-embedding-layer",style:{position:"relative"}},r.createElement(t.a,{href:"#6-embedding-layer","aria-label":"6 embedding layer permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6. embedding layer"),"\n",r.createElement(t.h3,{id:"61-role-of-embeddings-in-sequence-modeling",style:{position:"relative"}},r.createElement(t.a,{href:"#61-role-of-embeddings-in-sequence-modeling","aria-label":"61 role of embeddings in sequence modeling permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1 role of embeddings in sequence modeling"),"\n",r.createElement(t.p,null,"when dealing with natural language, tokens (words, subwords, characters) are discrete. to feed them into an rnn, we must convert them to numeric vectors that capture semantic and syntactic properties. this is done via an ",r.createElement(t.strong,null,"embedding layer"),"."),"\n",r.createElement(t.p,null,"embedding layers map each token (identified by an index) to a trainable dense vector representation. for example:"),"\n",r.createElement(t.p,null,r.createElement(i.A,{text:"\\( \\mathrm{embedding}(w) \\in \\mathbb{R}^d \\)"}),","),"\n",r.createElement(t.p,null,"where ",r.createElement(i.A,{text:"\\(d\\)"})," is the embedding dimension."),"\n",r.createElement(t.p,null,"these embeddings are learned jointly with the rest of the network."),"\n",r.createElement(t.h3,{id:"62-learning-embedding-representations",style:{position:"relative"}},r.createElement(t.a,{href:"#62-learning-embedding-representations","aria-label":"62 learning embedding representations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2 learning embedding representations"),"\n",r.createElement(t.p,null,"the embedding layer parameters are typically initialized randomly (or with pretrained embeddings from something like word2vec or glove) and then updated by backpropagation."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"example"),": if your vocabulary has 10,000 words and embedding size is 300, the embedding layer is effectively a 10,000 x 300 matrix, where each row is the vector for a particular word index."),"\n",r.createElement(t.h3,{id:"63-incorporating-embeddings-in-rnn-architectures",style:{position:"relative"}},r.createElement(t.a,{href:"#63-incorporating-embeddings-in-rnn-architectures","aria-label":"63 incorporating embeddings in rnn architectures permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.3 incorporating embeddings in rnn architectures"),"\n",r.createElement(t.p,null,"once a token is converted to its embedding ",r.createElement(i.A,{text:"\\(e_t\\)"}),", that embedding is used as the input ",r.createElement(i.A,{text:"\\(x_t\\)"})," for the rnn at time ",r.createElement(i.A,{text:"\\(t\\)"}),"."),"\n",r.createElement(t.p,null,"for example, a stacked rnn might look like:"),"\n",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">raw_token -> embedding -> (RNN cell) -> ...</code></pre></div>'}}),"\n",r.createElement(t.p,null,"this approach is standard in nlp tasks."),"\n",r.createElement(t.h3,{id:"64-pretrained-vs-trainable-embeddings",style:{position:"relative"}},r.createElement(t.a,{href:"#64-pretrained-vs-trainable-embeddings","aria-label":"64 pretrained vs trainable embeddings permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.4 pretrained vs. trainable embeddings"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"pretrained")," (e.g., glove, word2vec, fasttext): can help the model converge faster if domain vocabulary matches the pretrained corpus."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"trainable"),": for domain-specific tasks, learning embeddings from scratch is often beneficial. in practice, some mix is used, or embeddings are pretrained and then fine-tuned."),"\n"),"\n",r.createElement(t.h3,{id:"65-handling-out-of-vocabulary-and-rare-words",style:{position:"relative"}},r.createElement(t.a,{href:"#65-handling-out-of-vocabulary-and-rare-words","aria-label":"65 handling out of vocabulary and rare words permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.5 handling out-of-vocabulary and rare words"),"\n",r.createElement(t.p,null,"a major issue in nlp is how to handle tokens not seen in training or extremely rare words. solutions include:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"subword embeddings: splitting tokens into morphological units."),"\n",r.createElement(t.li,null,"byte-pair encoding (bpe): widely used in modern nlp."),"\n",r.createElement(t.li,null,"character-based embedding: letting the rnn handle characters, though that typically requires deeper or more advanced networks for performance."),"\n"),"\n",r.createElement(t.h2,{id:"7-training-and-optimization",style:{position:"relative"}},r.createElement(t.a,{href:"#7-training-and-optimization","aria-label":"7 training and optimization permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7. training and optimization"),"\n",r.createElement(t.h3,{id:"71-data-preprocessing-for-rnn-models",style:{position:"relative"}},r.createElement(t.a,{href:"#71-data-preprocessing-for-rnn-models","aria-label":"71 data preprocessing for rnn models permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1 data preprocessing for rnn models"),"\n",r.createElement(t.p,null,"preparing sequence data often requires:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"tokenization and normalization")," (text)."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"sequence padding or truncation")," to achieve uniform batch shapes."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"batching strategy"),": deciding how to batch sequences of different lengths. common approaches:","\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"bucketed batching"),": group sequences by similar length."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"masking"),": typically used so that the network ignores padded tokens."),"\n"),"\n"),"\n"),"\n",r.createElement(t.h3,{id:"72-hyperparameter-tuning",style:{position:"relative"}},r.createElement(t.a,{href:"#72-hyperparameter-tuning","aria-label":"72 hyperparameter tuning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2 hyperparameter tuning"),"\n",r.createElement(t.p,null,"common hyperparameters to tune:"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"learning rate"),": rnns can be sensitive to the chosen optimizer and learning rate schedule."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hidden state dimension"),": the size of ",r.createElement(i.A,{text:"\\(h_t\\)"})," strongly impacts capacity."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"number of layers"),": deeper rnns are more expressive but can be harder to train."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"dropout rate"),": especially crucial in recurrent connections to prevent overfitting."),"\n"),"\n",r.createElement(t.h3,{id:"73-regularization-techniques",style:{position:"relative"}},r.createElement(t.a,{href:"#73-regularization-techniques","aria-label":"73 regularization techniques permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3 regularization techniques"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"recurrent dropout"),": random dropout of hidden connections within the rnn cell."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"input/output dropout"),": dropping inputs or outputs to/from the rnn."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"weight decay"),": standard ",r.createElement(i.A,{text:"\\(L_2\\)"})," regularization."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"early stopping"),": stopping training when validation loss stagnates or worsens."),"\n"),"\n",r.createElement(t.p,null,"these methods help reduce overfitting, particularly in tasks involving large networks but limited data."),"\n",r.createElement(t.h3,{id:"74-monitoring-and-dealing-with-overfitting",style:{position:"relative"}},r.createElement(t.a,{href:"#74-monitoring-and-dealing-with-overfitting","aria-label":"74 monitoring and dealing with overfitting permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4 monitoring and dealing with overfitting"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"validation metrics"),": for language modeling, perplexity or cross-entropy. for classification, accuracy or f1."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"overfitting indicators"),": training loss decreases but validation loss stops decreasing or starts increasing."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"techniques to mitigate"),":"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"reduce model size."),"\n",r.createElement(t.li,null,"apply dropout more aggressively."),"\n",r.createElement(t.li,null,"gather more data or use data augmentation if feasible (in certain domains like text, data augmentation is non-trivial but possible with synonyms replacement or back-translation)."),"\n"),"\n",r.createElement(t.h3,{id:"75-practical-tools-and-libraries",style:{position:"relative"}},r.createElement(t.a,{href:"#75-practical-tools-and-libraries","aria-label":"75 practical tools and libraries permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.5 practical tools and libraries"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"pytorch"),": ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">torch.nn.rnn</code>'}}),", ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">torch.nn.lstm</code>'}}),", ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">torch.nn.gru</code>'}}),", or ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">torch.nn.rnncell</code>'}})," if going low-level."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"tensorflow/keras"),": ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">keras.layers.simpleRNN</code>'}}),", ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">keras.layers.lstm</code>'}}),", ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">keras.layers.gru</code>'}}),", or their bidirectional wrappers."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"mxnet"),": ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">mxnet.gluon.rnn</code>'}}),"."),"\n"),"\n",r.createElement(t.p,null,"each library typically provides easy-to-use modules for building advanced rnn architectures, including multi-layer stacked rnns, residual connections, and more."),"\n",r.createElement(t.h2,{id:"8-advanced-extensions",style:{position:"relative"}},r.createElement(t.a,{href:"#8-advanced-extensions","aria-label":"8 advanced extensions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8. advanced extensions"),"\n",r.createElement(t.h3,{id:"81-attention-mechanisms",style:{position:"relative"}},r.createElement(t.a,{href:"#81-attention-mechanisms","aria-label":"81 attention mechanisms permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.1 attention mechanisms"),"\n",r.createElement(t.p,null,"while not strictly part of a standard rnn cell, ",r.createElement(t.strong,null,"attention"),' revolutionized sequence-to-sequence tasks by allowing the model to "focus" on certain parts of the input sequence when predicting each token of the output.'),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"key idea"),": rather than compressing the entire source sequence into a single vector (like a naive encoder-decoder rnn might do), an attention mechanism provides context vectors that vary at each output time step. this overcame the bottleneck of a single representation and improved performance in tasks such as machine translation."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"soft attention"),": introduced by bahdanau and gang (2014) and luong and gang (2015)."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"transformers"),": introduced by vaswani and gang (2017), removed the rnn altogether in their architecture, replacing recurrence with purely attention-based blocks."),"\n",r.createElement(t.h3,{id:"82-transformers-vs-rnn-based-architectures",style:{position:"relative"}},r.createElement(t.a,{href:"#82-transformers-vs-rnn-based-architectures","aria-label":"82 transformers vs rnn based architectures permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.2 transformers vs. rnn-based architectures"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"parallelization"),": rnns process sequences step by step, limiting parallelization. transformers handle all positions simultaneously via self-attention."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"long-range dependencies"),": attention-based models handle them more gracefully, whereas rnns still might degrade for very long sequences."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"resource usage"),": transformers can require large memory for extremely long sequences."),"\n"),"\n",r.createElement(t.p,null,"that said, rnns remain valuable especially for smaller or streaming tasks."),"\n",r.createElement(t.h3,{id:"83-combining-rnns-with-convolutional-networks",style:{position:"relative"}},r.createElement(t.a,{href:"#83-combining-rnns-with-convolutional-networks","aria-label":"83 combining rnns with convolutional networks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.3 combining rnns with convolutional networks"),"\n",r.createElement(t.p,null,"in tasks like audio or video processing, one can combine a convolutional front end that processes local structure in time (or space-time for video) with a subsequent rnn that captures longer-range dependencies. for instance, a convolutional layer can embed short audio windows into higher-level features, then the rnn processes these features sequentially."),"\n",r.createElement(t.h3,{id:"84-memory-augmented-networks",style:{position:"relative"}},r.createElement(t.a,{href:"#84-memory-augmented-networks","aria-label":"84 memory augmented networks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.4 memory-augmented networks"),"\n",r.createElement(t.p,null,"beyond lstms, researchers have proposed advanced memory constructs, such as ",r.createElement(t.strong,null,"neural turing machines")," and ",r.createElement(t.strong,null,"differentiable neural computers")," (graves and gang, 2014, 2016), which explicitly handle read and write operations to an external memory. these approaches aim to let the network store information for indefinite lengths of time."),"\n",r.createElement(t.h3,{id:"85-reinforcement-learning-with-rnns",style:{position:"relative"}},r.createElement(t.a,{href:"#85-reinforcement-learning-with-rnns","aria-label":"85 reinforcement learning with rnns permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.5 reinforcement learning with rnns"),"\n",r.createElement(t.p,null,"when an agent interacts with an environment, partial observability can require maintaining hidden states over time. rnns such as lstms or grus can track historical observations for decision making. deepmind's use of lstms in deep reinforcement learning for tasks like atari is a well-known example (mnih and gang, 2015)."),"\n",r.createElement(t.h3,{id:"86-multi-task-learning",style:{position:"relative"}},r.createElement(t.a,{href:"#86-multi-task-learning","aria-label":"86 multi task learning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.6 multi-task learning"),"\n",r.createElement(t.p,null,'rnns are sometimes used in multi-task settings, for example, a single rnn might be used to do language modeling and sequence tagging simultaneously, sharing hidden layers. the gating and memory aspects can help the model not "forget" essential features across tasks.'),"\n",r.createElement(t.h3,{id:"87-hierarchical-rnns",style:{position:"relative"}},r.createElement(t.a,{href:"#87-hierarchical-rnns","aria-label":"87 hierarchical rnns permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.7 hierarchical rnns"),"\n",r.createElement(t.p,null,"a hierarchical approach might group tokens into sentences, paragraphs, or documents, with an rnn at each level. for instance, an rnn processes words in a sentence to produce a sentence embedding, then another rnn processes these sentence embeddings at the paragraph level, etc."),"\n",r.createElement(t.h2,{id:"9-case-studies-and-applications",style:{position:"relative"}},r.createElement(t.a,{href:"#9-case-studies-and-applications","aria-label":"9 case studies and applications permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9. case studies and applications"),"\n",r.createElement(t.h3,{id:"91-natural-language-processing",style:{position:"relative"}},r.createElement(t.a,{href:"#91-natural-language-processing","aria-label":"91 natural language processing permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.1 natural language processing"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"9.1.1 machine translation"),r.createElement(t.br),"\n","classic sequence-to-sequence rnns used an encoder rnn to encode a source sentence into a context vector, then a decoder rnn to generate target words step by step."),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,"coverage: attention-based rnns improved translation quality by letting the decoder attend to different parts of the source."),"\n"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"9.1.2 sentiment analysis"),r.createElement(t.br),"\n","rnns ingest word embeddings of a sentence in order, culminating in a final hidden state that can be used for classification (positive/negative)."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"9.1.3 text summarization"),r.createElement(t.br),"\n",'similar to machine translation, except the "target" is a compressed version of the input.'),"\n",r.createElement(t.h3,{id:"92-speech-recognition-and-generation",style:{position:"relative"}},r.createElement(t.a,{href:"#92-speech-recognition-and-generation","aria-label":"92 speech recognition and generation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.2 speech recognition and generation"),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"9.2.1 end-to-end automatic speech recognition (asr)"),r.createElement(t.br),"\n","frameworks like deep speech (hannun and gang, 2014) used multi-layer rnns (often bidirectional lstms) on spectrogram frames to map them directly to phoneme or character sequences."),"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"9.2.2 text-to-speech (tts)"),r.createElement(t.br),"\n","networks like tacotron combined a recurrent seq2seq approach with attention to generate spectrogram frames from text, followed by a vocoder to synthesize waveforms."),"\n",r.createElement(t.h3,{id:"93-time-series-forecasting-and-anomaly-detection",style:{position:"relative"}},r.createElement(t.a,{href:"#93-time-series-forecasting-and-anomaly-detection","aria-label":"93 time series forecasting and anomaly detection permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.3 time series forecasting and anomaly detection"),"\n",r.createElement(t.p,null,"rnns can be used to forecast future values in a univariate or multivariate time series. the ability to keep track of hidden states over time helps the model identify underlying patterns or anomalies."),"\n",r.createElement(t.h3,{id:"94-real-world-implementations",style:{position:"relative"}},r.createElement(t.a,{href:"#94-real-world-implementations","aria-label":"94 real world implementations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.4 real-world implementations"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"personalized recommendations"),": sequence-based recommendation systems for user event histories."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"conversational ai"),": older chatbots used hierarchical rnns. new systems more often adopt transformers."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"healthcare"),": event sequences in medical records can be used for diagnoses or risk prediction."),"\n"),"\n",r.createElement(t.h3,{id:"95-challenges-and-future-directions",style:{position:"relative"}},r.createElement(t.a,{href:"#95-challenges-and-future-directions","aria-label":"95 challenges and future directions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.5 challenges and future directions"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"interpretability"),": gating helps, but rnns are still often viewed as black boxes."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"scalability"),": step-by-step nature can be slow for large sequences."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hybrid approaches"),": mixture of rnns, attention, or memory modules."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"transformer dominance"),": many modern tasks have shifted to transformers, but rnns remain valuable for specialized or resource-constrained cases."),"\n"),"\n",r.createElement(t.hr),"\n",r.createElement(t.p,null,"below, i will provide expanded details, including code snippets for implementing various rnn structures using python (keras and pytorch examples). these examples illustrate the typical usage patterns for rnns, lstms, and grus in practice. i will also reference additional research as relevant."),"\n",r.createElement(t.hr),"\n",r.createElement(t.h2,{id:"expanded-details-and-implementation-code",style:{position:"relative"}},r.createElement(t.a,{href:"#expanded-details-and-implementation-code","aria-label":"expanded details and implementation code permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"expanded details and implementation code"),"\n",r.createElement(t.h3,{id:"a-code-example-simple-rnn-for-sentiment-analysis-keras",style:{position:"relative"}},r.createElement(t.a,{href:"#a-code-example-simple-rnn-for-sentiment-analysis-keras","aria-label":"a code example simple rnn for sentiment analysis keras permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"a. code example: simple rnn for sentiment analysis (keras)"),"\n",r.createElement(t.p,null,"the snippet below shows how one might implement a simple rnn for a text classification task, such as imdb sentiment classification:"),"\n",r.createElement(l.A,{text:"\nimport numpy as np\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense, Embedding\nfrom tensorflow.keras.optimizers import Adam\n\n# parameters\nmax_features = 5000   # size of vocabulary\nmaxlen = 100          # cut texts after this number of words\nbatch_size = 32\nembedding_dim = 128\nrnn_units = 64\nepochs = 5\n\n# load the data\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n\n# pad sequences\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_test  = pad_sequences(x_test,  maxlen=maxlen)\n\n# build the model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\nmodel.add(SimpleRNN(units=rnn_units, activation='tanh'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# compile\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(learning_rate=0.001),\n              metrics=['accuracy'])\n\n# train\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(x_test, y_test),\n          verbose=1)\n\n# evaluate\ntest_loss, test_acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(\"test accuracy:\", test_acc)\n"}),"\n",r.createElement(t.p,null,'this is a simplistic example using a standard "vanilla" rnn layer (',r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">SimpleRNN</code>'}}),"). for short sequences, it can work acceptably. for longer sequences, the model might struggle with capturing context from the beginning of the text."),"\n",r.createElement(t.hr),"\n",r.createElement(t.h3,{id:"b-code-example-lstm-for-time-series-forecasting-pytorch",style:{position:"relative"}},r.createElement(t.a,{href:"#b-code-example-lstm-for-time-series-forecasting-pytorch","aria-label":"b code example lstm for time series forecasting pytorch permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"b. code example: lstm for time series forecasting (pytorch)"),"\n",r.createElement(t.p,null,"imagine we have a univariate time series, and we want to forecast the next value based on the last 20 time steps. we can do this with an lstm in pytorch:"),"\n",r.createElement(l.A,{text:'\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass LSTMForecast(nn.Module):\n    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1):\n        super(LSTMForecast, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc   = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_length, input_size)\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        \n        out, (hn, cn) = self.lstm(x, (h0, c0))\n        # out shape: (batch_size, seq_length, hidden_size)\n        # we want only the last time step\n        out = out[:, -1, :]  # (batch_size, hidden_size)\n        out = self.fc(out)\n        return out\n\n# synthetic data\nimport numpy as np\nseq_length = 20\nnum_samples = 1000\n\n# random walk or some synthetic time series\ntime_series = np.zeros(num_samples + seq_length)\nfor i in range(1, num_samples + seq_length):\n    time_series[i] = time_series[i-1] + np.random.normal()\n\nx_data = []\ny_data = []\nfor i in range(num_samples):\n    x_data.append(time_series[i:i+seq_length])\n    y_data.append(time_series[i+seq_length])\n\nx_data = np.array(x_data, dtype=np.float32).reshape(num_samples, seq_length, 1)\ny_data = np.array(y_data, dtype=np.float32).reshape(num_samples, 1)\n\ntrain_size = int(num_samples * 0.8)\nx_train = x_data[:train_size]\ny_train = y_data[:train_size]\nx_test  = x_data[train_size:]\ny_test  = y_data[train_size:]\n\nx_train_torch = torch.from_numpy(x_train)\ny_train_torch = torch.from_numpy(y_train)\nx_test_torch  = torch.from_numpy(x_test)\ny_test_torch  = torch.from_numpy(y_test)\n\nmodel = LSTMForecast()\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nepochs = 30\nbatch_size = 32\nfor epoch in range(epochs):\n    # simple mini-batch iteration\n    permutation = torch.randperm(train_size)\n    for i in range(0, train_size, batch_size):\n        indices = permutation[i:i+batch_size]\n        batch_x = x_train_torch[indices]\n        batch_y = y_train_torch[indices]\n        \n        optimizer.zero_grad()\n        outputs = model(batch_x)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        \n        # gradient clipping \n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n        \n        optimizer.step()\n    \n    # check training loss\n    with torch.no_grad():\n        train_preds = model(x_train_torch)\n        train_loss = criterion(train_preds, y_train_torch).item()\n        test_preds = model(x_test_torch)\n        test_loss = criterion(test_preds, y_test_torch).item()\n    print(f"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}")\n\nprint("training complete!")\n'}),"\n",r.createElement(t.p,null,"here, we see the typical approach for time series:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"we define a recurrent architecture (",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">nn.lstm</code>'}}),") to take an input of shape ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">(batch_size, seq_length, input_size)</code>'}}),"."),"\n",r.createElement(t.li,null,"we do a forward pass, capturing the last time step's hidden representation."),"\n",r.createElement(t.li,null,"we add a final fully connected layer for regression output."),"\n",r.createElement(t.li,null,"we train using an mse loss, with gradient clipping."),"\n"),"\n",r.createElement(t.hr),"\n",r.createElement(t.h3,{id:"c-code-example-bidirectional-gru-for-nlp-sequence-labeling-pytorch",style:{position:"relative"}},r.createElement(t.a,{href:"#c-code-example-bidirectional-gru-for-nlp-sequence-labeling-pytorch","aria-label":"c code example bidirectional gru for nlp sequence labeling pytorch permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"c. code example: bidirectional gru for nlp sequence labeling (pytorch)"),"\n",r.createElement(t.p,null,"for tasks like named entity recognition (ner) or part-of-speech (pos) tagging, a sequence label must be emitted for each token. a bidirectional gru can be used:"),"\n",r.createElement(l.A,{text:'\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass BiGRU(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels):\n        super(BiGRU, self).__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.bigru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.classifier = nn.Linear(hidden_dim*2, num_labels)\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_length)\n        emb = self.embed(x)  # (batch_size, seq_length, embed_dim)\n        out, h_n = self.bigru(emb)  # out shape: (batch_size, seq_length, hidden_dim * 2)\n        logits = self.classifier(out)  # (batch_size, seq_length, num_labels)\n        return logits\n\n# example usage\nvocab_size = 5000\nembed_dim = 128\nhidden_dim = 64\nnum_labels = 10  # e.g. # of pos tags or entity classes\n\nmodel = BiGRU(vocab_size, embed_dim, hidden_dim, num_labels)\nx_sample = torch.randint(0, vocab_size, (8, 12))  # batch of 8, seq_length=12\noutput = model(x_sample)\nprint("output shape:", output.shape)  # expected: [8, 12, 10]\n'}),"\n",r.createElement(t.p,null,"in a real training loop for sequence labeling, you would compute cross-entropy at each token position. the final dimensionality is ",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">(batch_size, seq_length, num_labels)</code>'}}),", so you can measure the classification loss for each token."),"\n",r.createElement(t.hr),"\n",r.createElement(t.h2,{id:"references-to-advanced-research",style:{position:"relative"}},r.createElement(t.a,{href:"#references-to-advanced-research","aria-label":"references to advanced research permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"references to advanced research"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hopfield networks")," (hopfield, 1982) introduced the idea of stable attractor states and memory, which preceded modern rnn memory-like concepts."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"elman networks")," (elman, 1990) introduced the notion of simple context units."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"hochreiter & schmidhuber (1997)"),": original paper on lstms."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"gers and gang (2000)"),": introduced peephole connections."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"cho and gang (2014)"),": introduced the gru, widely used in neural machine translation."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"bahdanau and gang (2014)"),": introduced the attention mechanism for neural machine translation."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"vaswani and gang (2017)"),": introduced the transformer model, which replaced recurrence with multi-head self-attention."),"\n"),"\n",r.createElement(t.hr),"\n",r.createElement(t.h2,{id:"lengthier-theoretical-insights",style:{position:"relative"}},r.createElement(t.a,{href:"#lengthier-theoretical-insights","aria-label":"lengthier theoretical insights permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"lengthier theoretical insights"),"\n",r.createElement(t.h3,{id:"rnn-and-dynamical-systems-perspective",style:{position:"relative"}},r.createElement(t.a,{href:"#rnn-and-dynamical-systems-perspective","aria-label":"rnn and dynamical systems perspective permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"rnn and dynamical systems perspective"),"\n",r.createElement(t.p,null,"rnns can be framed as discrete-time dynamical systems, where the hidden state update"),"\n",r.createElement(i.A,{text:"\\(h_t = f(h_{t-1}, x_t; \\theta)\\)"}),"\n",r.createElement(t.p,null,"resembles a step in a dynamical system with parameters ",r.createElement(i.A,{text:"(\\theta)"}),". from a systems theory standpoint, one can analyze stability by examining the eigenvalues of the jacobian of ",r.createElement(i.A,{text:"\\(f(\\cdot)\\)"}),". large eigenvalues cause expansions in the state space (exploding gradients), while small eigenvalues cause contractions (vanishing gradients)."),"\n",r.createElement(t.h3,{id:"truncated-bptt",style:{position:"relative"}},r.createElement(t.a,{href:"#truncated-bptt","aria-label":"truncated bptt permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"truncated bptt"),"\n",r.createElement(t.p,null,'in practice, if sequences are extremely long, it is common to train rnns by unrolling for only a fixed window size of, say, 20 or 30 steps (the "truncation" length). the hidden state is then detached from the computational graph before continuing. this prevents computational blow-up but also means that the model might not fully learn extremely long dependencies.'),"\n",r.createElement(t.h3,{id:"second-order-methods",style:{position:"relative"}},r.createElement(t.a,{href:"#second-order-methods","aria-label":"second order methods permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"second-order methods"),"\n",r.createElement(t.p,null,"some research has investigated second-order optimization methods (using curvature information) to address the difficulties of training rnns. these are rarely used in mainstream libraries due to computational overhead, but occasionally appear in large-scale specialized systems."),"\n",r.createElement(t.h3,{id:"interpretability-and-gating-analyses",style:{position:"relative"}},r.createElement(t.a,{href:"#interpretability-and-gating-analyses","aria-label":"interpretability and gating analyses permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"interpretability and gating analyses"),"\n",r.createElement(t.p,null,"some interpretability research tries to see how gating in lstms or grus behaves. for instance, does the forget gate open or close for certain input patterns? sometimes gating patterns can be correlated with semantic boundaries in text."),"\n",r.createElement(t.hr),"\n",r.createElement(t.h2,{id:"conclusion",style:{position:"relative"}},r.createElement(t.a,{href:"#conclusion","aria-label":"conclusion permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"conclusion"),"\n",r.createElement(t.p,null,"i have walked through the fundamentals and modern forms of recurrent neural networks, covering vanilla rnns, lstms, grus, and bidirectional rnns, as well as essential gating ideas, the gating equations, training procedures, advanced uses, and real-world applications. while rnns are no longer the top approach for many language tasks — especially after the emergence of attention-only transformers — they remain a foundational technique for sequence modeling. understanding rnns is important not only for historical perspective but also for tackling certain specialized tasks (small resource settings, streaming tasks, certain time-series forecasting problems, or scenarios requiring explicit stateful processing)."),"\n",r.createElement(t.p,null,"above all, rnns underscore the importance of memory in machine learning: how to preserve and propagate relevant context from previous inputs to influence future predictions. lstms and grus introduced gating to make memory management more robust over time, mitigating the vanishing gradient problem. these gating ideas strongly influenced subsequent architectures, including many of the memory-augmented networks and the gating logic in some transformer variants."),"\n",r.createElement(t.p,null,"rnns also remain relevant in fields such as music generation, real-time inference on low-power devices, or any domain in which a step-by-step approach is natural. while i've provided thorough background, theoretical commentary, and code snippets, there is of course much more that can be explored, including specialized initialization methods, advanced regularization approaches, and synergy with convolutional or attention-based layers."),"\n",r.createElement(t.p,null,"i hope this comprehensive overview helps to build a deeper understanding of rnn architecture and fosters readiness to implement, debug, optimize, and apply rnns in a variety of projects that involve sequential or time-dependent data."),"\n",r.createElement(t.hr),"\n",r.createElement(t.h2,{id:"additional-references",style:{position:"relative"}},r.createElement(t.a,{href:"#additional-references","aria-label":"additional references permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"additional references"),"\n",r.createElement(t.ul,null,"\n",r.createElement(t.li,null,'graves a., liwicki m., fernández s., bertolami r., bunke h., schmidhuber j. "a novel connectionist system for unconstrained handwriting recognition." ieee transactions on pattern analysis and machine intelligence (2008).'),"\n",r.createElement(t.li,null,'sutskever i., vinyals o., le q.v. "sequence to sequence learning with neural networks." neurips (2014).'),"\n",r.createElement(t.li,null,'lipton z.c., kale d.c., elkan c., wetzell r. "learning to diagnose with lstm recurrent neural networks." iclr (2016).'),"\n",r.createElement(t.li,null,'vaswani a. and gang "attention is all you need." neurips (2017).'),"\n"),"\n",r.createElement(t.hr),"\n",r.createElement(n,{alt:"rnn illustration",path:"",caption:"a conceptual diagram of an rnn unrolled over time",zoom:"false"}))}var o=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,a.RP)(),e.components);return t?r.createElement(t,e,r.createElement(s,e)):s(e)};var c=n(54506),m=n(88864),h=n(58481),d=n.n(h),u=n(5984),p=n(43672),g=n(27042),f=n(72031),v=n(81817),E=n(27105),b=n(17265),y=n(2043),_=n(95751),w=n(94328),x=n(80791),S=n(78137);const H=e=>{let{toc:t}=e;if(!t||!t.items)return null;return r.createElement("nav",{className:x.R},r.createElement("ul",null,t.items.map(((e,t)=>r.createElement("li",{key:t},r.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const n=t.replace("#",""),a=document.getElementById(n);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&r.createElement(H,{toc:{items:e.items}}))))))};function k(e){let{data:{mdx:t,allMdx:l,allPostImages:i},children:s}=e;const{frontmatter:o,body:m,tableOfContents:h}=t,f=o.index,x=o.slug.split("/")[1],k=l.nodes.filter((e=>e.frontmatter.slug.includes(`/${x}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),z=k.findIndex((e=>e.frontmatter.index===f)),M=k[z+1],C=k[z-1],V=o.slug.replace(/\/$/,""),q=/[^/]*$/.exec(V)[0],T=`posts/${x}/content/${q}/`,{0:L,1:A}=(0,r.useState)(o.flagWideLayoutByDefault),{0:I,1:N}=(0,r.useState)(!1);var B;(0,r.useEffect)((()=>{N(!0);const e=setTimeout((()=>N(!1)),340);return()=>clearTimeout(e)}),[L]),"adventures"===x?B=b.cb:"research"===x?B=b.Qh:"thoughts"===x&&(B=b.T6);const W=d()(m).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,P=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),n=e%60;return n<=30?`~${t}${n>0?".5":""} h`:`~${t+1} h`}(Math.ceil(W/B)+(o.extraReadTimeMin||0)),R=[{flag:o.flagDraft,component:()=>Promise.all([n.e(5850),n.e(9833)]).then(n.bind(n,49833))},{flag:o.flagMindfuckery,component:()=>Promise.all([n.e(5850),n.e(7805)]).then(n.bind(n,27805))},{flag:o.flagRewrite,component:()=>Promise.all([n.e(5850),n.e(8916)]).then(n.bind(n,78916))},{flag:o.flagOffensive,component:()=>Promise.all([n.e(5850),n.e(6731)]).then(n.bind(n,49112))},{flag:o.flagProfane,component:()=>Promise.all([n.e(5850),n.e(3336)]).then(n.bind(n,83336))},{flag:o.flagMultilingual,component:()=>Promise.all([n.e(5850),n.e(2343)]).then(n.bind(n,62343))},{flag:o.flagUnreliably,component:()=>Promise.all([n.e(5850),n.e(6865)]).then(n.bind(n,11627))},{flag:o.flagPolitical,component:()=>Promise.all([n.e(5850),n.e(4417)]).then(n.bind(n,24417))},{flag:o.flagCognitohazard,component:()=>Promise.all([n.e(5850),n.e(8669)]).then(n.bind(n,18669))},{flag:o.flagHidden,component:()=>Promise.all([n.e(5850),n.e(8124)]).then(n.bind(n,48124))}],{0:j,1:O}=(0,r.useState)([]);return(0,r.useEffect)((()=>{R.forEach((e=>{let{flag:t,component:n}=e;t&&n().then((e=>{O((t=>[].concat((0,c.A)(t),[e.default])))}))}))}),[]),r.createElement(g.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},r.createElement(v.A,{postNumber:o.index,date:o.date,updated:o.updated,readTime:P,difficulty:o.difficultyLevel,title:o.title,desc:o.desc,banner:o.banner,section:x,postKey:q,isMindfuckery:o.flagMindfuckery,mainTag:o.mainTag}),r.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},o.otherTags.map(((e,t)=>r.createElement("span",{key:t,className:`noselect ${S.MW}`,style:{margin:"0 5px 5px 0"}},e)))),r.createElement("div",{className:"postBody"},r.createElement(H,{toc:h})),r.createElement("br",null),r.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},r.createElement(g.P.button,{className:`noselect ${w.pb}`,id:w.xG,onClick:()=>{A(!L)},whileTap:{scale:.93}},r.createElement(g.P.div,{className:_.DJ,key:L,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},L?"Switch to default layout":"Switch to wide layout"))),r.createElement("br",null),r.createElement("div",{className:"postBody",style:{margin:L?"0 -14%":"",maxWidth:L?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},r.createElement("div",{className:`${w.P_} ${I?w.Xn:w.qG}`},j.map(((e,t)=>r.createElement(e,{key:t}))),o.indexCourse?r.createElement(y.A,{index:o.indexCourse,category:o.courseCategoryName}):"",r.createElement(u.Z.Provider,{value:{images:i.nodes,basePath:T.replace(/\/$/,"")+"/"}},r.createElement(a.xA,{components:{Image:p.A}},s)))),r.createElement(E.A,{nextPost:M,lastPost:C,keyCurrent:q,section:x}))}function z(e){return r.createElement(k,e,r.createElement(o,e))}function M(e){var t,n,a,l,i;let{data:s}=e;const{frontmatter:o}=s.mdx,c=o.titleSEO||o.title,h=o.titleOG||c,d=o.titleTwitter||c,u=o.descSEO||o.desc,p=o.descOG||u,g=o.descTwitter||u,v=o.schemaType||"BlogPosting",E=o.keywordsSEO,b=o.date,y=o.updated||b,_=o.imageOG||(null===(t=o.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.gatsbyImageData)||void 0===a||null===(l=a.images)||void 0===l||null===(i=l.fallback)||void 0===i?void 0:i.src),w=o.imageAltOG||p,x=o.imageTwitter||_,S=o.imageAltTwitter||g,H=o.canonicalURL,k=o.flagHidden||!1,z=o.mainTag||"Posts",M=o.slug.split("/")[1]||"posts",{siteUrl:C}=(0,m.Q)(),V={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:C},{"@type":"ListItem",position:2,name:z,item:`${C}/${o.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${C}${o.slug}`}]};return r.createElement(f.A,{title:c+" - avrtt.blog",titleOG:h,titleTwitter:d,description:u,descriptionOG:p,descriptionTwitter:g,schemaType:v,keywords:E,datePublished:b,dateModified:y,imageOG:_,imageAltOG:w,imageTwitter:x,imageAltTwitter:S,canonicalUrl:H,flagHidden:k,mainTag:z,section:M,type:"article"},r.createElement("script",{type:"application/ld+json"},JSON.stringify(V)))}},90548:function(e,t,n){var a=n(96540),r=n(7978);t.A=e=>{let{text:t}=e;return a.createElement(r.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-pages-posts-research-rnn-architecture-mdx-fc29fb68349645862ba0.js.map