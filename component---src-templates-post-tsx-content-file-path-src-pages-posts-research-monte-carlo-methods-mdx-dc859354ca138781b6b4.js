"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[2010],{42249:function(e,t,a){a.r(t),a.d(t,{Head:function(){return A},PostTemplate:function(){return k},default:function(){return _}});var n=a(28453),i=a(96540),r=a(61992),l=a(62087),o=a(90548);function s(e){const t=Object.assign({p:"p",h2:"h2",a:"a",span:"span",h3:"h3",ol:"ol",li:"li",ul:"ul",strong:"strong"},(0,n.RP)(),e.components),{Image:a}=t;return a||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),i.createElement(i.Fragment,null,"\n",i.createElement("br"),"\n","\n",i.createElement(t.p,null,"Monte Carlo methods are a broad class of computational algorithms that rely on random sampling to approximate complex mathematical quantities. Historically, these methods trace their origins to the mid-20th century, notably during the Manhattan Project, where researchers encountered extremely intricate integrals and discovered that randomized procedures offered a remarkably effective strategy for approximating solutions. Over the decades, Monte Carlo algorithms have become indispensable in a variety of domains ranging from physics and computational chemistry to economics and modern machine learning."),"\n",i.createElement(t.p,null,"In this course, Monte Carlo methods appear after our discussions on markov models, sampling, and the broader context of statistical modeling. By now, we have already encountered the notion of a ",i.createElement(r.A,null,"Markov chain"),", which offers a sequence of random variables wherein the conditional distribution of future states depends only on the current state. We also explored how sampling from certain probability distributions is central to many machine learning tasks, especially when these distributions are too complex or high-dimensional for direct analytical solutions. Monte Carlo methods tie these threads together, providing a framework for systematically sampling from challenging distributions, especially in the context of Bayesian inference and advanced generative modeling."),"\n",i.createElement(t.p,null,"At a high level, the power of Monte Carlo approaches lies in their ability to simulate random draws from a target distribution — or at least a very close approximation — and then use these samples to compute expectations, probabilities, normalizing constants, or other quantities of interest. In modern machine learning, particularly in Bayesian deep learning and probabilistic modeling, we frequently encounter intractable integrals over high-dimensional parameter spaces. Monte Carlo solutions circumvent direct integration by numerical approximation, often in a way that is feasible even when explicit forms are unavailable."),"\n",i.createElement(t.p,null,"The primary focus here is ",i.createElement(r.A,null,"Markov Chain Monte Carlo (MCMC)"),", a particular set of Monte Carlo methods that constructs an ergodic Markov chain with the desired target distribution as its stationary distribution. MCMC has had a transformative effect on Bayesian data analysis and remains a staple in large-scale, complex models. Throughout these chapters, I will also shed light on specialized approaches such as Gibbs sampling, the Metropolis-Hastings algorithm, slice sampling, and the hybrid (Hamiltonian) Monte Carlo method. Each approach has its strengths and weaknesses, which I will detail in the coming sections."),"\n",i.createElement(t.p,null,"Monte Carlo methods are not restricted to Bayesian statistics; they also appear in everything from reinforcement learning (where policy gradients might incorporate various Monte Carlo estimates) to generative adversarial networks (which rely on sampling from high-dimensional distributions). However, I will place an emphasis on their common usage in Bayesian settings because that is where their role is especially prominent and theoretically elegant. My aim is to show why these approaches are powerful yet sometimes tricky to deploy, and how to mitigate practical issues like slow mixing or poor acceptance rates."),"\n",i.createElement(t.p,null,"Lastly, I want to emphasize that Monte Carlo methods are not just an academic curiosity — they are used in real-world systems at scale. Whether you are building Bayesian neural networks in healthcare or analyzing complex hierarchical data in astrophysics, MCMC-based sampling can offer a rigorous path to quantifying uncertainty in parameters and predictions. By the end of this long-form article, you should have a deep theoretical and practical understanding of the core ideas, be able to confidently select and implement different types of Monte Carlo algorithms, and appreciate how they fit into the larger tapestry of advanced machine learning techniques."),"\n",i.createElement(t.h2,{id:"2-markov-chain-monte-carlo",style:{position:"relative"}},i.createElement(t.a,{href:"#2-markov-chain-monte-carlo","aria-label":"2 markov chain monte carlo permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2. markov chain monte carlo"),"\n",i.createElement(t.h3,{id:"21-recap-of-markov-chain-properties",style:{position:"relative"}},i.createElement(t.a,{href:"#21-recap-of-markov-chain-properties","aria-label":"21 recap of markov chain properties permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.1. recap of markov chain properties"),"\n",i.createElement(t.p,null,"In previous discussions, we explored the properties of Markov chains. A Markov chain is a sequence of random variables ",i.createElement(o.A,{text:"\\(X_0, X_1, X_2, \\ldots\\)"})," such that each ",i.createElement(o.A,{text:"\\(X_{n+1}\\)"})," depends on ",i.createElement(o.A,{text:"\\(X_n\\)"})," but is conditionally independent of all the preceding states:"),"\n",i.createElement(o.A,{text:"\\[\np(X_{n+1} \\mid X_n, \\ldots, X_1) = p(X_{n+1} \\mid X_n).\n\\]"}),"\n",i.createElement(t.p,null,"This Markov property significantly simplifies model specification and analysis. A Markov chain is specified by its state space (which can be discrete or continuous) and a transition distribution ",i.createElement(o.A,{text:"\\(p(X_{n+1} \\mid X_n)\\)"}),". Under certain regularity conditions — such as ergodicity (every state can be reached from any other state with non-zero probability across some number of transitions, plus other technical constraints) — a Markov chain will converge to a unique stationary distribution ",i.createElement(o.A,{text:"\\(\\pi\\)"}),". Once in stationarity, the distribution of ",i.createElement(o.A,{text:"\\(X_n\\)"})," does not change with ",i.createElement(o.A,{text:"\\(n\\)"}),"."),"\n",i.createElement(t.h3,{id:"22-the-core-idea-behind-mcmc",style:{position:"relative"}},i.createElement(t.a,{href:"#22-the-core-idea-behind-mcmc","aria-label":"22 the core idea behind mcmc permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.2. the core idea behind mcmc"),"\n",i.createElement(t.p,null,"The key to Markov Chain Monte Carlo is constructing a Markov chain whose stationary distribution is exactly (or approximately) our ",i.createElement(r.A,null,"target distribution")," of interest, say ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"}),". Often, this target is a posterior distribution in Bayesian inference problems, or a distribution we want to sample from in a generative model. Rather than attempting to compute ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," directly (which can be intractable in high dimensions), MCMC methods define a transition kernel ",i.createElement(o.A,{text:"\\(T(\\theta' \\mid \\theta)\\)"})," that ensures ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"}),' is the unique stationary distribution of the chain. We then run the chain for many iterations, discard some initial "burn-in" period, and use the subsequent draws as correlated samples from ',i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"}),"."),"\n",i.createElement(t.p,null,"A simplified schematic is:"),"\n",i.createElement(t.ol,null,"\n",i.createElement(t.li,null,"Start from an initial point ",i.createElement(o.A,{text:"\\(\\theta^{(0)}\\)"}),"."),"\n",i.createElement(t.li,null,"Generate a proposed sample ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," from a transition rule dependent on ",i.createElement(o.A,{text:"\\(\\theta^{(t)}\\)"}),"."),"\n",i.createElement(t.li,null,"Decide whether to accept or reject ",i.createElement(o.A,{text:"\\(\\theta'\\)"}),", using an acceptance criterion derived to maintain ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," as stationary."),"\n",i.createElement(t.li,null,"If accepted, let ",i.createElement(o.A,{text:"\\(\\theta^{(t+1)} = \\theta'\\)"}),"; otherwise, let ",i.createElement(o.A,{text:"\\(\\theta^{(t+1)} = \\theta^{(t)}\\)"}),"."),"\n",i.createElement(t.li,null,"Repeat for many steps."),"\n"),"\n",i.createElement(t.h3,{id:"23-common-use-cases-in-discrete-and-continuous-latent-variable-models",style:{position:"relative"}},i.createElement(t.a,{href:"#23-common-use-cases-in-discrete-and-continuous-latent-variable-models","aria-label":"23 common use cases in discrete and continuous latent variable models permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.3. common use cases in discrete and continuous latent variable models"),"\n",i.createElement(t.p,null,"In machine learning, many latent variable models such as latent Dirichlet allocation (used in topic modeling) or hidden Markov models have complex posteriors that can be factorized but remain unnormalized, making direct sampling difficult. MCMC helps us approximate these posteriors:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,"\n",i.createElement(t.p,null,i.createElement(t.strong,null,"Discrete latent variable models"),": For instance, in a Bayesian mixture model with discrete cluster assignments, MCMC can sequentially sample cluster assignments for each data point by conditioning on the current assignments of all other points."),"\n"),"\n",i.createElement(t.li,null,"\n",i.createElement(t.p,null,i.createElement(t.strong,null,"Continuous latent variable models"),": In Bayesian neural networks, each weight is treated as a random variable. MCMC can, in principle, approximate the posterior over weights, though naive MCMC can be quite expensive for large networks."),"\n"),"\n"),"\n",i.createElement(t.p,null,'Moreover, advanced variants of MCMC incorporate gradient information to be more efficient in continuous high-dimensional spaces. Regardless of discrete or continuous nature, the underlying principle is the same: simulate a Markov chain that will hopefully "mix" well across the target distribution.'),"\n",i.createElement(t.h3,{id:"24-stepping-beyond-brute-force-simulation",style:{position:"relative"}},i.createElement(t.a,{href:"#24-stepping-beyond-brute-force-simulation","aria-label":"24 stepping beyond brute force simulation permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.4. stepping beyond brute-force simulation"),"\n",i.createElement(t.p,null,"Why not just do random sampling from ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," in a straightforward manner? Typically, ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," is known only up to a normalization constant. For instance, in Bayesian inference:"),"\n",i.createElement(o.A,{text:"\\[\n\\pi(\\theta \\mid x) = \\frac{p(x \\mid \\theta) \\, p(\\theta)}{p(x)}.\n\\]"}),"\n",i.createElement(t.p,null,"The denominator ",i.createElement(o.A,{text:"\\(p(x)\\)"})," is often an intractable integral. MCMC sidesteps the direct computation of ",i.createElement(o.A,{text:"\\(p(x)\\)"}),' by relying solely on ratios of densities. This elegantly bypasses the need for normalizing constants. However, MCMC introduces correlation between successive samples, leading to potential challenges with respect to the variance of estimators and the time needed to traverse the distribution. A key concept is the idea of "mixing time", which can be long in high-dimensional or multimodal scenarios, but is still frequently more tractable than naive direct sampling.'),"\n",i.createElement(t.h2,{id:"3-the-metropolis-hastings-algorithm",style:{position:"relative"}},i.createElement(t.a,{href:"#3-the-metropolis-hastings-algorithm","aria-label":"3 the metropolis hastings algorithm permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3. the metropolis-hastings algorithm"),"\n",i.createElement(t.h3,{id:"31-proposal-distributions-and-acceptance-ratio",style:{position:"relative"}},i.createElement(t.a,{href:"#31-proposal-distributions-and-acceptance-ratio","aria-label":"31 proposal distributions and acceptance ratio permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.1. proposal distributions and acceptance ratio"),"\n",i.createElement(t.p,null,"The Metropolis-Hastings (MH) algorithm is a cornerstone of MCMC, first introduced by Metropolis and gang (1953) and later generalized by Hastings (1970). At each iteration, you propose a new state ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," from a ",i.createElement(r.A,null,"proposal distribution")," ",i.createElement(o.A,{text:"\\(q(\\theta' \\mid \\theta^{(t)})\\)"}),", and then decide whether to accept or reject it based on an acceptance probability ",i.createElement(o.A,{text:"\\(\\alpha\\)"}),":"),"\n",i.createElement(o.A,{text:"\\[\n\\alpha(\\theta^{(t)}, \\theta') = \\min \\Biggl\\{ 1, \\frac{\\pi(\\theta')\\, q(\\theta^{(t)} \\mid \\theta')}{\\pi(\\theta^{(t)})\\, q(\\theta' \\mid \\theta^{(t)})} \\Biggr\\}.\n\\]"}),"\n",i.createElement(t.p,null,"Here:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," is the target density (up to a constant factor)."),"\n",i.createElement(t.li,null,i.createElement(o.A,{text:"\\(q(\\theta' \\mid \\theta)\\)"})," is the proposal density that suggests candidate updates."),"\n",i.createElement(t.li,null,i.createElement(o.A,{text:"\\(\\alpha\\)"})," ensures that in equilibrium, the chain adheres to ",i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"}),"."),"\n"),"\n",i.createElement(t.p,null,"Intuitively, if ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," has higher posterior density than ",i.createElement(o.A,{text:"\\(\\theta^{(t)}\\)"}),", it's more likely to be accepted; if it's lower, it might still be accepted, but with a probability less than 1. This mechanism encourages the chain to \"explore\" but not get stuck entirely in one region."),"\n",i.createElement(t.h3,{id:"32-balancing-exploration-vs-acceptance-rate",style:{position:"relative"}},i.createElement(t.a,{href:"#32-balancing-exploration-vs-acceptance-rate","aria-label":"32 balancing exploration vs acceptance rate permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.2. balancing exploration vs. acceptance rate"),"\n",i.createElement(t.p,null,"One of the biggest practical challenges in MH is to choose the right proposal distribution ",i.createElement(o.A,{text:"\\(q(\\cdot \\mid \\theta)\\)"}),". Common choices include symmetric random walks such as a Gaussian:"),"\n",i.createElement(o.A,{text:"\\[\n\\theta' = \\theta^{(t)} + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\Sigma).\n\\]"}),"\n",i.createElement(t.p,null,"When ",i.createElement(o.A,{text:"\\(q\\)"})," is symmetric (",i.createElement(o.A,{text:"\\(q(a \\mid b) = q(b \\mid a)\\)"}),"), the acceptance ratio simplifies to"),"\n",i.createElement(o.A,{text:"\\[\n\\alpha(\\theta^{(t)}, \\theta') = \\min\\Bigl\\{1, \\frac{\\pi(\\theta')}{\\pi(\\theta^{(t)})}\\Bigr\\}.\n\\]"}),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,"If ",i.createElement(o.A,{text:"\\(\\Sigma\\)"})," is too large, the chain might propose states too far from the current location, leading to frequent rejections (low acceptance rate)."),"\n",i.createElement(t.li,null,"If ",i.createElement(o.A,{text:"\\(\\Sigma\\)"})," is too small, the chain takes tiny steps and might traverse the space very slowly (high acceptance rate but poor exploration)."),"\n"),"\n",i.createElement(t.p,null,"In practice, one often tunes the step size or covariance of the proposal to achieve an acceptance rate in a recommended range (e.g., 0.2 — 0.5 for typical problems, though it can vary). This tuning often must be done adaptively or in multiple pilot runs to converge to an efficient setting."),"\n",i.createElement(t.h3,{id:"33-practical-considerations-in-machine-learning-contexts",style:{position:"relative"}},i.createElement(t.a,{href:"#33-practical-considerations-in-machine-learning-contexts","aria-label":"33 practical considerations in machine learning contexts permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.3. practical considerations in machine learning contexts"),"\n",i.createElement(t.p,null,"In large-scale machine learning, naive Metropolis-Hastings can be expensive because each proposed update often requires evaluation of a high-dimensional posterior. For instance, a Bayesian neural network with millions of parameters can be extremely cumbersome to evaluate for each proposal. Some strategies to mitigate these challenges include:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Parallelization"),": Evaluate multiple chains simultaneously (if resources permit)."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Adaptive proposals"),": Use something like the adaptive Metropolis algorithm, which tunes ",i.createElement(o.A,{text:"\\(\\Sigma\\)"})," on-the-fly based on the empirical covariance of previously accepted states."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Surrogate models"),": Train approximate surrogates or use partial gradient information to propose new states that are more likely to be accepted."),"\n"),"\n",i.createElement(t.p,null,"Despite these complexities, Metropolis-Hastings remains conceptually simple and widely used, particularly in moderate to high dimensional settings where specialized alternatives, such as Gibbs or Hamiltonian Monte Carlo, are less straightforward to implement."),"\n",i.createElement(t.h3,{id:"34-code-snippet-a-simple-metropolis-hastings-in-python",style:{position:"relative"}},i.createElement(t.a,{href:"#34-code-snippet-a-simple-metropolis-hastings-in-python","aria-label":"34 code snippet a simple metropolis hastings in python permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.4. code snippet: a simple metropolis-hastings in python"),"\n",i.createElement(t.p,null,"Below is a minimal Python snippet illustrating Metropolis-Hastings for sampling from a univariate posterior. Assume we have a target unnormalized density ",i.createElement(o.A,{text:"\\(p(\\theta)\\)"}),", represented by a function ",i.createElement(o.A,{text:"target_density"}),"."),"\n",i.createElement(l.A,{text:'\nimport numpy as np\n\ndef target_density(theta):\n    # Example: unnormalized posterior for demonstration\n    # Let\'s say p(theta) ~ exp(-theta^2/2), i.e. Gaussian(0,1)\n    return np.exp(-theta**2 / 2)\n\ndef metropolis_hastings(target, n_samples=10000, init=0.0, proposal_std=1.0):\n    samples = np.zeros(n_samples)\n    current = init\n    current_p = target(current)\n    \n    for i in range(n_samples):\n        proposal = current + np.random.normal(0, proposal_std)\n        proposal_p = target(proposal)\n        \n        # Acceptance ratio\n        alpha = proposal_p / current_p\n        # Compare alpha to a uniform random threshold\n        if np.random.rand() < alpha:\n            current = proposal\n            current_p = proposal_p\n        \n        samples[i] = current\n    \n    return samples\n\n# Example usage\nsamples = metropolis_hastings(target_density, n_samples=5000)\nprint("Mean of samples:", np.mean(samples))\nprint("Std of samples:", np.std(samples))\n'}),"\n",i.createElement(t.p,null,"This code uses a simple Gaussian(0, 1) target, but we do not need to specify any normalizing constant because the ratio in the acceptance step cancels it out. Note that in practice, one might have more complicated ",i.createElement(o.A,{text:"\\(p(\\theta)\\)"})," and also might tune ",i.createElement(o.A,{text:"proposal_std"})," carefully to get a good acceptance rate."),"\n",i.createElement(t.h2,{id:"4-gibbs-sampling",style:{position:"relative"}},i.createElement(t.a,{href:"#4-gibbs-sampling","aria-label":"4 gibbs sampling permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4. gibbs sampling"),"\n",i.createElement(t.h3,{id:"41-conditional-sampling-as-a-special-case-of-metropolis-hastings",style:{position:"relative"}},i.createElement(t.a,{href:"#41-conditional-sampling-as-a-special-case-of-metropolis-hastings","aria-label":"41 conditional sampling as a special case of metropolis hastings permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.1. conditional sampling as a special case of metropolis-hastings"),"\n",i.createElement(t.p,null,"Gibbs sampling is an important MCMC technique often used in hierarchical Bayesian models, latent variable models, and other high-dimensional problems. It can be viewed as a special case of Metropolis-Hastings where the proposal distribution is taken from the full conditional distributions of each variable. More concretely, suppose we have parameters ",i.createElement(o.A,{text:"\\(\\theta = (\\theta_1, \\theta_2, \\ldots, \\theta_d)\\)"}),". In a Gibbs sampler, we cycle through each coordinate, sampling:"),"\n",i.createElement(o.A,{text:"\\[\n\\theta_1^{(t+1)} \\sim p(\\theta_1 \\mid \\theta_2^{(t)}, \\theta_3^{(t)}, \\ldots, \\theta_d^{(t)}),\n\\]"}),"\n",i.createElement(o.A,{text:"\\[\n\\theta_2^{(t+1)} \\sim p(\\theta_2 \\mid \\theta_1^{(t+1)}, \\theta_3^{(t)}, \\ldots, \\theta_d^{(t)}),\n\\]"}),"\n",i.createElement(t.p,null,"and so on. Because we are sampling from the exact conditional distribution, the acceptance probability is always 1. This eliminates the Metropolis-Hastings acceptance-rejection step and can be simpler to implement if the conditional distributions are easy to sample from."),"\n",i.createElement(t.h3,{id:"42-blocked-gibbs-sampling-vs-full-conditional-updates",style:{position:"relative"}},i.createElement(t.a,{href:"#42-blocked-gibbs-sampling-vs-full-conditional-updates","aria-label":"42 blocked gibbs sampling vs full conditional updates permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.2. blocked gibbs sampling vs. full conditional updates"),"\n",i.createElement(t.p,null,'While the basic Gibbs algorithm updates each parameter sequentially, sometimes it is more efficient to update a subset (or "block") of parameters simultaneously, using their joint conditional distribution. This approach is called ',i.createElement(r.A,null,"blocked Gibbs sampling"),". The advantage is that updating a block might reduce correlations among parameters and speed up mixing, but it requires that the joint conditional distribution for that block be tractable to sample from."),"\n",i.createElement(t.p,null,"In many advanced models, certain subsets of parameters have conjugate forms (e.g., a Gaussian prior leads to a Gaussian posterior). We can exploit that structure for direct sampling in large blocks."),"\n",i.createElement(t.h3,{id:"43-convergence-and-mixing-properties",style:{position:"relative"}},i.createElement(t.a,{href:"#43-convergence-and-mixing-properties","aria-label":"43 convergence and mixing properties permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.3. convergence and mixing properties"),"\n",i.createElement(t.p,null,"Gibbs sampling can converge quickly if the conditional distributions are straightforward to sample from and if the variables are not too strongly correlated. However, in high-dimensional models where variables exhibit strong dependencies, simple coordinate-wise Gibbs can mix poorly. Blocked Gibbs or specialized transformations might be needed to sample efficiently."),"\n",i.createElement(t.h3,{id:"44-example-gibbs-sampling-for-a-bivariate-normal",style:{position:"relative"}},i.createElement(t.a,{href:"#44-example-gibbs-sampling-for-a-bivariate-normal","aria-label":"44 example gibbs sampling for a bivariate normal permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.4. example: gibbs sampling for a bivariate normal"),"\n",i.createElement(t.p,null,"To illustrate the core logic, consider a two-dimensional Gaussian where the conditional distributions are also Gaussian. Let's show the code:"),"\n",i.createElement(l.A,{text:'\nimport numpy as np\n\ndef sample_bivariate_normal_gibbs(mu, sigma, n_samples=10000):\n    """\n    mu: [mu1, mu2]\n    sigma: 2x2 covariance matrix\n    """\n    # We\'ll store the samples in an array\n    samples = np.zeros((n_samples, 2))\n    # Start from some initial guess\n    current = np.array([0.0, 0.0])\n    \n    # Precompute components we need for conditional distributions\n    # Covariance matrix: sigma = [[sigma11, sigma12],[sigma21, sigma22]]\n    sigma11 = sigma[0, 0]\n    sigma22 = sigma[1, 1]\n    sigma12 = sigma[0, 1]\n    rho = sigma12 / (np.sqrt(sigma11 * sigma22))\n    \n    # We\'ll do a simple approach ignoring partial correlation details,\n    # but in practice you can find the conditional distribution formulas:\n    # X1 | X2 ~ Normal(mu1 + rho * (X2 - mu2) * (sqrt(sigma11)/sqrt(sigma22)), (1-rho^2)*sigma11)\n    # and similarly for X2 | X1.\n    \n    for i in range(n_samples):\n        # sample X1 given X2\n        x2 = current[1]\n        cond_mean_1 = mu[0] + (rho * (x2 - mu[1]) * (np.sqrt(sigma11)/np.sqrt(sigma22)))\n        cond_var_1 = (1 - rho**2) * sigma11\n        x1_new = np.random.normal(cond_mean_1, np.sqrt(cond_var_1))\n        \n        # sample X2 given X1\n        x1 = x1_new\n        cond_mean_2 = mu[1] + (rho * (x1 - mu[0]) * (np.sqrt(sigma22)/np.sqrt(sigma11)))\n        cond_var_2 = (1 - rho**2) * sigma22\n        x2_new = np.random.normal(cond_mean_2, np.sqrt(cond_var_2))\n        \n        current = np.array([x1_new, x2_new])\n        samples[i] = current\n        \n    return samples\n\n# Example usage\nmu = np.array([0, 0])\nsigma = np.array([[1, 0.8],[0.8, 1]])\nsamples = sample_bivariate_normal_gibbs(mu, sigma, 5000)\nprint("Sample mean:", np.mean(samples, axis=0))\nprint("Sample cov:\n", np.cov(samples.T))\n'}),"\n",i.createElement(t.p,null,'Conceptually, this example demonstrates how straightforward it can be to implement Gibbs sampling when conditional distributions are easy to sample. For complicated models (e.g., hierarchical Bayesian structures with multiple random effects), each "Gibbs update" might still require some algebra but is typically more direct than designing a good Metropolis-Hastings proposal.'),"\n",i.createElement(t.h2,{id:"5-slice-sampling",style:{position:"relative"}},i.createElement(t.a,{href:"#5-slice-sampling","aria-label":"5 slice sampling permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5. slice sampling"),"\n",i.createElement(t.h3,{id:"51-conceptual-overview",style:{position:"relative"}},i.createElement(t.a,{href:"#51-conceptual-overview","aria-label":"51 conceptual overview permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.1. conceptual overview"),"\n",i.createElement(t.p,null,"Slice sampling is an alternative Monte Carlo method that adapts proposals based on the shape of the target distribution ",i.createElement(o.A,{text:"\\(p(\\theta)\\)"}),". Instead of directly proposing ",i.createElement(o.A,{text:"\\(\\theta'\\)"}),", slice sampling introduces an auxiliary variable ",i.createElement(o.A,{text:"\\(u\\)"}),' that defines a horizontal "slice" of the density function. Formally, we sample:'),"\n",i.createElement(o.A,{text:"\\[\nu \\sim \\text{Uniform}(0, p(\\theta^{(t)})),\n\\]"}),"\n",i.createElement(t.p,null,"Then, we define the slice ",i.createElement(o.A,{text:"\\(S = \\{\\theta : p(\\theta) \\ge u\\}\\)"}),". Our task becomes sampling a new ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," uniformly from ",i.createElement(o.A,{text:"\\(S\\)"}),". In one dimension, this can be done via a procedure known as stepping out and shrinkage. Intuitively, we first find an interval in which the slice ",i.createElement(o.A,{text:"\\(S\\)"})," is contained (stepping out), and then we repeatedly narrow down this interval until we isolate a single region containing a valid new sample (shrinkage)."),"\n",i.createElement(t.h3,{id:"52-implementation-details-stepping-out-and-shrinkage-steps",style:{position:"relative"}},i.createElement(t.a,{href:"#52-implementation-details-stepping-out-and-shrinkage-steps","aria-label":"52 implementation details stepping out and shrinkage steps permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.2. implementation details: stepping-out and shrinkage steps"),"\n",i.createElement(t.ol,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Stepping-out"),": Start from a point ",i.createElement(o.A,{text:"\\(\\theta^{(t)}\\)"})," and randomly choose a direction left or right in small increments to find an interval ",i.createElement(o.A,{text:"\\([L, R]\\)"})," that covers the entire slice ",i.createElement(o.A,{text:"\\(\\{\\theta: p(\\theta) \\ge u\\}\\)"}),"."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Shrinkage"),": Once we have an interval known to contain the slice, we repeatedly draw a candidate ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," from this interval. If ",i.createElement(o.A,{text:"p(\\theta') \\ge u"})," (meaning ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," is in the slice), we move on; otherwise, we shrink the interval around ",i.createElement(o.A,{text:"\\(\\theta^{(t)}\\)"})," to exclude ",i.createElement(o.A,{text:"\\(\\theta'\\)"})," and keep trying until we find a valid ",i.createElement(o.A,{text:"\\(\\theta'\\)"}),"."),"\n"),"\n",i.createElement(t.p,null,"Because slice sampling adapts to the local shape of ",i.createElement(o.A,{text:"p(\\theta)"}),", it often converges quickly and does not require manual tuning of a proposal scale (like in Metropolis). However, in higher-dimensional spaces, slice sampling can become more complex. One might apply it coordinate-wise or with clever transformations."),"\n",i.createElement(t.h3,{id:"53-advantages-for-certain-distributions",style:{position:"relative"}},i.createElement(t.a,{href:"#53-advantages-for-certain-distributions","aria-label":"53 advantages for certain distributions permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.3. advantages for certain distributions"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Automatic tuning"),': Since slice sampling attempts to discover an appropriate "slice" automatically, it can avoid the labor of tuning proposal step sizes.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Non-symmetric distributions"),": It can handle distributions with skewness or heavy tails if the stepping-out procedure is done carefully."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Better local adaptation"),": If the density is sharply peaked, the slice method quickly narrows the candidate region."),"\n"),"\n",i.createElement(t.p,null,"However, in high dimensions, the intervals become multi-dimensional regions that can be expensive to explore. Thus, slice sampling is most straightforward in univariate or moderate-dimensional contexts."),"\n",i.createElement(t.h2,{id:"6-the-hybrid-monte-carlo-algorithm",style:{position:"relative"}},i.createElement(t.a,{href:"#6-the-hybrid-monte-carlo-algorithm","aria-label":"6 the hybrid monte carlo algorithm permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6. the hybrid monte carlo algorithm"),"\n",i.createElement(t.h3,{id:"61-combining-hamiltonian-dynamics-with-markov-chains",style:{position:"relative"}},i.createElement(t.a,{href:"#61-combining-hamiltonian-dynamics-with-markov-chains","aria-label":"61 combining hamiltonian dynamics with markov chains permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1. combining hamiltonian dynamics with markov chains"),"\n",i.createElement(t.p,null,'Also referred to as "Hamiltonian Monte Carlo" (HMC) or "Hybrid Monte Carlo", this method uses concepts from physics — specifically Hamiltonian dynamics — to guide proposals in a high-dimensional space more efficiently than naive random walks. It was popularized in the context of Bayesian inference by Neal (1993), and is a mainstay in modern probabilistic software like Stan and PyMC.'),"\n",i.createElement(t.p,null,"The key insight is to introduce an auxiliary momentum variable ",i.createElement(o.A,{text:"\\(p\\)"})," alongside the position variables ",i.createElement(o.A,{text:"\\(\\theta\\)"}),". We define a Hamiltonian function:"),"\n",i.createElement(o.A,{text:"\\[\nH(\\theta, p) = - \\log \\pi(\\theta) + \\frac{1}{2} p^\\top M^{-1} p,\n\\]"}),"\n",i.createElement(t.p,null,"where:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(o.A,{text:"\\(\\pi(\\theta)\\)"})," is our target density (the negative log-likelihood plus the negative log-prior in a Bayesian context)."),"\n",i.createElement(t.li,null,i.createElement(o.A,{text:"\\(p\\)"})," is typically drawn from a Gaussian ",i.createElement(o.A,{text:"\\(\\mathcal{N}(0, M)\\)"})," at the start of each trajectory, with ",i.createElement(o.A,{text:"\\(M\\)"})," as a mass matrix (often the identity or a diagonal approximation)."),"\n",i.createElement(t.li,null,"The first term ",i.createElement(o.A,{text:"\\(- \\log \\pi(\\theta)\\)"})," acts like a potential energy, and the second term ",i.createElement(o.A,{text:"\\(\\frac12 p^\\top M^{-1} p\\)"})," is the kinetic energy."),"\n"),"\n",i.createElement(t.h3,{id:"62-leapfrog-integrator-and-energy-functions",style:{position:"relative"}},i.createElement(t.a,{href:"#62-leapfrog-integrator-and-energy-functions","aria-label":"62 leapfrog integrator and energy functions permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2. leapfrog integrator and energy functions"),"\n",i.createElement(t.p,null,"HMC simulates the dynamics governed by Hamilton's equations for a (discrete) number of leapfrog steps, effectively moving ",i.createElement(o.A,{text:"(\\theta, p)"})," in a direction informed by gradients ",i.createElement(o.A,{text:"\\(\\nabla_\\theta \\log \\pi(\\theta)\\)"}),". A single iteration often looks like this:"),"\n",i.createElement(t.ol,null,"\n",i.createElement(t.li,null,"Sample momentum ",i.createElement(o.A,{text:"\\(p^{(t)} \\sim \\mathcal{N}(0, M)\\)"}),"."),"\n",i.createElement(t.li,null,"Using the leapfrog integrator, simulate Hamiltonian dynamics for ",i.createElement(o.A,{text:"L\\)"})," steps with step size ",i.createElement(o.A,{text:"\\(\\epsilon\\)"}),"."),"\n",i.createElement(t.li,null,"After these ",i.createElement(o.A,{text:"L\\)"})," steps, you get a proposal ",i.createElement(o.A,{text:"(\\theta', p')"}),"."),"\n",i.createElement(t.li,null,"Accept or reject ",i.createElement(o.A,{text:"(\\theta', p')"})," using a Metropolis criterion based on the change in Hamiltonian ",i.createElement(o.A,{text:"\\(\\Delta H = H(\\theta', p') - H(\\theta^{(t)}, p^{(t)})\\)"}),":"),"\n"),"\n",i.createElement(o.A,{text:"\\[\n\\alpha = \\min\\{1, e^{-\\Delta H}\\}.\n\\]"}),"\n",i.createElement(t.p,null,"If accepted, ",i.createElement(o.A,{text:"\\(\\theta^{(t+1)} = \\theta'\\)"}),"; if not, ",i.createElement(o.A,{text:"\\(\\theta^{(t+1)} = \\theta^{(t)}\\)"}),". The momentum ",i.createElement(o.A,{text:"\\(p\\)"})," is usually discarded or resampled for the next iteration to maintain an ergodic chain."),"\n",i.createElement(t.h3,{id:"63-typical-usage-in-continuous-latent-variable-models",style:{position:"relative"}},i.createElement(t.a,{href:"#63-typical-usage-in-continuous-latent-variable-models","aria-label":"63 typical usage in continuous latent variable models permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.3. typical usage in continuous latent variable models"),"\n",i.createElement(t.p,null,"HMC is especially powerful for continuous, high-dimensional distributions where gradient information can guide the sampling away from random walk behavior. This leads to larger effective step sizes, higher acceptance rates, and more rapid exploration of complicated posteriors."),"\n",i.createElement(t.p,null,"However, HMC also requires gradients of the log-likelihood (or log-posterior) with respect to ",i.createElement(o.A,{text:"\\(\\theta\\)"}),". Hence it's well-suited for models where we can compute derivatives via automatic differentiation (like neural networks). In large-scale machine learning contexts, one might also see ",i.createElement(r.A,null,"Stochastic Gradient Langevin Dynamics (SGLD)")," (Welling and Teh, 2011) or ",i.createElement(r.A,null,"Stochastic Gradient Hamiltonian Monte Carlo (SGHMC)")," as variants that use minibatches of data to approximate the gradient."),"\n",i.createElement(t.h3,{id:"64-practical-aspects-of-hmc",style:{position:"relative"}},i.createElement(t.a,{href:"#64-practical-aspects-of-hmc","aria-label":"64 practical aspects of hmc permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.4. practical aspects of hmc"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Choosing step size ",i.createElement(o.A,{text:"\\(\\epsilon\\)"})," and leapfrog steps ",i.createElement(o.A,{text:"\\(L\\)"})),": This can drastically affect performance. Too large a step size or too many leapfrog steps can lead to high rejection rates. Too small or too few can revert the sampler to a random-walk-like behavior. Tools like No-U-Turn Sampler (NUTS) (Hoffman and Gelman, 2014) adapt these parameters automatically."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Mass matrix"),": Setting ",i.createElement(o.A,{text:"\\(M\\)"})," to approximate the covariance of ",i.createElement(o.A,{text:"\\(\\theta\\)"})," can dramatically improve sampling efficiency. Adaptive approaches estimate this during warm-up."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Computational cost"),": Each iteration can be more expensive than naive MH because we must compute gradients multiple times per iteration. But the improved mixing often pays off in fewer overall iterations."),"\n"),"\n",i.createElement(t.h2,{id:"7-the-challenge-of-mixing-between-separated-modes",style:{position:"relative"}},i.createElement(t.a,{href:"#7-the-challenge-of-mixing-between-separated-modes","aria-label":"7 the challenge of mixing between separated modes permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7. the challenge of mixing between separated modes"),"\n",i.createElement(t.h3,{id:"71-why-isolated-modes-cause-sampling-difficulties",style:{position:"relative"}},i.createElement(t.a,{href:"#71-why-isolated-modes-cause-sampling-difficulties","aria-label":"71 why isolated modes cause sampling difficulties permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1. why isolated modes cause sampling difficulties"),"\n",i.createElement(t.p,null,"Many real-world distributions have multiple separated modes — think of a complicated posterior with multiple distinct parameter configurations that yield near-equivalent likelihoods. MCMC methods based on local updates (Metropolis, HMC, Gibbs, slice sampling) can get trapped in one region if there is a substantial energy barrier between modes. Once the chain settles into a local mode, it may take a very long time to move to a different peak, leading to poor mixing."),"\n",i.createElement(t.h3,{id:"72-possible-strategies-to-encourage-exploration",style:{position:"relative"}},i.createElement(t.a,{href:"#72-possible-strategies-to-encourage-exploration","aria-label":"72 possible strategies to encourage exploration permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2. possible strategies to encourage exploration"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Parallel tempering"),' (also known as replica exchange MCMC): Run multiple chains at different "temperatures", allowing them to swap states occasionally. The higher-temperature chains can more easily traverse energy barriers, pulling the lower-temperature chains out of local traps.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Adaptive proposals"),": Continuously refine the proposal covariance in Metropolis-Hastings to better scale steps when in broad or narrow modes."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Mixture proposals"),": Propose from a mixture of local steps and broader global jumps."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Overrelaxation"),": In some cases, you can implement overrelaxed updates that systematically skip across modes in certain structured problems."),"\n"),"\n",i.createElement(t.h3,{id:"73-implications-for-discrete-relaxations-and-large-scale-models",style:{position:"relative"}},i.createElement(t.a,{href:"#73-implications-for-discrete-relaxations-and-large-scale-models","aria-label":"73 implications for discrete relaxations and large scale models permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3. implications for discrete relaxations and large-scale models"),"\n",i.createElement(t.p,null,"Discrete spaces (like large assignment problems) can be especially challenging. One might combine methods: for example, a Gibbs step for local structure plus a parallel tempering step to jump across modes more effectively. In large-scale problems (like Bayesian neural networks), multiple modes can represent drastically different function behaviors. If you want a proper exploration of the posterior, specialized approaches or carefully chosen initializations may be necessary."),"\n",i.createElement(t.h2,{id:"8-advanced-topics-in-monte-carlo-methods",style:{position:"relative"}},i.createElement(t.a,{href:"#8-advanced-topics-in-monte-carlo-methods","aria-label":"8 advanced topics in monte carlo methods permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8. advanced topics in monte carlo methods"),"\n",i.createElement(t.p,null,"In addition to the well-known algorithms above, the field of Monte Carlo sampling is replete with advanced extensions and variations designed to tackle specific bottlenecks. Below, I briefly highlight a few that expand beyond the standard mainstream approaches."),"\n",i.createElement(t.h3,{id:"81-no-u-turn-sampler-nuts",style:{position:"relative"}},i.createElement(t.a,{href:"#81-no-u-turn-sampler-nuts","aria-label":"81 no u turn sampler nuts permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.1. no-u-turn sampler (nuts)"),"\n",i.createElement(t.p,null,"Introduced by Hoffman and Gelman (2014), NUTS is an extension of Hamiltonian Monte Carlo that eliminates the need to choose the number of leapfrog steps ",i.createElement(o.A,{text:"\\(L\\)"}),' manually. Instead, it builds a set of candidate points in each iteration and uses a recursive criterion to decide where to stop. This approach adaptively tunes the trajectory so that the chain doesn\'t "turn back on itself", hence the name "No-U-Turn".'),"\n",i.createElement(t.p,null,"NUTS is popular in software libraries like Stan because it greatly simplifies user-tuning and often yields high-efficiency sampling with minimal user intervention."),"\n",i.createElement(t.h3,{id:"82-reparameterization-strategies",style:{position:"relative"}},i.createElement(t.a,{href:"#82-reparameterization-strategies","aria-label":"82 reparameterization strategies permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.2. reparameterization strategies"),"\n",i.createElement(t.p,null,"In some Bayesian models, poorly scaled parameters can hamper MCMC convergence. A reparameterization that transforms parameters into a space with more favorable geometry can accelerate mixing. For example:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Non-centered parameterization")," in hierarchical models, where we represent parameters as standardized values that are then scaled by hyperparameters."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Riemann manifold HMC")," (Girolami and Calderhead, 2011): modifies the Hamiltonian equations to account for local curvature in the posterior, leading to more efficient exploration in highly anisotropic distributions."),"\n"),"\n",i.createElement(t.h3,{id:"83-population-mc-and-sequential-mc",style:{position:"relative"}},i.createElement(t.a,{href:"#83-population-mc-and-sequential-mc","aria-label":"83 population mc and sequential mc permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.3. population mc and sequential mc"),"\n",i.createElement(t.p,null,"Beyond typical MCMC, there exist population-based methods that maintain a set of samples (a population) and evolve them collectively. For instance, ",i.createElement(r.A,null,"sequential Monte Carlo")," (SMC) can be used to systematically move from a prior distribution to a posterior by gradually introducing the likelihood term. Population-based MCMC (e.g., parallel tempering or differential evolution MCMC) uses multiple interacting chains at once. These methods can robustly handle multimodality and can provide a more global perspective on the target distribution."),"\n",i.createElement(t.h3,{id:"84-variational-approaches-as-alternatives-or-complements",style:{position:"relative"}},i.createElement(t.a,{href:"#84-variational-approaches-as-alternatives-or-complements","aria-label":"84 variational approaches as alternatives or complements permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.4. variational approaches as alternatives or complements"),"\n",i.createElement(t.p,null,"While not strictly Monte Carlo, variational inference can serve as a complementary technique. Sometimes we might initialize MCMC from a variational approximation or use MCMC to fine-tune a variational distribution. The synergy between these two paradigms is an active research area, where hybrid methods attempt to leverage the scalability of variational approximations and the accuracy of MCMC."),"\n",i.createElement(t.h2,{id:"9-diagnosing-and-evaluating-mcmc",style:{position:"relative"}},i.createElement(t.a,{href:"#9-diagnosing-and-evaluating-mcmc","aria-label":"9 diagnosing and evaluating mcmc permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9. diagnosing and evaluating mcmc"),"\n",i.createElement(t.h3,{id:"91-assessing-convergence",style:{position:"relative"}},i.createElement(t.a,{href:"#91-assessing-convergence","aria-label":"91 assessing convergence permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.1. assessing convergence"),"\n",i.createElement(t.p,null,"Even the most refined MCMC methods can get stuck or fail to converge. Typically, we run multiple chains from different initial states and check if they converge to the same distribution of samples. Common metrics and diagnostics include:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"R-hat statistic")," (Gelman-Rubin diagnostic): Compares within-chain and between-chain variances. Values close to 1 indicate convergence."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Effective sample size"),': A measure of how many "independent" samples the chain provides, given the autocorrelation.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Trace plots"),": Visual inspection of the chain's path over iterations."),"\n"),"\n",i.createElement(t.h3,{id:"92-burn-in-and-thinning",style:{position:"relative"}},i.createElement(t.a,{href:"#92-burn-in-and-thinning","aria-label":"92 burn in and thinning permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.2. burn-in and thinning"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Burn-in"),': The initial samples before the chain has "forgotten" its initialization are discarded to reduce bias.'),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Thinning"),": One might store only every ",i.createElement(o.A,{text:"\\(k\\)"}),"-th sample to reduce autocorrelation in the stored sequence. This practice is somewhat controversial, as some argue it might throw away data unnecessarily. But it can help with memory and correlation issues when dealing with large sample sizes."),"\n"),"\n",i.createElement(t.h3,{id:"93-computing-posterior-summaries",style:{position:"relative"}},i.createElement(t.a,{href:"#93-computing-posterior-summaries","aria-label":"93 computing posterior summaries permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"9.3. computing posterior summaries"),"\n",i.createElement(t.p,null,"Once a chain is considered converged, we often compute posterior means, credible intervals, or other summary statistics. For instance, if we want ",i.createElement(o.A,{text:"\\(E[f(\\theta)]\\)"}),", we approximate with an empirical average:"),"\n",i.createElement(o.A,{text:"\\[\n\\frac{1}{N} \\sum_{i=1}^{N} f(\\theta^{(i)}),\n\\]"}),"\n",i.createElement(t.p,null,"where ",i.createElement(o.A,{text:"\\(\\theta^{(i)}\\)"})," are samples post burn-in. Confidence intervals can be derived by looking at quantiles of the sample distribution or using more advanced methods like the highest posterior density interval."),"\n",i.createElement(t.h2,{id:"10-software-tools",style:{position:"relative"}},i.createElement(t.a,{href:"#10-software-tools","aria-label":"10 software tools permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"10. software tools"),"\n",i.createElement(t.p,null,"Modern data science frameworks offer a host of tools that can drastically simplify implementing Monte Carlo methods:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"PyMC"),": A Python library for Bayesian analysis that includes NUTS, Metropolis, and other samplers."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Stan"),": A probabilistic programming language featuring HMC/NUTS as its primary sampler."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"TensorFlow Probability"),": Offers MCMC modules, including HMC and Replica Exchange MCMC, with automatic differentiation."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Pyro"),": Built on PyTorch, providing an extensive suite of inference algorithms (both variational and MCMC-based)."),"\n"),"\n",i.createElement(t.h2,{id:"11-code-example-using-pymc-for-hierarchical-regression",style:{position:"relative"}},i.createElement(t.a,{href:"#11-code-example-using-pymc-for-hierarchical-regression","aria-label":"11 code example using pymc for hierarchical regression permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"11. code example: using pymc for hierarchical regression"),"\n",i.createElement(t.p,null,"Below is a conceptual snippet (not fully tested) that demonstrates how one might do hierarchical Bayesian regression with PyMC:"),"\n",i.createElement(l.A,{text:'\nimport numpy as np\nimport pymc as pm\nimport arviz as az\n\n# Synthetic data\nnp.random.seed(42)\nN = 100\nx = np.random.randn(N)\ntrue_alpha = 2.0\ntrue_beta = -1.0\ntrue_sigma = 0.5\ny = true_alpha + true_beta * x + np.random.normal(0, true_sigma, size=N)\n\n# Build model\nwith pm.Model() as model:\n    alpha = pm.Normal("alpha", mu=0, sigma=1)\n    beta = pm.Normal("beta", mu=0, sigma=1)\n    sigma = pm.HalfNormal("sigma", sigma=1)\n    \n    mu = alpha + beta * x\n    obs = pm.Normal("obs", mu=mu, sigma=sigma, observed=y)\n    \n    # Sample using NUTS\n    trace = pm.sample(draws=2000, tune=1000, cores=1)\n    \naz.plot_trace(trace, var_names=["alpha", "beta", "sigma"])\naz.summary(trace, var_names=["alpha", "beta", "sigma"])\n'}),"\n",i.createElement(t.p,null,"This script sets up a simple regression model where ",i.createElement(o.A,{text:"\\(y\\)"})," depends linearly on ",i.createElement(o.A,{text:"\\(x\\)"})," with a Gaussian noise term. PyMC's ",i.createElement(o.A,{text:"pm.sample"})," automatically runs the NUTS (an HMC variant), returning an ArviZ ",i.createElement(o.A,{text:"trace"})," object we can analyze or visualize. Such high-level frameworks provide an accessible way to leverage advanced MCMC techniques without implementing them from scratch."),"\n",i.createElement(t.h2,{id:"12-advanced-research-directions",style:{position:"relative"}},i.createElement(t.a,{href:"#12-advanced-research-directions","aria-label":"12 advanced research directions permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"12. advanced research directions"),"\n",i.createElement(t.p,null,"Monte Carlo sampling continues to be a vibrant research area. Below are some advanced threads of interest:"),"\n",i.createElement(t.ul,null,"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Stochastic Gradient MCMC"),": Methods that incorporate minibatch gradients to scale MCMC to very large datasets. SGLD (Welling and Teh, 2011) is an early example; more refined variants like SGHMC attempt to correct for the noise introduced by partial data."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"MCMC for discrete structures"),": Graphical models, combinatorial optimization, or big discrete-latent spaces remain challenging. Specialized methods that carefully design proposals or use partial enumeration are under active development."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Transdimensional MCMC"),": Reversible jump MCMC (Green, 1995) and related methods for model selection tasks where the dimension of the parameter space can change across samples."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Normalizing flows"),": A synergy of Monte Carlo with invertible transformations (flows) that can help define more flexible proposals or reparameterizations for advanced models (Papamakarios and gang, 2019)."),"\n",i.createElement(t.li,null,i.createElement(t.strong,null,"Neural network-based proposals"),": Some approaches train neural networks to learn an approximate distribution that is used as a proposal in Metropolis-Hastings or importance sampling (e.g., Bayesian large-scale deep generative modeling tasks)."),"\n"),"\n",i.createElement(t.h2,{id:"13-visual-illustrations",style:{position:"relative"}},i.createElement(t.a,{href:"#13-visual-illustrations","aria-label":"13 visual illustrations permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"13. visual illustrations"),"\n",i.createElement(t.p,null,"To clarify the geometry and transitions behind MCMC, one might visualize a bivariate distribution and the chain's path. Consider:"),"\n",i.createElement(a,{alt:"2D distribution with MCMC path",path:"",caption:"A typical MCMC chain exploring a 2D Gaussian mixture. The path indicates how correlated steps might jump between modes.",zoom:"false"}),"\n",i.createElement(t.p,null,"Such a figure can highlight how states cluster around modes and occasionally hop to other peaks — or fail to do so if the mixing is insufficient. Another helpful visualization is how HMC trajectories arc through the parameter space, guided by gradient-based momentum."),"\n",i.createElement(a,{alt:"Hamiltonian Monte Carlo trajectories",path:"",caption:"Illustration of HMC leapfrog updates, showing how momentum and potential energy interact to propose new states far from the current position.",zoom:"false"}),"\n",i.createElement(t.h2,{id:"14-conclusion-and-outlook",style:{position:"relative"}},i.createElement(t.a,{href:"#14-conclusion-and-outlook","aria-label":"14 conclusion and outlook permalink",className:"anchor before"},i.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"14. conclusion and outlook"),"\n",i.createElement(t.p,null,'Monte Carlo methods sit at the very heart of modern statistical analysis and machine learning, offering a direct, intuitive way to handle complex distributions that defy closed-form solutions. By casting the problem of "computing complicated integrals" into a problem of "smartly generating random samples," Monte Carlo algorithms open the door to in-depth Bayesian inference, deep generative modeling, robust uncertainty quantification, and beyond.'),"\n",i.createElement(t.p,null,"From the foundational Metropolis-Hastings scheme, through the specialized Gibbs sampler, to advanced gradient-informed strategies like Hamiltonian Monte Carlo, we see that each approach attempts to tackle the same central challenge — exploring the intricate nooks and crannies of a probability distribution. The choice of method depends heavily on the structure of the model, the nature of the data, and practical computational constraints."),"\n",i.createElement(t.p,null,"Although MCMC is well-established, its limitations in high-dimensional, multimodal spaces demand vigilance. Tuning or advanced methods (e.g., parallel tempering, adaptive proposals, or reparameterizations) can mitigate slow mixing, while bridging tools like sequential Monte Carlo or normalizing flows broaden the possibilities for sampling from extremely complicated distributions. Research is ongoing to unify deep learning with Monte Carlo inference, to exploit GPU acceleration, and to integrate approximate inference in a way that retains the theoretical rigor of sampling-based approaches."),"\n",i.createElement(t.p,null,"I encourage you to experiment with multiple MCMC libraries, attempt to implement small-scale Metropolis samplers yourself, and monitor convergence carefully. With practice, you will gain an intuition for how to diagnose slow mixing or an overzealous acceptance rate. Monte Carlo methods reward patience and iteration in refining both model specification and the sampler's hyperparameters."),"\n",i.createElement(t.p,null,"In the broader context of this course, you should now see how Monte Carlo sampling connects with prior discussions about Markov processes, probability theory, and advanced modeling. It also sets the stage for future topics on advanced Bayesian modeling, hierarchical approaches, and potentially bridging into more specialized or modern variants (like SGMCMC for deep neural networks). In short, Monte Carlo's role in the machine learning toolbox cannot be overstated, and I believe a strong command of MCMC theory and practice will be invaluable for tackling many real-world data science problems."),"\n",i.createElement(t.p,null,"Having traversed the fundamentals and dived into specialized algorithms, you should be equipped with a powerful lens to approach uncertainty and inference in your machine learning endeavors. The next steps in the course will continue building on these ideas as we explore even deeper aspects of generative models, advanced optimization strategies, and potentially specialized sampling frameworks."))}var c=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,n.RP)(),e.components);return t?i.createElement(t,e,i.createElement(s,e)):s(e)};var m=a(54506),h=a(88864),p=a(58481),d=a.n(p),u=a(5984),g=a(43672),f=a(27042),v=a(72031),b=a(81817),y=a(27105),E=a(17265),w=a(2043),x=a(95751),M=a(94328),S=a(80791),C=a(78137);const H=e=>{let{toc:t}=e;if(!t||!t.items)return null;return i.createElement("nav",{className:S.R},i.createElement("ul",null,t.items.map(((e,t)=>i.createElement("li",{key:t},i.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const a=t.replace("#",""),n=document.getElementById(a);n&&n.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&i.createElement(H,{toc:{items:e.items}}))))))};function k(e){let{data:{mdx:t,allMdx:r,allPostImages:l},children:o}=e;const{frontmatter:s,body:c,tableOfContents:h}=t,p=s.index,v=s.slug.split("/")[1],S=r.nodes.filter((e=>e.frontmatter.slug.includes(`/${v}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),k=S.findIndex((e=>e.frontmatter.index===p)),_=S[k+1],A=S[k-1],z=s.slug.replace(/\/$/,""),T=/[^/]*$/.exec(z)[0],I=`posts/${v}/content/${T}/`,{0:B,1:V}=(0,i.useState)(s.flagWideLayoutByDefault),{0:N,1:L}=(0,i.useState)(!1);var q;(0,i.useEffect)((()=>{L(!0);const e=setTimeout((()=>L(!1)),340);return()=>clearTimeout(e)}),[B]),"adventures"===v?q=E.cb:"research"===v?q=E.Qh:"thoughts"===v&&(q=E.T6);const G=d()(c).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,P=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),a=e%60;return a<=30?`~${t}${a>0?".5":""} h`:`~${t+1} h`}(Math.ceil(G/q)+(s.extraReadTimeMin||0)),O=[{flag:s.flagDraft,component:()=>Promise.all([a.e(5850),a.e(9833)]).then(a.bind(a,49833))},{flag:s.flagMindfuckery,component:()=>Promise.all([a.e(5850),a.e(7805)]).then(a.bind(a,27805))},{flag:s.flagRewrite,component:()=>Promise.all([a.e(5850),a.e(8916)]).then(a.bind(a,78916))},{flag:s.flagOffensive,component:()=>Promise.all([a.e(5850),a.e(6731)]).then(a.bind(a,49112))},{flag:s.flagProfane,component:()=>Promise.all([a.e(5850),a.e(3336)]).then(a.bind(a,83336))},{flag:s.flagMultilingual,component:()=>Promise.all([a.e(5850),a.e(2343)]).then(a.bind(a,62343))},{flag:s.flagUnreliably,component:()=>Promise.all([a.e(5850),a.e(6865)]).then(a.bind(a,11627))},{flag:s.flagPolitical,component:()=>Promise.all([a.e(5850),a.e(4417)]).then(a.bind(a,24417))},{flag:s.flagCognitohazard,component:()=>Promise.all([a.e(5850),a.e(8669)]).then(a.bind(a,18669))},{flag:s.flagHidden,component:()=>Promise.all([a.e(5850),a.e(8124)]).then(a.bind(a,48124))}],{0:j,1:X}=(0,i.useState)([]);return(0,i.useEffect)((()=>{O.forEach((e=>{let{flag:t,component:a}=e;t&&a().then((e=>{X((t=>[].concat((0,m.A)(t),[e.default])))}))}))}),[]),i.createElement(f.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},i.createElement(b.A,{postNumber:s.index,date:s.date,updated:s.updated,readTime:P,difficulty:s.difficultyLevel,title:s.title,desc:s.desc,banner:s.banner,section:v,postKey:T,isMindfuckery:s.flagMindfuckery,mainTag:s.mainTag}),i.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},s.otherTags.map(((e,t)=>i.createElement("span",{key:t,className:`noselect ${C.MW}`,style:{margin:"0 5px 5px 0"}},e)))),i.createElement("div",{className:"postBody"},i.createElement(H,{toc:h})),i.createElement("br",null),i.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},i.createElement(f.P.button,{className:`noselect ${M.pb}`,id:M.xG,onClick:()=>{V(!B)},whileTap:{scale:.93}},i.createElement(f.P.div,{className:x.DJ,key:B,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},B?"Switch to default layout":"Switch to wide layout"))),i.createElement("br",null),i.createElement("div",{className:"postBody",style:{margin:B?"0 -14%":"",maxWidth:B?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},i.createElement("div",{className:`${M.P_} ${N?M.Xn:M.qG}`},j.map(((e,t)=>i.createElement(e,{key:t}))),s.indexCourse?i.createElement(w.A,{index:s.indexCourse,category:s.courseCategoryName}):"",i.createElement(u.Z.Provider,{value:{images:l.nodes,basePath:I.replace(/\/$/,"")+"/"}},i.createElement(n.xA,{components:{Image:g.A}},o)))),i.createElement(y.A,{nextPost:_,lastPost:A,keyCurrent:T,section:v}))}function _(e){return i.createElement(k,e,i.createElement(c,e))}function A(e){var t,a,n,r,l;let{data:o}=e;const{frontmatter:s}=o.mdx,c=s.titleSEO||s.title,m=s.titleOG||c,p=s.titleTwitter||c,d=s.descSEO||s.desc,u=s.descOG||d,g=s.descTwitter||d,f=s.schemaType||"BlogPosting",b=s.keywordsSEO,y=s.date,E=s.updated||y,w=s.imageOG||(null===(t=s.banner)||void 0===t||null===(a=t.childImageSharp)||void 0===a||null===(n=a.gatsbyImageData)||void 0===n||null===(r=n.images)||void 0===r||null===(l=r.fallback)||void 0===l?void 0:l.src),x=s.imageAltOG||u,M=s.imageTwitter||w,S=s.imageAltTwitter||g,C=s.canonicalURL,H=s.flagHidden||!1,k=s.mainTag||"Posts",_=s.slug.split("/")[1]||"posts",{siteUrl:A}=(0,h.Q)(),z={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:A},{"@type":"ListItem",position:2,name:k,item:`${A}/${s.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${A}${s.slug}`}]};return i.createElement(v.A,{title:c+" - avrtt.blog",titleOG:m,titleTwitter:p,description:d,descriptionOG:u,descriptionTwitter:g,schemaType:f,keywords:b,datePublished:y,dateModified:E,imageOG:w,imageAltOG:x,imageTwitter:M,imageAltTwitter:S,canonicalUrl:C,flagHidden:H,mainTag:k,section:_,type:"article"},i.createElement("script",{type:"application/ld+json"},JSON.stringify(z)))}},90548:function(e,t,a){var n=a(96540),i=a(7978);t.A=e=>{let{text:t}=e;return n.createElement(i.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-pages-posts-research-monte-carlo-methods-mdx-dc859354ca138781b6b4.js.map