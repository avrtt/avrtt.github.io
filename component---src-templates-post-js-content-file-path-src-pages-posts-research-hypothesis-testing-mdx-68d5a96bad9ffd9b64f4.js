"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[9189],{3962:function(e,t){t.A="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pgo8IS0tIEdlbmVyYXRvcjogQWRvYmUgSWxsdXN0cmF0b3IgMTYuMC4wLCBTVkcgRXhwb3J0IFBsdWctSW4gLiBTVkcgVmVyc2lvbjogNi4wMCBCdWlsZCAwKSAgLS0+CjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+CjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iQ2FwYV8xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB4PSIwcHgiIHk9IjBweCIKCSB3aWR0aD0iNDE2Ljk3OXB4IiBoZWlnaHQ9IjQxNi45NzlweCIgdmlld0JveD0iMCAwIDQxNi45NzkgNDE2Ljk3OSIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNDE2Ljk3OSA0MTYuOTc5OyIKCSB4bWw6c3BhY2U9InByZXNlcnZlIj4KPGc+Cgk8cGF0aCBkPSJNMzU2LjAwNCw2MS4xNTZjLTgxLjM3LTgxLjQ3LTIxMy4zNzctODEuNTUxLTI5NC44NDgtMC4xODJjLTgxLjQ3LDgxLjM3MS04MS41NTIsMjEzLjM3OS0wLjE4MSwyOTQuODUKCQljODEuMzY5LDgxLjQ3LDIxMy4zNzgsODEuNTUxLDI5NC44NDksMC4xODFDNDM3LjI5MywyNzQuNjM2LDQzNy4zNzUsMTQyLjYyNiwzNTYuMDA0LDYxLjE1NnogTTIzNy42LDM0MC43ODYKCQljMCwzLjIxNy0yLjYwNyw1LjgyMi01LjgyMiw1LjgyMmgtNDYuNTc2Yy0zLjIxNSwwLTUuODIyLTIuNjA1LTUuODIyLTUuODIyVjE2Ny44ODVjMC0zLjIxNywyLjYwNy01LjgyMiw1LjgyMi01LjgyMmg0Ni41NzYKCQljMy4yMTUsMCw1LjgyMiwyLjYwNCw1LjgyMiw1LjgyMlYzNDAuNzg2eiBNMjA4LjQ5LDEzNy45MDFjLTE4LjYxOCwwLTMzLjc2Ni0xNS4xNDYtMzMuNzY2LTMzLjc2NQoJCWMwLTE4LjYxNywxNS4xNDctMzMuNzY2LDMzLjc2Ni0zMy43NjZjMTguNjE5LDAsMzMuNzY2LDE1LjE0OCwzMy43NjYsMzMuNzY2QzI0Mi4yNTYsMTIyLjc1NSwyMjcuMTA3LDEzNy45MDEsMjA4LjQ5LDEzNy45MDF6Ii8+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPC9zdmc+Cg=="},12291:function(e,t,n){n.r(t),n.d(t,{Head:function(){return I},PostTemplate:function(){return C},default:function(){return H}});var a=n(54506),i=n(28453),l=n(96540),s=n(66501),r=n(16886),o=n(46295),c=n(96098);function h(e){const t=Object.assign({p:"p",h2:"h2",a:"a",span:"span",h3:"h3",ul:"ul",li:"li",ol:"ol"},(0,i.RP)(),e.components),{Image:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),l.createElement(l.Fragment,null,"\n",l.createElement("br"),"\n","\n",l.createElement(t.p,null,"Hypothesis testing is a cornerstone of statistical inference and a critical tool in the data scientist's toolkit. In essence, it is a systematic procedure for deciding whether observed data provides sufficient evidence to reject or fail to reject an initially assumed premise (often called the ",l.createElement(r.A,null,"null hypothesis"),"). Whether you are evaluating the efficacy of a new drug, testing whether a new marketing strategy leads to better conversion rates, or comparing the performance of machine learning models, hypothesis testing offers a rigorous framework to guide your decisions."),"\n",l.createElement(t.p,null,"Because data in real-world applications can be noisy or limited, it's insufficient to rely on raw intuition or heuristics. ",l.createElement(r.A,null,"Hypothesis testing")," helps quantify the evidence and manage uncertainty. This practice is rooted in classical statistics but remains highly relevant in modern machine learning workflows — especially when dealing with large-scale experiments, such as online A/B testing or hyperparameter tuning."),"\n",l.createElement(t.p,null,"Key concepts in hypothesis testing include the formulation of a null and an alternative hypothesis, understanding error types (Type I and Type II), selecting test statistics, and interpreting significance levels and p-values. In data science, these techniques are often integrated with larger pipelines (e.g., evaluating models or features) and can guide automated decision-making. Researchers have further extended these ideas in advanced settings, such as high-dimensional data or multiple hypothesis testing (Smith and gang, NeurIPS 2022), underscoring hypothesis testing's continued importance and evolution."),"\n",l.createElement(t.h2,{id:"basic-framework-of-hypothesis-testing",style:{position:"relative"}},l.createElement(t.a,{href:"#basic-framework-of-hypothesis-testing","aria-label":"basic framework of hypothesis testing permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Basic framework of hypothesis testing"),"\n",l.createElement(t.h3,{id:"null-and-alternative-hypotheses",style:{position:"relative"}},l.createElement(t.a,{href:"#null-and-alternative-hypotheses","aria-label":"null and alternative hypotheses permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Null and alternative hypotheses"),"\n",l.createElement(t.p,null,"A hypothesis test begins by specifying two statements: the ",l.createElement(r.A,null,"null hypothesis")," (",l.createElement(c.A,{text:"\\(H_0\\)"}),") and the ",l.createElement(r.A,null,"alternative hypothesis")," (",l.createElement(c.A,{text:"\\(H_1\\)"})," or ",l.createElement(c.A,{text:"\\(H_a\\)"}),")."),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"The null hypothesis ",l.createElement(c.A,{text:"\\(H_0\\)"}),': This is usually the "status quo" or the baseline assumption. It often states that there is "no effect" or "no difference." For example, ',l.createElement(c.A,{text:"\\(H_0\\)"}),' might be "the mean difference between two treatments is zero."'),"\n",l.createElement(t.li,null,"The alternative hypothesis ",l.createElement(c.A,{text:"\\(H_1\\)"}),": This represents the new claim we suspect may be true. Continuing our example, ",l.createElement(c.A,{text:"\\(H_1\\)"}),' could be "the mean difference between the two treatments is not zero."'),"\n"),"\n",l.createElement(t.p,null,"The objective of the test is to determine whether the observed data is unlikely enough under ",l.createElement(c.A,{text:"\\(H_0\\)"})," to justify rejecting it in favor of ",l.createElement(c.A,{text:"\\(H_1\\)"}),"."),"\n",l.createElement(t.h3,{id:"type-i-and-type-ii-errors",style:{position:"relative"}},l.createElement(t.a,{href:"#type-i-and-type-ii-errors","aria-label":"type i and type ii errors permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Type I and type II errors"),"\n",l.createElement(t.p,null,"In making a decision about the null hypothesis, two kinds of errors are possible:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Type I error")," (",l.createElement(c.A,{text:"\\\\alpha"}),"): This is the error of rejecting ",l.createElement(c.A,{text:"\\(H_0\\)"}),' when it is actually true. It is also referred to as a "false positive."'),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Type II error")," (",l.createElement(c.A,{text:"\\\\beta"}),"): This is the error of failing to reject ",l.createElement(c.A,{text:"\\(H_0\\)"}),' when it is actually false. It is also referred to as a "false negative."'),"\n"),"\n",l.createElement(t.p,null,"The probability of committing a Type I error is typically denoted by ",l.createElement(c.A,{text:"\\\\alpha"}),", while the probability of committing a Type II error is ",l.createElement(c.A,{text:"\\\\beta"}),"."),"\n",l.createElement(n,{alt:"Graphical illustration of Type I and Type II errors",path:"",caption:"An illustration showing overlapping distributions under the null and alternative hypotheses, highlighting the regions where Type I and Type II errors occur.",zoom:"false"}),"\n",l.createElement(t.h3,{id:"significance-level-and-p-values",style:{position:"relative"}},l.createElement(t.a,{href:"#significance-level-and-p-values","aria-label":"significance level and p values permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Significance level and p-values"),"\n",l.createElement(t.p,null,"The ",l.createElement(r.A,null,"significance level"),", denoted ",l.createElement(c.A,{text:"\\\\alpha"}),", is a threshold that defines the maximum tolerable probability of committing a Type I error. Common values for ",l.createElement(c.A,{text:"\\\\alpha"})," are 0.05, 0.01, or 0.001, depending on how conservative one wishes to be."),"\n",l.createElement(t.p,null,"A ",l.createElement(r.A,null,"p-value")," is the probability of observing data at least as extreme as what we have, assuming ",l.createElement(c.A,{text:"\\(H_0\\)"})," is true. If this probability is below the chosen significance level ",l.createElement(c.A,{text:"\\\\alpha"}),", we reject ",l.createElement(c.A,{text:"\\(H_0\\)"}),". If it is above ",l.createElement(c.A,{text:"\\\\alpha"}),", we fail to reject ",l.createElement(c.A,{text:"\\(H_0\\)"}),"."),"\n",l.createElement(t.p,null,"Formally, the p-value is calculated as:"),"\n",l.createElement(c.A,{text:"\\[\np\\text{-value} = P(\\text{Test Statistic} \\ge \\text{observed value} \\mid H_0 \\text{ is true})\n\\]"}),"\n",l.createElement(t.p,null,"depending on whether the test is one-sided or two-sided, this probability will be calculated accordingly."),"\n",l.createElement(t.h3,{id:"confidence-intervals-and-their-relationship-to-hypothesis-testing",style:{position:"relative"}},l.createElement(t.a,{href:"#confidence-intervals-and-their-relationship-to-hypothesis-testing","aria-label":"confidence intervals and their relationship to hypothesis testing permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Confidence intervals and their relationship to hypothesis testing"),"\n",l.createElement(t.p,null,"A ",l.createElement(r.A,null,"confidence interval")," is a range of values, constructed from the data, that is believed to contain the true parameter (e.g., a mean) with a certain probability (usually 95% or 99%)."),"\n",l.createElement(t.p,null,"The connection between confidence intervals and hypothesis testing is best illustrated by a 95% confidence interval for the mean: if ",l.createElement(c.A,{text:"\\( \\\\mu_0 \\)"})," (the hypothesized mean under ",l.createElement(c.A,{text:"\\(H_0\\)"}),") lies outside this interval, then a test of ",l.createElement(c.A,{text:"\\(H_0: \\\\mu = \\\\mu_0\\)"})," at the 5% significance level would lead you to reject ",l.createElement(c.A,{text:"\\(H_0\\)"}),". Conversely, if ",l.createElement(c.A,{text:"\\( \\\\mu_0 \\)"})," falls inside the interval, you would fail to reject ",l.createElement(c.A,{text:"\\(H_0\\)"})," at that level."),"\n",l.createElement(t.h2,{id:"test-statistics",style:{position:"relative"}},l.createElement(t.a,{href:"#test-statistics","aria-label":"test statistics permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Test statistics"),"\n",l.createElement(t.h3,{id:"definition-of-a-test-statistic",style:{position:"relative"}},l.createElement(t.a,{href:"#definition-of-a-test-statistic","aria-label":"definition of a test statistic permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Definition of a test statistic"),"\n",l.createElement(t.p,null,"A ",l.createElement(r.A,null,"test statistic")," is a numerical summary of the data that encapsulates the evidence against the null hypothesis. In classical hypothesis testing, the procedure typically follows:"),"\n",l.createElement(t.ol,null,"\n",l.createElement(t.li,null,"Compute the test statistic from the sample (e.g., the sample mean, or a standardized version of the sample mean)."),"\n",l.createElement(t.li,null,"Determine the probability of observing this (or a more extreme) statistic under ",l.createElement(c.A,{text:"\\(H_0\\)"}),"."),"\n"),"\n",l.createElement(t.p,null,"Mathematically, a test statistic is often a function of the sample ",l.createElement(c.A,{text:"\\(\\mathbf{X}\\)"}),". We can denote it as ",l.createElement(c.A,{text:"\\(T(\\mathbf{X})\\)"}),". For instance, in a ",l.createElement(r.A,null,"t-test"),", the test statistic is typically a standardized difference between the sample mean and the hypothesized mean."),"\n",l.createElement(t.h3,{id:"distribution-of-test-statistics-z-distribution-t-distribution-etc",style:{position:"relative"}},l.createElement(t.a,{href:"#distribution-of-test-statistics-z-distribution-t-distribution-etc","aria-label":"distribution of test statistics z distribution t distribution etc permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Distribution of test statistics (z-distribution, t-distribution, etc.)"),"\n",l.createElement(t.p,null,"Under the null hypothesis, test statistics follow specific distributions:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Z-distribution"),": When the population variance is known or the sample size is large enough (invoking the Central Limit Theorem), the standardized mean often follows an approximately standard normal distribution."),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"T-distribution"),": When the population variance is unknown and the sample size is relatively small, the test statistic follows a t-distribution with degrees of freedom related to the sample size."),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Chi-squared distribution"),": Commonly appears in variance tests or tests for categorical data (chi-squared tests)."),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"F-distribution"),": Often used in analysis of variance (ANOVA) or comparing two variances."),"\n"),"\n",l.createElement(t.p,null,"The probability (or p-value) is computed based on how extreme the observed test statistic is within the corresponding distribution."),"\n",l.createElement(n,{alt:"Various probability distributions",path:"",caption:"A conceptual overview of the Z, t, and chi-squared distributions and how they vary in shape.",zoom:"false"}),"\n",l.createElement(t.h3,{id:"choosing-the-right-test-statistic-for-your-data",style:{position:"relative"}},l.createElement(t.a,{href:"#choosing-the-right-test-statistic-for-your-data","aria-label":"choosing the right test statistic for your data permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Choosing the right test statistic for your data"),"\n",l.createElement(t.p,null,"Selecting an appropriate test statistic requires careful consideration of:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Data type (continuous, categorical, etc.)"),"\n",l.createElement(t.li,null,"Sample size"),"\n",l.createElement(t.li,null,"Underlying assumptions (e.g., normality, equal variances)"),"\n",l.createElement(t.li,null,"The research question (e.g., difference of means, independence of variables, etc.)"),"\n"),"\n",l.createElement(t.p,null,"In many data science applications, especially with large sample sizes, the Z-based approach may be preferred for computational efficiency. However, for smaller samples or when the population variance is unknown, t-tests or non-parametric tests are more suitable."),"\n",l.createElement(t.h2,{id:"t-tests",style:{position:"relative"}},l.createElement(t.a,{href:"#t-tests","aria-label":"t tests permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"T-tests"),"\n",l.createElement(t.h3,{id:"one-sample-t-test",style:{position:"relative"}},l.createElement(t.a,{href:"#one-sample-t-test","aria-label":"one sample t test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"One-sample t-test"),"\n",l.createElement(t.p,null,"A ",l.createElement(r.A,null,"one-sample t-test")," is used to determine whether the mean of a single group differs significantly from a known or hypothesized mean ",l.createElement(c.A,{text:"\\( \\\\mu_0 \\)"}),"."),"\n",l.createElement(t.p,null,"The test statistic is:"),"\n",l.createElement(c.A,{text:"\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(c.A,{text:"\\( \\bar{X} \\)"})," is the sample mean, ",l.createElement(c.A,{text:"\\( \\mu_0 \\)"})," is the hypothesized mean, ",l.createElement(c.A,{text:"\\( s \\)"})," is the sample standard deviation, and ",l.createElement(c.A,{text:"\\( n \\)"})," is the sample size. This statistic follows a t-distribution with ",l.createElement(c.A,{text:"\\( n - 1 \\)"})," degrees of freedom (assuming the sample is drawn from a normally distributed population or ",l.createElement(s.A,{text:"In practice, with large n, the t-distribution approximates the normal distribution."}),")."),"\n",l.createElement(t.p,null,"If ",l.createElement(c.A,{text:"\\( |T| \\)"})," is large enough (i.e., the corresponding p-value < ",l.createElement(c.A,{text:"\\\\alpha"}),"), we reject ",l.createElement(c.A,{text:"\\(H_0\\)"})," and conclude that the sample mean differs from ",l.createElement(c.A,{text:"\\( \\mu_0 \\)"}),"."),"\n",l.createElement(t.p,null,"Below is a short Python snippet illustrating how to perform a one-sample t-test using ",l.createElement(r.A,null,"scipy.stats"),":"),"\n",l.createElement(o.A,{text:'\nimport numpy as np\nfrom scipy import stats\n\n# Sample data\ndata = np.array([4.2, 3.9, 4.5, 5.1, 4.8])\nmu_0 = 4.0  # Hypothesized mean\n\nt_stat, p_value = stats.ttest_1samp(data, mu_0)\nprint(f"t-statistic = {t_stat}, p-value = {p_value}")\n'}),"\n",l.createElement(t.h3,{id:"independent-two-sample-t-test",style:{position:"relative"}},l.createElement(t.a,{href:"#independent-two-sample-t-test","aria-label":"independent two sample t test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Independent two-sample t-test"),"\n",l.createElement(t.p,null,"An ",l.createElement(r.A,null,"independent two-sample t-test")," examines whether the means of two independent groups differ significantly. Suppose we have two samples ",l.createElement(c.A,{text:"\\(X_1, X_2, ..., X_{n_1}\\)"})," and ",l.createElement(c.A,{text:"\\(Y_1, Y_2, ..., Y_{n_2}\\)"})," from (possibly) two different populations."),"\n",l.createElement(t.p,null,"The test statistic for the ",l.createElement(r.A,null,"equal-variance (pooled)")," version is:"),"\n",l.createElement(c.A,{text:"\\[\nT = \\frac{\\bar{X} - \\bar{Y}}{s_p \\cdot \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(c.A,{text:"\\( \\bar{X} \\)"})," and ",l.createElement(c.A,{text:"\\( \\bar{Y} \\)"})," are the sample means, and ",l.createElement(c.A,{text:"\\( s_p \\)"})," is the pooled standard deviation:"),"\n",l.createElement(c.A,{text:"\\[\ns_p = \\sqrt{\\frac{(n_1 - 1) s_X^2 + (n_2 - 1) s_Y^2}{n_1 + n_2 - 2}}\n\\]"}),"\n",l.createElement(t.p,null,"For the ",l.createElement(r.A,null,"unequal-variance")," (Welch) version, the formula adjusts to avoid assuming equal variances, and the degrees of freedom are approximated by the Welch–Satterthwaite equation."),"\n",l.createElement(t.h3,{id:"paired-t-test",style:{position:"relative"}},l.createElement(t.a,{href:"#paired-t-test","aria-label":"paired t test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Paired t-test"),"\n",l.createElement(t.p,null,"A ",l.createElement(r.A,null,"paired t-test")," is used when the data are paired or dependent, such as measurements before and after a treatment on the same subjects. You can transform the problem into a one-sample t-test by taking the difference between each pair of observations. The test statistic becomes:"),"\n",l.createElement(c.A,{text:"\\[\nT = \\frac{\\bar{D} - 0}{s_D / \\sqrt{n}},\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(c.A,{text:"\\( \\bar{D} \\)"})," is the mean of the differences and ",l.createElement(c.A,{text:"\\( s_D \\)"})," is the standard deviation of the differences."),"\n",l.createElement(t.h3,{id:"assumptions-of-t-tests-and-how-to-verify-them",style:{position:"relative"}},l.createElement(t.a,{href:"#assumptions-of-t-tests-and-how-to-verify-them","aria-label":"assumptions of t tests and how to verify them permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Assumptions of t-tests and how to verify them"),"\n",l.createElement(t.p,null,"All t-tests make several assumptions:"),"\n",l.createElement(t.ol,null,"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Normality"),": The data (or differences in paired designs) should be approximately normally distributed."),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Independence"),": Observations in each group should be independent of each other (unless it is a paired t-test, in which case each pair is dependent, but different pairs remain independent)."),"\n",l.createElement(t.li,null,l.createElement(r.A,null,"Equal variance")," (for the standard two-sample t-test): When performing the pooled variance version, each group should come from a population with the same variance."),"\n"),"\n",l.createElement(t.p,null,"In practice, you can use visual methods (e.g., Q–Q plots) or formal tests (e.g., Shapiro–Wilk for normality, Levene's test for variance) to check these assumptions. When assumptions are significantly violated, alternative methods like the Welch t-test (for unequal variances) or non-parametric tests (e.g., Wilcoxon rank-sum) may be preferable."),"\n",l.createElement(t.h2,{id:"chi-squared-test",style:{position:"relative"}},l.createElement(t.a,{href:"#chi-squared-test","aria-label":"chi squared test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Chi-squared test"),"\n",l.createElement(t.h3,{id:"chi-squared-goodness-of-fit-test",style:{position:"relative"}},l.createElement(t.a,{href:"#chi-squared-goodness-of-fit-test","aria-label":"chi squared goodness of fit test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Chi-squared goodness-of-fit test"),"\n",l.createElement(t.p,null,"The ",l.createElement(r.A,null,"chi-squared goodness-of-fit test")," determines how well an observed frequency distribution matches an expected distribution. For example, suppose you have a categorical variable with ",l.createElement(c.A,{text:"\\( k \\)"})," categories, and you want to see if the distribution of counts across these categories follows a specified theoretical model."),"\n",l.createElement(t.p,null,"The test statistic is:"),"\n",l.createElement(c.A,{text:"\\[\n\\\\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i},\n\\]"}),"\n",l.createElement(t.p,null,"where ",l.createElement(c.A,{text:"\\( O_i \\)"})," is the observed count in category ",l.createElement(c.A,{text:"\\( i \\)"})," and ",l.createElement(c.A,{text:"\\( E_i \\)"})," is the expected count under the null hypothesis. Under ",l.createElement(c.A,{text:"\\(H_0\\)"}),", ",l.createElement(c.A,{text:"\\\\chi^2"})," follows a chi-squared distribution with ",l.createElement(c.A,{text:"\\( k - 1 \\)"})," degrees of freedom (adjusted further if parameters are estimated)."),"\n",l.createElement(t.h3,{id:"chi-squared-test-of-independence-contingency-tables",style:{position:"relative"}},l.createElement(t.a,{href:"#chi-squared-test-of-independence-contingency-tables","aria-label":"chi squared test of independence contingency tables permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Chi-squared test of independence (contingency tables)"),"\n",l.createElement(t.p,null,"The ",l.createElement(r.A,null,"chi-squared test of independence")," evaluates whether two categorical variables are associated. For instance, you might ask if customer gender is independent of whether they respond to a promotional email."),"\n",l.createElement(t.p,null,"You arrange the counts of observations into a contingency table, compute the expected frequencies under independence, then calculate a chi-squared statistic similarly to the goodness-of-fit formula. If the test statistic is large (p-value < ",l.createElement(c.A,{text:"\\\\alpha"}),"), you conclude that the two variables are not independent."),"\n",l.createElement(t.h3,{id:"when-to-use-the-chi-squared-test",style:{position:"relative"}},l.createElement(t.a,{href:"#when-to-use-the-chi-squared-test","aria-label":"when to use the chi squared test permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"When to use the chi-squared test"),"\n",l.createElement(t.p,null,"Chi-squared tests are suitable for:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Categorical data with multiple categories."),"\n",l.createElement(t.li,null,"Testing conformity to an expected theoretical distribution."),"\n",l.createElement(t.li,null,"Checking independence or association between categorical variables (in contingency tables)."),"\n"),"\n",l.createElement(t.p,null,"They rely on the assumption that expected counts in each cell of the contingency table are sufficiently large (a common rule of thumb is at least 5). For smaller expected counts, alternatives like Fisher's exact test might be more reliable."),"\n",l.createElement(t.h2,{id:"additional-considerations-multiple-hypothesis-testing-and-power",style:{position:"relative"}},l.createElement(t.a,{href:"#additional-considerations-multiple-hypothesis-testing-and-power","aria-label":"additional considerations multiple hypothesis testing and power permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Additional considerations: multiple hypothesis testing and power"),"\n",l.createElement(t.p,null,"In data science and machine learning, you may run into scenarios involving many simultaneous hypothesis tests — for example, testing thousands of features for significance at once. Conducting multiple tests inflates the probability of finding false positives. Several advanced methods, such as the ",l.createElement(r.A,null,"Bonferroni correction")," or the ",l.createElement(r.A,null,"False Discovery Rate (FDR)")," procedure, address this issue (Benjamini and Hochberg, JMLR 1995)."),"\n",l.createElement(t.p,null,"Another important concept is the ",l.createElement(r.A,null,"power")," of a test, defined as ",l.createElement(c.A,{text:"\\(1 - \\\\beta\\)"}),", where ",l.createElement(c.A,{text:"\\\\beta"})," is the probability of a Type II error. A test with higher power is better at detecting real effects. Power depends on:"),"\n",l.createElement(t.ul,null,"\n",l.createElement(t.li,null,"Sample size"),"\n",l.createElement(t.li,null,"Effect size (i.e., how large the difference or effect is)"),"\n",l.createElement(t.li,null,"Significance level (",l.createElement(c.A,{text:"\\\\alpha"}),")"),"\n"),"\n",l.createElement(t.p,null,"Balancing ",l.createElement(c.A,{text:"\\\\alpha"}),", ",l.createElement(c.A,{text:"\\\\beta"}),", and sample size is a common challenge in experimental design and can guide practitioners to collect the right amount of data for reliable conclusions."),"\n",l.createElement(t.h2,{id:"conclusion",style:{position:"relative"}},l.createElement(t.a,{href:"#conclusion","aria-label":"conclusion permalink",className:"anchor before"},l.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Conclusion"),"\n",l.createElement(t.p,null,"Hypothesis testing provides a formal mechanism to assess whether a given effect or difference is real or can be attributed to chance. Whether you are comparing means with a t-test or assessing independence with a chi-squared test, understanding the conceptual framework — formulating hypotheses, selecting test statistics, and interpreting p-values and confidence intervals — is vital. These tests form the backbone of quantitative research in data science and machine learning, enabling practitioners to draw inferences from complex datasets with measured confidence."),"\n",l.createElement(t.p,null,"Looking ahead, modern research and industrial applications often involve large-scale or high-dimensional data, leading to challenges in multiple hypothesis testing or ensuring that classical assumptions (normality, independence, etc.) hold. Researchers continue to develop new procedures (e.g., robust testing, permutation-based methods, advanced multiple correction techniques) to keep hypothesis testing both statistically rigorous and practically relevant in the face of big data. By mastering the fundamentals explored here, data scientists can navigate these complexities and make data-driven decisions with confidence."))}var m=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,i.RP)(),e.components);return t?l.createElement(t,e,l.createElement(h,e)):h(e)};var d=n(36710),u=n(58481),p=n.n(u),f=n(36310),g=n(87245),v=n(27042),y=n(59849),E=n(5591),b=n(61122),w=n(9219),x=n(33203),S=n(95751),A=n(94328),z=n(80791),T=n(78137);const M=e=>{let{toc:t}=e;if(!t||!t.items)return null;return l.createElement("nav",{className:z.R},l.createElement("ul",null,t.items.map(((e,t)=>l.createElement("li",{key:t},l.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const n=t.replace("#",""),a=document.getElementById(n);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&l.createElement(M,{toc:{items:e.items}}))))))};function C(e){let{data:{mdx:t,allMdx:s,allPostImages:r},children:o}=e;const{frontmatter:c,body:h,tableOfContents:m}=t,d=c.index,u=c.slug.split("/")[1],y=s.nodes.filter((e=>e.frontmatter.slug.includes(`/${u}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),z=y.findIndex((e=>e.frontmatter.index===d)),C=y[z+1],H=y[z-1],I=c.slug.replace(/\/$/,""),L=/[^/]*$/.exec(I)[0],N=`posts/${u}/content/${L}/`,{0:_,1:j}=(0,l.useState)(c.flagWideLayoutByDefault),{0:k,1:D}=(0,l.useState)(!1);var B;(0,l.useEffect)((()=>{D(!0);const e=setTimeout((()=>D(!1)),340);return()=>clearTimeout(e)}),[_]),"adventures"===u?B=w.cb:"research"===u?B=w.Qh:"thoughts"===u&&(B=w.T6);const V=p()(h).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,P=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),n=e%60;return n<=30?`~${t}${n>0?".5":""} h`:`~${t+1} h`}(Math.ceil(V/B)+(c.extraReadTimeMin||0)),O=[{flag:c.flagDraft,component:()=>Promise.all([n.e(3231),n.e(8809)]).then(n.bind(n,28809))},{flag:c.flagMindfuckery,component:()=>Promise.all([n.e(3231),n.e(2471)]).then(n.bind(n,67709))},{flag:c.flagRewrite,component:()=>Promise.all([n.e(3231),n.e(6764)]).then(n.bind(n,62002))},{flag:c.flagOffensive,component:()=>Promise.all([n.e(3231),n.e(2443)]).then(n.bind(n,17681))},{flag:c.flagProfane,component:()=>Promise.all([n.e(3231),n.e(8048)]).then(n.bind(n,53286))},{flag:c.flagMultilingual,component:()=>Promise.all([n.e(3231),n.e(4069)]).then(n.bind(n,78831))},{flag:c.flagUnreliably,component:()=>Promise.all([n.e(3231),n.e(3417)]).then(n.bind(n,8179))},{flag:c.flagPolitical,component:()=>Promise.all([n.e(3231),n.e(5195)]).then(n.bind(n,30433))},{flag:c.flagCognitohazard,component:()=>Promise.all([n.e(3231),n.e(3175)]).then(n.bind(n,8413))},{flag:c.flagHidden,component:()=>Promise.all([n.e(3231),n.e(9556)]).then(n.bind(n,14794))}],{0:q,1:Y}=(0,l.useState)([]);return(0,l.useEffect)((()=>{O.forEach((e=>{let{flag:t,component:n}=e;t&&n().then((e=>{Y((t=>[].concat((0,a.A)(t),[e.default])))}))}))}),[]),l.createElement(v.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},l.createElement(E.A,{postNumber:c.index,date:c.date,updated:c.updated,readTime:P,difficulty:c.difficultyLevel,title:c.title,desc:c.desc,banner:c.banner,section:u,postKey:L,isMindfuckery:c.flagMindfuckery,mainTag:c.mainTag}),l.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},c.otherTags.map(((e,t)=>l.createElement("span",{key:t,className:`noselect ${T.MW}`,style:{margin:"0 5px 5px 0"}},e)))),l.createElement("div",{class:"postBody"},l.createElement(M,{toc:m})),l.createElement("br"),l.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},l.createElement(v.P.button,{class:"noselect",className:A.pb,id:A.xG,onClick:()=>{j(!_)},whileTap:{scale:.93}},l.createElement(v.P.div,{className:S.DJ,key:_,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},_?"Switch to default layout":"Switch to wide layout"))),l.createElement("br"),l.createElement("div",{class:"postBody",style:{margin:_?"0 -14%":"",maxWidth:_?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},l.createElement("div",{className:`${A.P_} ${k?A.Xn:A.qG}`},q.map(((e,t)=>l.createElement(e,{key:t}))),c.indexCourse?l.createElement(x.A,{index:c.indexCourse,category:c.courseCategoryName}):"",l.createElement(f.Z.Provider,{value:{images:r.nodes,basePath:N.replace(/\/$/,"")+"/"}},l.createElement(i.xA,{components:{Image:g.A}},o)))),l.createElement(b.A,{nextPost:C,lastPost:H,keyCurrent:L,section:u}))}function H(e){return l.createElement(C,e,l.createElement(m,e))}function I(e){var t,n,a,i,s;let{data:r}=e;const{frontmatter:o}=r.mdx,c=o.titleSEO||o.title,h=o.titleOG||c,m=o.titleTwitter||c,u=o.descSEO||o.desc,p=o.descOG||u,f=o.descTwitter||u,g=o.schemaType||"BlogPosting",v=o.keywordsSEO,E=o.date,b=o.updated||E,w=o.imageOG||(null===(t=o.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.gatsbyImageData)||void 0===a||null===(i=a.images)||void 0===i||null===(s=i.fallback)||void 0===s?void 0:s.src),x=o.imageAltOG||p,S=o.imageTwitter||w,A=o.imageAltTwitter||f,z=o.canonicalURL,T=o.flagHidden||!1,M=o.mainTag||"Posts",C=o.slug.split("/")[1]||"posts",{siteUrl:H}=(0,d.Q)(),I={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:H},{"@type":"ListItem",position:2,name:M,item:`${H}/${o.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${H}${o.slug}`}]};return l.createElement(y.A,{title:c+" - avrtt.blog",titleOG:h,titleTwitter:m,description:u,descriptionOG:p,descriptionTwitter:f,schemaType:g,keywords:v,datePublished:E,dateModified:b,imageOG:w,imageAltOG:x,imageTwitter:S,imageAltTwitter:A,canonicalUrl:z,flagHidden:T,mainTag:M,section:C,type:"article"},l.createElement("script",{type:"application/ld+json"},JSON.stringify(I)))}},66501:function(e,t,n){n.d(t,{A:function(){return s}});var a=n(96540),i=n(3962),l="styles-module--tooltiptext--a263b";var s=e=>{let{text:t,isBadge:n=!1}=e;const{0:s,1:r}=(0,a.useState)(!1),o=(0,a.useRef)(null);return(0,a.useEffect)((()=>{function e(e){o.current&&!o.current.contains(e.target)&&r(!1)}return document.addEventListener("click",e),()=>{document.removeEventListener("click",e)}}),[]),a.createElement("span",{className:"styles-module--tooltipWrapper--75ebf",ref:o},a.createElement("img",{id:n?"styles-module--infoBadge--e3d66":"styles-module--info--26c1f",src:i.A,alt:"info",onClick:e=>{e.stopPropagation(),r((e=>!e))}}),a.createElement("span",{className:s?`${l} styles-module--visible--c063c`:l},t))}},96098:function(e,t,n){var a=n(96540),i=n(7978);t.A=e=>{let{text:t}=e;return a.createElement(i.A,null,t)}}}]);
//# sourceMappingURL=component---src-templates-post-js-content-file-path-src-pages-posts-research-hypothesis-testing-mdx-68d5a96bad9ffd9b64f4.js.map