{"version":3,"file":"component---src-templates-post-js-content-file-path-src-pages-posts-research-ai-search-mdx-1c07833e17ddb2e0c6cb.js","mappings":"8RAyEA,SAASA,EAAkBC,GACzB,MAAMC,EAAcC,OAAOC,OAAO,CAChCC,EAAG,IACHC,GAAI,KACJC,GAAI,KACJC,GAAI,KACJC,GAAI,KACJC,EAAG,IACHC,KAAM,OACNC,GAAI,KACJC,GAAI,KACJC,OAAQ,WACPC,EAAAA,EAAAA,MAAsBd,EAAMe,aAAa,MAACC,GAASf,EAEtD,OADKe,GAwgCP,SAA8BC,EAAIC,GAChC,MAAM,IAAIC,MAAM,aAAeD,EAAY,YAAc,UAAY,KAAOD,EAAK,qEACnF,CA1gCcG,CAAqB,SAAS,GACnCC,EAAAA,cAAoBA,EAAAA,SAAgB,KAAM,KAAMA,EAAAA,cAAoB,MAAO,KAAM,KAAM,KAAMA,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qvBAA0vB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gkBAAikB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uuBAAwuB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mDAAoD,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,eAAgBiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,6BAA8Bc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+BAAgCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,oDAAqDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,qDAAsD,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+CAAgDiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,yDAA0Dc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+BAAgCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,mCAAoCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,qBAAsBc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,wCAAyC,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uCAAwCiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,yDAA0Dc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+BAAgCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,6BAA8Bc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+CAAgDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+CAAgD,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yCAA0CiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,iDAAkDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0DAA2Dc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,6BAA8Bc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,wBAAyBc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,4CAA6C,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yCAA0CiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,iEAAkEc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+BAAgCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,wBAAyBc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,sDAAuDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,uCAAwC,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+CAAgDiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0CAA2Cc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,gDAAiDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,mDAAoD,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0CAA2CiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,oDAAqDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,iDAAkDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,iCAAkCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0BAA2Bc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0EAA2E,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+BAAgCiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,mFAAoFc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,yCAA0Cc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,iDAAkDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,4BAA6Bc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,oDAAqDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,2CAA4C,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,sCAAuCiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,wCAAyCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,+CAAgDc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0CAA2Cc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,0BAA2B,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kBAAmBiB,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,yCAA0Cc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,2EAA4Ec,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,4CAA6Cc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,uCAAwCc,EAAAA,cAAoBpB,EAAYM,IAAK,KAAM,wCAAyC,MAAO,MAAO,KAAMc,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uKAAwK,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACliQS,GAAI,+CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gDACN,aAAc,yDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gDAAiD,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9FM,GAAI,mDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,oDACN,aAAc,6DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wDAAyD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yeAA4e,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8bAAmc,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uKAAwK,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,wDAAyDiB,EAAAA,cAAoBO,EAAAA,EAAO,CACn6CC,KAAM,8BACJ,WAAY,KAAMR,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBO,EAAAA,EAAO,CACzIC,KAAM,YACJ,mCAAoC,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBO,EAAAA,EAAO,CACjHC,KAAM,YACJ,uEAAwE,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBO,EAAAA,EAAO,CACrJC,KAAM,sBACJ,wCAAyCR,EAAAA,cAAoBO,EAAAA,EAAO,CACtEC,KAAM,YACJ,aAAcR,EAAAA,cAAoBO,EAAAA,EAAO,CAC3CC,KAAM,YACJ,wBAAyBR,EAAAA,cAAoBO,EAAAA,EAAO,CACtDC,KAAM,aACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBO,EAAAA,EAAO,CACnFC,KAAM,cACJ,0BAA2B,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBO,EAAAA,EAAO,CACxGC,KAAM,yBACJ,+BAAgC,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACnFM,GAAI,6BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,8BACN,aAAc,uCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,8BAA+B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6dAAge,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oUAAqU,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC/8BM,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,kCAAmC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,iDAAkDiB,EAAAA,cAAoBO,EAAAA,EAAO,CAClKC,KAAM,cACJ,sdAAyd,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6SAAgT,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACp2BM,GAAI,mBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,oBACN,aAAc,6BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,oBAAqB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6EAA8E,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mCAAoC,2DAA4D,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,kBAAmB,8DAA+D,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,2BAA4B,kEAAmE,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,wBAAyB,0LAA2L,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mNAAwN,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC11CM,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qFAAsF,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,+FAAgG,KAAMe,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,2EAA4E,KAAMe,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,+FAAgG,KAAMe,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,wFAAyF,MAAO,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+ZAAga,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACpwCS,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACtFM,GAAI,uDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,wDACN,aAAc,iEACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wDAAyD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,utBAA8tB,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACn3BM,GAAI,2BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,4BACN,aAAc,qCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,8BAA+B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qOAAsO,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,gCAAiC,KAAM,KAAMQ,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,8BAA+Be,EAAAA,cAAoBO,EAAAA,EAAO,CACrlBC,KAAM,cACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,SAAUe,EAAAA,cAAoBO,EAAAA,EAAO,CAC7FC,KAAM,cACJ,iCAAkC,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,gCAAiC,KAAMe,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,mBAAoBe,EAAAA,cAAoBO,EAAAA,EAAO,CACpQC,KAAM,YACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,MAAOe,EAAAA,cAAoBO,EAAAA,EAAO,CAC1FC,KAAM,YACJ,0CAA2C,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,kDAAmDe,EAAAA,cAAoBO,EAAAA,EAAO,CAC3KC,KAAM,YACJ,KAAM,MAAO,MAAO,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uDAAwD,KAAMiB,EAAAA,cAAoBS,EAAAA,EAAM,CACpKD,KAAM,48BAmCJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,UAAWiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,YAAa,uHAAwHQ,EAAAA,cAAoBO,EAAAA,EAAO,CAC1QC,KAAM,YACJ,yCAA0CR,EAAAA,cAAoBO,EAAAA,EAAO,CACvEC,KAAM,YACJ,mDAAoDR,EAAAA,cAAoBO,EAAAA,EAAO,CACjFC,KAAM,iBACJ,yKAA0K,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACtNM,GAAI,yBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,0BACN,aAAc,mCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,4BAA6B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,wUAAyU,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,gCAAiC,KAAM,KAAMQ,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,YAAae,EAAAA,cAAoBO,EAAAA,EAAO,CACpqBC,KAAM,cACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,yBAA0Be,EAAAA,cAAoBO,EAAAA,EAAO,CAC7GC,KAAM,cACJ,uEAAwE,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,qDAAsD,MAAO,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,iEAAkE,KAAMiB,EAAAA,cAAoBS,EAAAA,EAAM,CACxUD,KAAM,obAiBJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2CAA4CiB,EAAAA,cAAoBO,EAAAA,EAAO,CACxHC,KAAM,iBACJ,UAAWR,EAAAA,cAAoBO,EAAAA,EAAO,CACxCC,KAAM,YACJ,oMAAqMR,EAAAA,cAAoBO,EAAAA,EAAO,CAClOC,KAAM,gBACJ,wBAAyB,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACrEM,GAAI,0CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,2CACN,aAAc,oDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,8CAA+C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kEAAmEiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC/LC,KAAM,eACJ,8BAA+BR,EAAAA,cAAoBO,EAAAA,EAAO,CAC5DC,KAAM,YACJ,0NAA2N,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,YAAa,2KAA4KQ,EAAAA,cAAoBO,EAAAA,EAAO,CAC9gBC,KAAM,eACJ,sGAAuG,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,wSAAyS,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC3eM,GAAI,4CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,6CACN,aAAc,sDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,6CAA8C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,wLAAyL,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,0EAA2E,KAAMe,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,4EAA6E,KAAMe,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,wFAAyF,MAAO,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2CAA4CiB,EAAAA,cAAoBO,EAAAA,EAAO,CACv0BC,KAAM,iBACJ,kBAAmBR,EAAAA,cAAoBO,EAAAA,EAAO,CAChDC,KAAM,iBACJ,UAAWR,EAAAA,cAAoBO,EAAAA,EAAO,CACxCC,KAAM,YACJ,4BAA6BR,EAAAA,cAAoBO,EAAAA,EAAO,CAC1DC,KAAM,YACJ,oKAAqK,KAAMR,EAAAA,cAAoBpB,EAAYO,GAAI,CACjNS,GAAI,uCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,wCACN,aAAc,iDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,0CAA2C,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACxFM,GAAI,+CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gDACN,aAAc,yDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gDAAiD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0BAA6BiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC3JC,KAAM,eACJ,6DAA8DR,EAAAA,cAAoBO,EAAAA,EAAO,CAC3FC,KAAM,YACJ,iRAAkR,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6QAAgRiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,cAAe,mKAAoK,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CAC91BM,GAAI,sDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,uDACN,aAAc,gEACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,yDAA0D,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4FAA6F,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,iBAAkB,iBAAkBQ,EAAAA,cAAoBO,EAAAA,EAAO,CACrcC,KAAM,eACJ,qBAAsBR,EAAAA,cAAoBO,EAAAA,EAAO,CACnDC,KAAM,4BACJ,YAAaR,EAAAA,cAAoBO,EAAAA,EAAO,CAC1CC,KAAM,YACJ,WAAYR,EAAAA,cAAoBO,EAAAA,EAAO,CACzCC,KAAM,iBACJ,kDAAmDR,EAAAA,cAAoBO,EAAAA,EAAO,CAChFC,KAAM,YACJ,+DAAgE,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,KAAMe,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,iCAAkC,kCAAmCQ,EAAAA,cAAoBO,EAAAA,EAAO,CACtTC,KAAM,yCACJ,wBAAyBR,EAAAA,cAAoBO,EAAAA,EAAO,CACtDC,KAAM,aACJ,OAAQR,EAAAA,cAAoBO,EAAAA,EAAO,CACrCC,KAAM,YACJ,wBAAyBR,EAAAA,cAAoBO,EAAAA,EAAO,CACtDC,KAAM,YACJ,cAAeR,EAAAA,cAAoBO,EAAAA,EAAO,CAC5CC,KAAM,sBACJ,0JAA6J,MAAO,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACvNM,GAAI,2BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,4BACN,aAAc,qCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,4BAA6B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gFAAiFiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC3LC,KAAM,eACJ,8IAA+I,KAAMR,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,YAAa,gGAAiG,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,YAAa,2IAA4IQ,EAAAA,cAAoBO,EAAAA,EAAO,CAC/pBC,KAAM,eACJ,uCAAwC,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CAC3FM,GAAI,qBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,sBACN,aAAc,+BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,uBAAwB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uIAAwI,KAAMiB,EAAAA,cAAoBO,EAAAA,EAAO,CACnPC,KAAM,iCACJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,SAAUiB,EAAAA,cAAoBO,EAAAA,EAAO,CACtFC,KAAM,eACJ,0CAA2CR,EAAAA,cAAoBO,EAAAA,EAAO,CACxEC,KAAM,YACJ,SAAUR,EAAAA,cAAoBO,EAAAA,EAAO,CACvCC,KAAM,eACJ,mCAAoCR,EAAAA,cAAoBO,EAAAA,EAAO,CACjEC,KAAM,YACJ,8DAA+DR,EAAAA,cAAoBO,EAAAA,EAAO,CAC5FC,KAAM,eACJ,kCAAmCR,EAAAA,cAAoBO,EAAAA,EAAO,CAChEC,KAAM,YACJ,sDAAuDR,EAAAA,cAAoBO,EAAAA,EAAO,CACpFC,KAAM,YACJ,0KAA2K,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,sBAAuB,KAAM,KAAMQ,EAAAA,cAAoBS,EAAAA,EAAM,CACvUD,KAAM,ywCA4CJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6IAA8IiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC1NC,KAAM,iBACJ,uJAAwJ,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACpMM,GAAI,yCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,0CACN,aAAc,mDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,0CAA2C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8hBAAiiB,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACxqBS,GAAI,yCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,0CACN,aAAc,mDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,0CAA2C,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACxFM,GAAI,6DACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,8DACN,aAAc,uEACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gEAAiE,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,skBAAukB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gNAAmN,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACt+BM,GAAI,6BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,8BACN,aAAc,uCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,8BAA+B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kUAAmU,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,4BAA6B,yGAA0G,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,8BAA+B,qJAAsJ,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mBAAoB,oGAAqG,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CACpsCM,GAAI,sBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,uBACN,aAAc,gCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,uBAAwB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6eAAkf,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gEAAiEiB,EAAAA,cAAoBO,EAAAA,EAAO,CACvsBC,KAAM,YACJ,aAAcR,EAAAA,cAAoBO,EAAAA,EAAO,CAC3CC,KAAM,aACJ,+BAAgCR,EAAAA,cAAoBO,EAAAA,EAAO,CAC7DC,KAAM,mCACJ,QAAS,KAAMR,EAAAA,cAAoBO,EAAAA,EAAO,CAC5CC,KAAM,uEACJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,SAAUiB,EAAAA,cAAoBO,EAAAA,EAAO,CACtFC,KAAM,YACJ,mCAAoCR,EAAAA,cAAoBO,EAAAA,EAAO,CACjEC,KAAM,wBACJ,iDAAkD,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9FM,GAAI,oDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,qDACN,aAAc,8DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,qDAAsD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oPAAuP,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,kBAAmB,uBAAwB,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,aAAc,6CAA8C,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,aAAc,0DAA2D,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,YAAa,0DAA2D,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,eAAgB,kDAAmD,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2JAA4J,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC55CM,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0FAA2FiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,oBAAqB,OAAQQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,+BAAgC,8XAA+X,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6UAA8U,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CAClnCS,GAAI,+CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gDACN,aAAc,yDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gDAAiD,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9FM,GAAI,wCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,yCACN,aAAc,kDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,yCAA0C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,waAAya,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mBAAoBiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,iBAAkB,yQAA0Q,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CAC57BM,GAAI,8CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,+CACN,aAAc,wDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,+CAAgD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8EAA+EiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,gBAAiB,mOAAsOQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,2DAA4D,0FAA2F,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CACrsBM,GAAI,gDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,iDACN,aAAc,0DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,iDAAkD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8FAA+FiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,iBAAkB,6XAA8XQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,QAAS,gGAAiG,KAAMQ,EAAAA,cAAoBpB,EAAYO,GAAI,CACn0BS,GAAI,wCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,yCACN,aAAc,kDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,2CAA4C,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACzFM,GAAI,8CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,+CACN,aAAc,wDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,mDAAoD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6PAA8PiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,gBAAiB,gGAAiGQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,2BAA4B,KAAMQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,UAAW,2DAA4D,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oCAAqC,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,sBAAuBe,EAAAA,cAAoBO,EAAAA,EAAO,CAC/6BC,KAAM,4CACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,6BAA8Be,EAAAA,cAAoBO,EAAAA,EAAO,CACjHC,KAAM,iBACJ,KAAM,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAM,eAAgBe,EAAAA,cAAoBO,EAAAA,EAAO,CACnGC,KAAM,YACJ,mDAAoD,MAAO,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACvGM,GAAI,+CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gDACN,aAAc,yDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gDAAiD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,wPAAyPiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mBAAoB,8EAA+EQ,EAAAA,cAAoBO,EAAAA,EAAO,CACxgBC,KAAM,YACJ,iDAAkDR,EAAAA,cAAoBO,EAAAA,EAAO,CAC/EC,KAAM,YACJ,wCAAyCR,EAAAA,cAAoBO,EAAAA,EAAO,CACtEC,KAAM,YACJ,cAAe,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CAC3DM,GAAI,+BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gCACN,aAAc,yCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gCAAiC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+OAAgPiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,4BAA6B,uGAAwG,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,WAAY,2CAA4CQ,EAAAA,cAAoBO,EAAAA,EAAO,CACtqBC,KAAM,wBACJ,qBAA6B,EAAI,0BAA2BR,EAAAA,cAAoBO,EAAAA,EAAO,CACzFC,KAAM,wBACJ,KAAMR,EAAAA,cAAoBO,EAAAA,EAAO,CACnCC,KAAM,wBACJ,SAAUR,EAAAA,cAAoBO,EAAAA,EAAO,CACvCC,KAAM,wBACJ,0NAA2N,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACvQM,GAAI,wBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,yBACN,aAAc,kCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,yBAA0B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4ZAA6ZiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,iBAAkB,+EAAgF,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CACnqBM,GAAI,oEACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,qEACN,aAAc,8EACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wEAAyE,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gCAAiCiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,qBAAsB,gUAAiUQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,gBAAiB,OAAQQ,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,sBAAuB,mGAAoG,KAAMQ,EAAAA,cAAoBpB,EAAYO,GAAI,CAC3zBS,GAAI,+BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gCACN,aAAc,yCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gCAAiC,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9EM,GAAI,8EACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,+EACN,aAAc,wFACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,kFAAmF,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,ySAA0S,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0NAA2N,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACnuBM,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,udAAge,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,qBAAsB,KAAM,KAAMQ,EAAAA,cAAoBO,EAAAA,EAAO,CACrtBC,KAAM,+QACJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2IAA4I,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACvOM,GAAI,+CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,gDACN,aAAc,yDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,gDAAiD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kIAAmIiB,EAAAA,cAAoBU,EAAAA,EAAW,KAAM,SAAU,0DAA2DV,EAAAA,cAAoBU,EAAAA,EAAW,KAAM,QAAS,uRAAwR,KAAMV,EAAAA,cAAoBpB,EAAYU,GAAI,CAChsBM,GAAI,0BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,2BACN,aAAc,oCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,2BAA4B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2QAA4Q,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,KAAM,KAAMgB,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,aAAc,4GAA6G,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,aAAc,iEAAkE,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,cAAe,qFAAsF,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mBAAoB,qHAAsH,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0NAA2N,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACv/CM,GAAI,kDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,mDACN,aAAc,4DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,mDAAoD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gbAAib,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACjkBM,GAAI,wCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,yCACN,aAAc,kDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,yCAA0C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gjBAAijB,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACvrBS,GAAI,sCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,uCACN,aAAc,gDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,uCAAwC,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACrFM,GAAI,6DACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,8DACN,aAAc,uEACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,oEAAqE,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4EAA6E,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,OAAQ,8EAA+E,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,OAAQ,0EAA2E,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,uBAAwB,4EAA6E,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,MAAO,iEAAkE,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CACr/BM,GAAI,4CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,6CACN,aAAc,sDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,8CAA+C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,maAAoa,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC/iBM,GAAI,wCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,yCACN,aAAc,kDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,yCAA0C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oGAAqGiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC5NC,KAAM,YACJ,mBAAoBR,EAAAA,cAAoBO,EAAAA,EAAO,CACjDC,KAAM,YACJ,sSAAuS,KAAMR,EAAAA,cAAoBpB,EAAYU,GAAI,CACnVM,GAAI,uBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,wBACN,aAAc,iCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wBAAyB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,iOAAkOiB,EAAAA,cAAoBO,EAAAA,EAAO,CACxUC,KAAM,iBACJ,qBAAsBR,EAAAA,cAAoBO,EAAAA,EAAO,CACnDC,KAAM,qBACJ,gCAAiCR,EAAAA,cAAoBO,EAAAA,EAAO,CAC9DC,KAAM,qBACJ,mKAAoK,KAAMR,EAAAA,cAAoBpB,EAAYO,GAAI,CAChNS,GAAI,kBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,mBACN,aAAc,4BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,mBAAoB,KAAMN,EAAAA,cAAoBpB,EAAYU,GAAI,CACjEM,GAAI,uCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,wCACN,aAAc,iDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6RAA8R,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mCAAoC,gEAAiE,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,yBAA0B,kDAAmD,KAAMQ,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,mBAAoB,yIAA0I,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYU,GAAI,CACpkCM,GAAI,sEACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,uEACN,aAAc,gFACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,0EAA2E,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kcAAqc,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yPAA0P,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACr5BM,GAAI,0CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,2CACN,aAAc,oDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,2CAA4C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qYAAsY,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9gBM,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,sIAAuIiB,EAAAA,cAAoBO,EAAAA,EAAO,CAC3PC,KAAM,eACJ,sBAAuB,KAAMR,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,QAAS,0EAA2EQ,EAAAA,cAAoBO,EAAAA,EAAO,CACtRC,KAAM,eACJ,sCAAuC,KAAMR,EAAAA,cAAoBpB,EAAYK,GAAI,KAAMe,EAAAA,cAAoBpB,EAAYY,OAAQ,KAAM,QAAS,+IAAgJ,MAAO,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yGAA0G,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC1eM,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+bAAgc,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qNAAsN,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACx0BS,GAAI,0BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,2BACN,aAAc,oCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,2BAA4B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,ooBAAqoB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,suBAAuuB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,ojBAAqjB,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CACvnES,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0EAA2E,KAAMiB,EAAAA,cAAoBL,EAAO,CAChMgB,IAAK,2BACLC,KAAM,GACNC,QAAS,uJACTC,KAAM,UACJ,KAAMd,EAAAA,cAAoBL,EAAO,CACnCgB,IAAK,gCACLC,KAAM,GACNC,QAAS,sHACTC,KAAM,UACJ,KAAMd,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qMAAsM,KAAMiB,EAAAA,cAAoBS,EAAAA,EAAM,CACvRD,KAAM,g+CA6CJ,KAAMR,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+WAAgX,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,CAC3cS,GAAI,gBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYQ,EAAG,CACpCe,KAAM,iBACN,aAAc,0BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYS,KAAM,CACvCgB,wBAAyB,CACvBC,OAAQ,meAEP,iBAAkB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yZAA0Z,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2qBAA4qB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kLAC5uC,CAKA,MAJA,SAAoBJ,QAAK,IAALA,IAAAA,EAAQ,CAAC,GAC3B,MAAOoC,QAASC,GAAanC,OAAOC,OAAO,CAAC,GAAGW,EAAAA,EAAAA,MAAsBd,EAAMe,YAC3E,OAAOsB,EAAYhB,EAAAA,cAAoBgB,EAAWrC,EAAOqB,EAAAA,cAAoBtB,EAAmBC,IAAUD,EAAkBC,EAC9H,E,qKC5jCA,MAAMsC,EAAkBC,IAAW,IAAV,IAACC,GAAID,EAC5B,IAAKC,IAAQA,EAAIC,MAAO,OAAO,KAY/B,OAAOpB,EAAAA,cAAoB,MAAO,CAChCI,UAAWiB,EAAAA,GACVrB,EAAAA,cAAoB,KAAM,KAAMmB,EAAIC,MAAME,KAAI,CAACC,EAAMC,IAAUxB,EAAAA,cAAoB,KAAM,CAC1FyB,IAAKD,GACJxB,EAAAA,cAAoB,IAAK,CAC1BG,KAAMoB,EAAKG,IACXC,QAASC,GAjBSC,EAACD,EAAGF,KACtBE,EAAEE,iBACF,MAAMC,EAAWL,EAAIM,QAAQ,IAAK,IAC5BC,EAAgBC,SAASC,eAAeJ,GAC1CE,GACFA,EAAcG,eAAe,CAC3BC,SAAU,SACVC,MAAO,SAEX,EAQcT,CAAYD,EAAGL,EAAKG,MACjCH,EAAKgB,OAAQhB,EAAKH,OAASpB,EAAAA,cAAoBiB,EAAiB,CACjEE,IAAK,CACHC,MAAOG,EAAKH,aAEV,EAED,SAASoB,EAAYC,GAAiD,IAA/CC,MAAM,IAACC,EAAG,OAAEC,EAAM,cAAEC,GAAc,SAAEC,GAASL,EACzE,MAAM,YAACM,EAAW,KAAEC,EAAI,gBAAEC,GAAmBN,EACvCnB,EAAQuB,EAAYvB,MAEpB0B,EADOH,EAAYI,KACJC,MAAM,KAAK,GAE1BC,EADQT,EAAOU,MAAMC,QAAOC,GAAQA,EAAKT,YAAYI,KAAKM,SAAS,IAAIP,QACnDQ,MAAK,CAACtE,EAAGuE,IAAMvE,EAAE2D,YAAYvB,MAAQmC,EAAEZ,YAAYvB,QACvEoC,EAAeP,EAAYQ,WAAUL,GAAQA,EAAKT,YAAYvB,QAAUA,IACxEsC,EAAWT,EAAYO,EAAe,GACtCG,EAAWV,EAAYO,EAAe,GACtCI,EAAcjB,EAAYI,KAAKnB,QAAQ,MAAO,IAC9CiC,EAAc,SAAUC,KAAKF,GAAa,GAC1CG,EAAW,SAASjB,aAAmBe,MACvC,EAACG,EAAY,EAAEC,IAAmBC,EAAAA,EAAAA,UAASvB,EAAYwB,0BACvD,EAACC,EAAW,EAAEC,IAAkBH,EAAAA,EAAAA,WAAS,GAS/C,IAAII,GALJC,EAAAA,EAAAA,YAAU,KACRF,GAAe,GACf,MAAMG,EAAQC,YAAW,IAAMJ,GAAe,IAAQ,KACtD,MAAO,IAAMK,aAAaF,EAAM,GAC/B,CAACR,IAEY,eAAZlB,EACFwB,EAAiBK,EAAAA,GACI,aAAZ7B,EACTwB,EAAiBM,EAAAA,GACI,aAAZ9B,IACTwB,EAAiBO,EAAAA,IAEnB,MACMC,EADgBC,IAAenC,GAAMhB,QAAQ,wBAAyB,IAAIA,QAAQ,SAAU,IAAIA,QAAQ,wBAAyB,IAAIoD,OAC3GhC,MAAM,OAAOiC,OAIvCC,EA5ER,SAAwBC,GACtB,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,OAC1B,MAAMC,EAAQC,KAAKC,MAAMH,EAAU,IAC7BI,EAAYJ,EAAU,GAC5B,OAAII,GAAa,GACR,IAAIH,IAAQG,EAAY,EAAI,KAAO,OAErC,IAAIH,EAAQ,KACrB,CA+DmBI,CAHWH,KAAKI,KAAKX,EAAYR,IAChC3B,EAAY+C,kBAAoB,IAG5CC,EAAU,CAAC,CACfC,KAAMjD,EAAYkD,UAClBpG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYmD,gBAClBrG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYoD,YAClBtG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYqD,cAClBvG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYsD,YAClBxG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYuD,iBAClBzG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYwD,eAClB1G,UAAWA,IAAM,yDAChB,CACDmG,KAAMjD,EAAYyD,cAClB3G,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAY0D,kBAClB5G,UAAWA,IAAM,yDAChB,CACDmG,KAAMjD,EAAY2D,WAClB7G,UAAWA,IAAM,4DAEb,EAAC8G,EAAa,EAAEC,IAAoBtC,EAAAA,EAAAA,UAAS,IAUnD,OATAK,EAAAA,EAAAA,YAAU,KACRoB,EAAQc,SAAQC,IAAuB,IAAtB,KAACd,EAAI,UAAEnG,GAAUiH,EAC5Bd,GACFnG,IAAYkH,MAAKC,IACfJ,GAAiBK,GAAQ,GAAJC,QAAAC,EAAAA,EAAAA,GAAQF,GAAI,CAAED,EAAOI,WAAS,GAEvD,GACA,GACD,IACIpH,EAAAA,cAAoBqH,EAAAA,EAAOC,IAAK,CACrCC,QAAS,CACPC,QAAS,GAEXC,QAAS,CACPD,QAAS,GAEXE,KAAM,CACJF,QAAS,GAEXG,WAAY,CACVC,SAAU,MAEX5H,EAAAA,cAAoB6H,EAAAA,EAAY,CACjCC,WAAY/E,EAAYvB,MACxBuG,KAAMhF,EAAYgF,KAClBC,QAASjF,EAAYiF,QACrB1C,SAAUA,EACV2C,WAAYlF,EAAYmF,gBACxB3F,MAAOQ,EAAYR,MACnB4F,KAAMpF,EAAYoF,KAClBC,OAAQrF,EAAYqF,OACpBlF,QAASA,EACTmF,QAASpE,EACTqE,cAAevF,EAAYmD,gBAC3BqC,QAASxF,EAAYwF,UACnBvI,EAAAA,cAAoB,MAAO,CAC7BC,MAAO,CACLuI,QAAS,OACTC,eAAgB,WAChBC,SAAU,OACVC,SAAU,MACVC,WAAY,OACZC,aAAc,MACdC,UAAW,OACXC,aAAc,QAEfhG,EAAYiG,UAAU1H,KAAI,CAAC2H,EAAKzH,IAAUxB,EAAAA,cAAoB,OAAQ,CACvEyB,IAAKD,EACLpB,UAAW,YAAY8I,EAAAA,KACvBjJ,MAAO,CACLkJ,OAAQ,gBAETF,MAAQjJ,EAAAA,cAAoB,MAAO,CACpCoJ,MAAO,YACNpJ,EAAAA,cAAoBiB,EAAiB,CACtCE,IAAK8B,KACFjD,EAAAA,cAAoB,MAAOA,EAAAA,cAAoB,MAAO,CACzDC,MAAO,CACLkJ,OAAQ,iBACRE,UAAW,UAEZrJ,EAAAA,cAAoBqH,EAAAA,EAAOiC,OAAQ,CACpCF,MAAO,WACPhJ,UAAWmJ,EAAAA,GACX3J,GAAI2J,EAAAA,GACJ5H,QAvHmB6H,KACnBnF,GAAiBD,EAAa,EAuH9BqF,SAAU,CACRC,MAAO,MAER1J,EAAAA,cAAoBqH,EAAAA,EAAOC,IAAK,CACjClH,UAAWuJ,EAAAA,GACXlI,IAAK2C,EACLmD,QAAS,CACPC,QAAS,GAEXC,QAAS,CACPD,QAAS,GAEXE,KAAM,CACJF,QAAS,GAEXG,WAAY,CACVC,SAAU,GACVgC,KAAM,cAEPxF,EAAe,2BAA6B,2BAA4BpE,EAAAA,cAAoB,MAAOA,EAAAA,cAAoB,MAAO,CAC/HoJ,MAAO,WACPnJ,MAAO,CACLkJ,OAAQ/E,EAAe,SAAW,GAClCuE,SAAUvE,EAAe,OAAS,GAClCuD,WAAY,uDAEb3H,EAAAA,cAAoB,MAAO,CAC5BI,UAAW,GAAGmJ,EAAAA,MAAuC/E,EAAc+E,EAAAA,GAAkCA,EAAAA,MACpG5C,EAAcrF,KAAI,CAACuI,EAAiBrI,IAAUxB,EAAAA,cAAoB6J,EAAiB,CACpFpI,IAAKD,MACFuB,EAAY+G,YAAc9J,EAAAA,cAAoB+J,EAAAA,EAAoB,CACrEvI,MAAOuB,EAAY+G,YACnBE,SAAUjH,EAAYkH,qBACnB,GAAIjK,EAAAA,cAAoBkK,EAAAA,EAAaC,SAAU,CAClDC,MAAO,CACLC,OAAQxH,EAAcS,MACtBa,SAAUA,EAASnC,QAAQ,MAAO,IAAM,MAEzChC,EAAAA,cAAoBsK,EAAAA,GAAa,CAClC5K,WAAY,CACVC,MAAKA,EAAAA,IAENmD,MAAc9C,EAAAA,cAAoBuK,EAAAA,EAAY,CAC/CzG,SAAUA,EACVC,SAAUA,EACVE,WAAYA,EACZf,QAASA,IAEb,CAEe,SAASsH,EAAiB7L,GACvC,OAAOqB,EAAAA,cAAoBwC,EAAc7D,EAAOqB,EAAAA,cAAoByK,EAAqB9L,GAC3F,CACO,SAAS+L,EAAIC,GAAS,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA,IAAR,KAACtI,GAAKiI,EACzB,MAAM,YAAC5H,GAAeL,EAAKC,IACrBJ,EAAQQ,EAAYkI,UAAYlI,EAAYR,MAC5C2I,EAAUnI,EAAYmI,SAAW3I,EACjC4I,EAAepI,EAAYoI,cAAgB5I,EAC3C6I,EAAcrI,EAAYsI,SAAWtI,EAAYoF,KACjDmD,EAAgBvI,EAAYwI,QAAUH,EACtCI,EAAqBzI,EAAY0I,aAAeL,EAChDM,EAAa3I,EAAY2I,YAAc,cACvCC,EAAW5I,EAAY6I,YACvBC,EAAgB9I,EAAYgF,KAC5B+D,EAAe/I,EAAYiF,SAAW6D,EACtCE,EAAUhJ,EAAYgJ,UAA6B,QAAtBnB,EAAI7H,EAAYqF,cAAM,IAAAwC,GAAiB,QAAjBC,EAAlBD,EAAoBoB,uBAAe,IAAAnB,GAAiB,QAAjBC,EAAnCD,EAAqCoB,uBAAe,IAAAnB,GAAQ,QAARC,EAApDD,EAAsDT,cAAM,IAAAU,GAAU,QAAVC,EAA5DD,EAA8DmB,gBAAQ,IAAAlB,OAApD,EAAlBA,EAAwEmB,KACzGC,EAAarJ,EAAYqJ,YAAcd,EACvCe,EAAetJ,EAAYsJ,cAAgBN,EAC3CO,EAAkBvJ,EAAYuJ,iBAAmBd,EACjDe,EAAexJ,EAAYyJ,aAC3B9F,EAAa3D,EAAY2D,aAAc,EACvC6B,EAAUxF,EAAYwF,SAAW,QACjCrF,EAAUH,EAAYI,KAAKC,MAAM,KAAK,IAAM,SAE5C,QAACqJ,IAAWC,EAAAA,EAAAA,KACZC,EAAiB,CACrB,WAAY,qBACZ,QAAS,iBACT,gBAAmB,CAAC,CAClB,QAAS,WACT,SAAY,EACZ,KAAQ,OACR,KAAQF,GACP,CACD,QAAS,WACT,SAAY,EACZ,KAAQlE,EACR,KAAQ,GAAGkE,KAAW1J,EAAYI,KAAKC,MAAM,KAAK,MACjD,CACD,QAAS,WACT,SAAY,EACZ,KAAQb,EACR,KAAQ,GAAGkK,IAAU1J,EAAYI,UAGrC,OAAOnD,EAAAA,cAAoB4M,EAAAA,EAAK,CAC9BrK,MAAOA,EAAQ,gBACf2I,QAASA,EACTC,aAAcA,EACdC,YAAaA,EACbE,cAAeA,EACfE,mBAAoBA,EACpBE,WAAYA,EACZC,SAAUA,EACVE,cAAeA,EACfC,aAAcA,EACdC,QAASA,EACTK,WAAYA,EACZC,aAAcA,EACdC,gBAAiBA,EACjBC,aAAcA,EACd7F,WAAYA,EACZ6B,QAASA,EACTrF,QAASA,EACT2J,KAzCW,WA0CV7M,EAAAA,cAAoB,SAAU,CAC/B6M,KAAM,uBACLC,KAAKC,UAAUJ,IACpB,C,iDC9SA,IALUzL,IAAe,IAAd,KAAEV,GAAMU,EACjB,OACElB,EAAAA,cAACO,EAAAA,EAAK,KAAEC,EAAa,C","sources":["webpack://avrtt.blog/./src/pages/posts/research/ai_search.mdx","webpack://avrtt.blog/./src/templates/post.js","webpack://avrtt.blog/./src/components/Latex/index.js"],"sourcesContent":["/*@jsxRuntime classic @jsx React.createElement @jsxFrag React.Fragment*/\n/**(intro: a quote, catchphrase, joke, etc.)**/\n/*\n\nArtificial Intelligence: A Modern Approach, Global Edition, 4ed: 3. Solving Problems by Searching + 4. Search in Complex Environments + 5. Constraint Satisfaction Problems + 6. Adversarial Search and Games\n\n*/\n/*\n\n1. Introduction\n- Motivation for AI search\n- Definition of search in AI\n- Problem-solving agents and their role in search\n- Overview of key search paradigms and techniques\n2. Fundamentals of Problem-Solving by Searching\n- Defining the search problem (states, actions, goals)\n- State space representation\n- Search trees vs. search graphs\n- Example problems\n- Algorithmic problem solving basics\n3. Uninformed (Blind) Search Strategies\n- Characteristics and limitations of uninformed search\n- Breadth-first search (BFS)\n- Depth-first search (DFS)\n- Uniform-cost search (Dijkstra's algorithm)\n- Comparison of time and space complexities\n4. Informed (Heuristic) Search Strategies\n- Heuristic functions and their role in search\n- Heuristic evaluations (admissibility and consistency)\n- Greedy best-first search\n- A* search algorithm\n- Analysis of performance and optimality\n5. Local Search and Optimization Problems\n- Motivation for local search (large or infinite state spaces)\n- Hill-climbing and variants\n- Simulated annealing\n- Genetic algorithms and other evolutionary methods\n- Local search in continuous spaces\n6. Search in Complex and Uncertain Environments\n- Dealing with nondeterministic actions\n- Search in partially observable environments\n- Online search agents for unknown environments\n7. Constraint Satisfaction Problems (CSPs)\n- Defining CSPs (variables, domains, constraints)\n- Constraint propagation and inference in CSPs\n- Backtracking search for CSPs\n- Local search for CSPs\n- The structure of problems (constraint graphs, problem decomposition)\n8. Adversarial Search and Games\n- Motivation for adversarial search (two-player games, competitive environments)\n- Optimal decisions in games (minimax)\n- Heuristic alpha-beta tree search and pruning\n- Monte Carlo tree search\n- Stochastic games and partially observable games\n- Limitations of game search algorithms\n9. Classical Search and Its Extensions\n- Review of classic search algorithms (BFS, DFS, Uniform Cost, A*)\n- When to use informed vs. uninformed search\n- Iterative deepening search strategies\n- Bidirectional search\n10. Advanced Topics\n- Algorithmic problem solving at scale\n- Enhancing heuristic functions (pattern databases, learning heuristics)\n- Incorporating domain-specific knowledge\n- Memory-bounded search (IDA*, SMA*)\n- Dealing with real-time constraints\n\n*/\nimport {useMDXComponents as _provideComponents} from \"@mdx-js/react\";\nimport React from \"react\";\nimport Highlight from \"../../../components/Highlight\";\nimport Code from \"../../../components/Code\";\nimport Latex from \"../../../components/Latex\";\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    ol: \"ol\",\n    li: \"li\",\n    br: \"br\",\n    h2: \"h2\",\n    a: \"a\",\n    span: \"span\",\n    h3: \"h3\",\n    ul: \"ul\",\n    strong: \"strong\"\n  }, _provideComponents(), props.components), {Image} = _components;\n  if (!Image) _missingMdxReference(\"Image\", true);\n  return React.createElement(React.Fragment, null, \"\\n\", React.createElement(\"br\"), \"\\n\", \"\\n\", \"\\n\", React.createElement(_components.p, null, \"Artificial intelligence search — often referred to simply as \\\"search\\\" — plays a crucial role in the broader field of AI, serving as a core framework for problem-solving agents that need to find solutions systematically in well-defined or sometimes partially defined spaces. The concept of \\\"search\\\" in AI revolves around exploring possible sequences of actions and outcomes, attempting to arrive at a goal that fulfills certain criteria or solves a particular challenge. At its foundation, AI search is about generating and evaluating states — or sets of possible configurations — using a structured process that can be as naive as exploring every possibility or as sophisticated as leveraging heuristics, constraints, or other domain-specific knowledge.\"), \"\\n\", React.createElement(_components.p, null, \"I find AI search especially motivating because of its wide applicability. From routing problems (like shortest paths in transportation networks) and scheduling tasks (like optimizing resource allocation) to game-playing agents and complex constraint satisfaction puzzles, search mechanisms help cut down potentially astronomically large solution spaces to something manageable. In daily practice, search strategies empower advanced software and intelligent systems, allowing them to identify optimal — or near-optimal — solutions in the face of complexity and uncertainty.\"), \"\\n\", React.createElement(_components.p, null, \"This article is intended for readers who have some background in machine learning and data science but wish to dive deeper into the theoretical and practical details of AI-based search strategies. I will walk through fundamental ideas, from the most basic uninformed search techniques to heuristically guided approaches, local search, constraint satisfaction, and adversarial search. I will also highlight relevant insights from research (e.g., from major conferences like NeurIPS or journals like JMLR) that have shaped the modern understanding of AI search and its associated methods. By the end, you should feel confident about where each search strategy fits and how to design or choose the right one for your specific problem context.\"), \"\\n\", React.createElement(_components.p, null, \"Below is the overall structure of this article:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Introduction\", React.createElement(_components.br), \"\\n\", \"— Motivation for AI search\", React.createElement(_components.br), \"\\n\", \"— Definition of search in AI\", React.createElement(_components.br), \"\\n\", \"— Problem-solving agents and their role in search\", React.createElement(_components.br), \"\\n\", \"— Overview of key search paradigms and techniques\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Fundamentals of problem-solving by searching\", React.createElement(_components.br), \"\\n\", \"— Defining the search problem (states, actions, goals)\", React.createElement(_components.br), \"\\n\", \"— State space representation\", React.createElement(_components.br), \"\\n\", \"— Search trees vs. search graphs\", React.createElement(_components.br), \"\\n\", \"— Example problems\", React.createElement(_components.br), \"\\n\", \"— Algorithmic problem-solving basics\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Uninformed (blind) search strategies\", React.createElement(_components.br), \"\\n\", \"— Characteristics and limitations of uninformed search\", React.createElement(_components.br), \"\\n\", \"— Breadth-first search (BFS)\", React.createElement(_components.br), \"\\n\", \"— Depth-first search (DFS)\", React.createElement(_components.br), \"\\n\", \"— Uniform-cost search (Dijkstra's algorithm)\", React.createElement(_components.br), \"\\n\", \"— Comparison of time and space complexities\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Informed (heuristic) search strategies\", React.createElement(_components.br), \"\\n\", \"— Heuristic functions and their role in search\", React.createElement(_components.br), \"\\n\", \"— Heuristic evaluations (admissibility and consistency)\", React.createElement(_components.br), \"\\n\", \"— Greedy best-first search\", React.createElement(_components.br), \"\\n\", \"— A* search algorithm\", React.createElement(_components.br), \"\\n\", \"— Analysis of performance and optimality\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Local search and optimization problems\", React.createElement(_components.br), \"\\n\", \"— Motivation for local search (large or infinite state spaces)\", React.createElement(_components.br), \"\\n\", \"— Hill-climbing and variants\", React.createElement(_components.br), \"\\n\", \"— Simulated annealing\", React.createElement(_components.br), \"\\n\", \"— Genetic algorithms and other evolutionary methods\", React.createElement(_components.br), \"\\n\", \"— Local search in continuous spaces\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Search in complex and uncertain environments\", React.createElement(_components.br), \"\\n\", \"— Dealing with nondeterministic actions\", React.createElement(_components.br), \"\\n\", \"— Search in partially observable environments\", React.createElement(_components.br), \"\\n\", \"— Online search agents for unknown environments\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Constraint satisfaction problems (CSPs)\", React.createElement(_components.br), \"\\n\", \"— Defining CSPs (variables, domains, constraints)\", React.createElement(_components.br), \"\\n\", \"— Constraint propagation and inference in CSPs\", React.createElement(_components.br), \"\\n\", \"— Backtracking search for CSPs\", React.createElement(_components.br), \"\\n\", \"— Local search for CSPs\", React.createElement(_components.br), \"\\n\", \"— The structure of problems (constraint graphs, problem decomposition)\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Adversarial search and games\", React.createElement(_components.br), \"\\n\", \"— Motivation for adversarial search (two-player games, competitive environments)\", React.createElement(_components.br), \"\\n\", \"— Optimal decisions in games (minimax)\", React.createElement(_components.br), \"\\n\", \"— Heuristic alpha-beta tree search and pruning\", React.createElement(_components.br), \"\\n\", \"— Monte Carlo tree search\", React.createElement(_components.br), \"\\n\", \"— Stochastic games and partially observable games\", React.createElement(_components.br), \"\\n\", \"— Limitations of game search algorithms\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Classical search and its extensions\", React.createElement(_components.br), \"\\n\", \"— Review of classic search algorithms\", React.createElement(_components.br), \"\\n\", \"— When to use informed vs. uninformed search\", React.createElement(_components.br), \"\\n\", \"— Iterative deepening search strategies\", React.createElement(_components.br), \"\\n\", \"— Bidirectional search\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, \"Advanced topics\", React.createElement(_components.br), \"\\n\", \"— Algorithmic problem solving at scale\", React.createElement(_components.br), \"\\n\", \"— Enhancing heuristic functions (pattern databases, learning heuristics)\", React.createElement(_components.br), \"\\n\", \"— Incorporating domain-specific knowledge\", React.createElement(_components.br), \"\\n\", \"— Memory-bounded search (IDA*, SMA*)\", React.createElement(_components.br), \"\\n\", \"— Dealing with real-time constraints\"), \"\\n\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"In what follows, I will expand extensively on each section, aiming to provide a robust understanding of AI search for experienced data scientists and ML engineers.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"fundamentals-of-problem-solving-by-searching\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#fundamentals-of-problem-solving-by-searching\",\n    \"aria-label\": \"fundamentals of problem solving by searching permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"fundamentals of problem-solving by searching\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"defining-the-search-problem-states-actions-goals\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#defining-the-search-problem-states-actions-goals\",\n    \"aria-label\": \"defining the search problem states actions goals permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"defining the search problem (states, actions, goals)\"), \"\\n\", React.createElement(_components.p, null, \"At the heart of any AI search method is the formal definition of a problem as a set of states, a set of actions that cause state transitions, and one or more goal conditions. A \\\"state\\\" is an abstract representation of the configuration of the system at a given point. For example, in a sliding tile puzzle, a state might be an arrangement of the tiles on the board; in a pathfinding scenario, a state might be a particular location on a map along with certain resources or constraints.\"), \"\\n\", React.createElement(_components.p, null, \"An \\\"action\\\" is a choice that transforms one state into another. Actions can have preconditions (requirements that must be met before the action is applicable), and they may have effects (how the state changes once the action is applied). A \\\"goal\\\" condition is a set of constraints or properties that define when the problem is solved. For instance, the goal in the sliding tile puzzle might be to arrange the tiles in ascending numeric order.\"), \"\\n\", React.createElement(_components.p, null, \"The interplay of states, actions, and goals frames the search space. Agents systematically explore this space to find a path from an initial state to a goal state.\"), \"\\n\", React.createElement(_components.p, null, \"Formally, a search problem can be defined as a tuple \", React.createElement(Latex, {\n    text: \"\\\\( (S, A, c, s_0, G) \\\\)\"\n  }), \" where:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(Latex, {\n    text: \"\\\\(S\\\\)\"\n  }), \" is the set of possible states.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(Latex, {\n    text: \"\\\\(A\\\\)\"\n  }), \" is the set of actions or operators that transition between states.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(Latex, {\n    text: \"\\\\(c(s, a, s')\\\\)\"\n  }), \" defines the cost of applying action \", React.createElement(Latex, {\n    text: \"\\\\(a\\\\)\"\n  }), \" in state \", React.createElement(Latex, {\n    text: \"\\\\(s\\\\)\"\n  }), \" that leads to state \", React.createElement(Latex, {\n    text: \"\\\\(s'\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \" is the initial state.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(Latex, {\n    text: \"\\\\(G \\\\subseteq S\\\\)\"\n  }), \" is the set of goal states.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"state-space-representation\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#state-space-representation\",\n    \"aria-label\": \"state space representation permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"state space representation\"), \"\\n\", React.createElement(_components.p, null, \"The \\\"state space\\\" is the conceptual or literal graph whose nodes correspond to states, and edges correspond to the application of actions. Often, the major challenge lies in how to encode states in a way that is both expressive enough to capture the problem constraints, yet lean enough to be computationally feasible. If the state representation is too large or complex, the search problem can become intractable due to exponential growth in the number of possible states.\"), \"\\n\", React.createElement(_components.p, null, \"For instance, in a scheduling problem, each state can represent the assignment of tasks to resources. However, enumerating all possible assignments might be infeasible if the number of tasks and resources is large. Hence, effective representation and subsequent search methods are essential for real-world applicability.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"search-trees-vs-search-graphs\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#search-trees-vs-search-graphs\",\n    \"aria-label\": \"search trees vs search graphs permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"search trees vs. search graphs\"), \"\\n\", React.createElement(_components.p, null, \"When an AI agent starts from an initial state \", React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \" and branches out by applying actions, we often visualize a \\\"search tree\\\". Each node in the tree represents a state, and each edge corresponds to an action. A search tree is an excellent conceptual tool because it underscores the branching factor — i.e., the average number of successors for each state — and it helps illustrate naive search expansions. However, some states can be reached by multiple paths, which would be represented multiple times in a pure tree.\"), \"\\n\", React.createElement(_components.p, null, \"A \\\"search graph\\\" is a more compact representation that recognizes repeated states, effectively merging paths that arrive at the same state. While search trees are simpler to illustrate conceptually, many practical algorithms internally keep track of visited states to avoid redundant computations.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"example-problems\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#example-problems\",\n    \"aria-label\": \"example problems permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"example problems\"), \"\\n\", React.createElement(_components.p, null, \"Search as a problem-solving framework spans a wide array of applications:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Pathfinding in grids and graphs\"), \": Classic route-finding, navigation, or robotics tasks.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Puzzle solving\"), \": Sliding tile puzzles, Rubik's Cube solutions, or Sudoku.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Scheduling and planning\"), \": Coordinating tasks under deadlines and resource constraints.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Network optimization\"), \": Optimizing flow across a network subject to capacity constraints (sometimes solved by specialized algorithms but grounded in the same conceptual framing of states and transitions).\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Historically, the well-known \\\"8-puzzle\\\" or \\\"15-puzzle\\\" has served as a popular test for search algorithms, illustrating the complexity that can emerge even from seemingly small or simple problem definitions.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"algorithmic-problem-solving-basics\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#algorithmic-problem-solving-basics\",\n    \"aria-label\": \"algorithmic problem solving basics permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"algorithmic problem-solving basics\"), \"\\n\", React.createElement(_components.p, null, \"A systematic way to solve search problems typically involves the following steps:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"Formulate the problem precisely (i.e., define states, actions, costs, and goal conditions).\"), \"\\n\", React.createElement(_components.li, null, \"Define or select an algorithmic strategy for exploring the state space.\"), \"\\n\", React.createElement(_components.li, null, \"Execute the search procedure (which might be BFS, DFS, A*, or a more specialized strategy).\"), \"\\n\", React.createElement(_components.li, null, \"Return the path or sequence of actions once a goal state is reached (if one exists).\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"One must also be prepared to address practical concerns such as memory usage, computational complexity, suboptimal solutions, or real-time constraints that limit search depth or expansions. In the sections that follow, I'll cover various strategies that differ mainly by how they expand states and in what order, whether or not they use heuristics, and how they cope with large or partially known search spaces.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"uninformed-blind-search-strategies\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#uninformed-blind-search-strategies\",\n    \"aria-label\": \"uninformed blind search strategies permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"uninformed (blind) search strategies\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"characteristics-and-limitations-of-uninformed-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#characteristics-and-limitations-of-uninformed-search\",\n    \"aria-label\": \"characteristics and limitations of uninformed search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"characteristics and limitations of uninformed search\"), \"\\n\", React.createElement(_components.p, null, \"Uninformed search — also known as \\\"blind search\\\" — refers to a category of algorithms that do not exploit additional knowledge about the domain; they do not know how \\\"good\\\" or \\\"close\\\" a state is to the goal. Instead, they blindly explore the state space in a systematic manner. While uninformed methods guarantee certain completeness properties (given enough time and memory), they can be dramatically inefficient. Situations with large state spaces or complicated constraints might render uninformed approaches unusable in practice. Nonetheless, they form the foundation upon which more sophisticated approaches are built, and they are crucial for understanding key concepts like branching factor, depth, and memory usage.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"breadth-first-search-bfs\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#breadth-first-search-bfs\",\n    \"aria-label\": \"breadth first search bfs permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"breadth-first search (BFS)\"), \"\\n\", React.createElement(_components.p, null, \"Breadth-first search systematically explores all states at a given depth before moving to the next depth level. This method ensures that if a solution exists at the shallowest level in the search tree, BFS will find it first.\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Algorithm (informal outline)\"), \":\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"Begin at the initial state \", React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"Place \", React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \" in a queue (FIFO structure).\"), \"\\n\", React.createElement(_components.li, null, \"While the queue is not empty:\", \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"Dequeue a state \", React.createElement(Latex, {\n    text: \"\\\\(s\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"If \", React.createElement(Latex, {\n    text: \"\\\\(s\\\\)\"\n  }), \" is a goal state, return the solution.\"), \"\\n\", React.createElement(_components.li, null, \"Otherwise, enqueue all unvisited successors of \", React.createElement(Latex, {\n    text: \"\\\\(s\\\\)\"\n  }), \".\"), \"\\n\"), \"\\n\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Here is a minimal Python example to illustrate BFS:\"), \"\\n\", React.createElement(Code, {\n    text: `\nfrom collections import deque\n\ndef bfs(start, goal_test, get_successors):\n    \"\"\"\n    start: initial state\n    goal_test: function(state) -> bool\n    get_successors: function(state) -> list of successor states\n    \"\"\"\n    visited = set()\n    queue = deque([start])\n    \n    # parent dict to reconstruct path if needed\n    parent = {start: None}\n    \n    while queue:\n        current = queue.popleft()\n        if goal_test(current):\n            # Reconstruct path\n            path = []\n            while current is not None:\n                path.append(current)\n                current = parent[current]\n            path.reverse()\n            return path\n        \n        visited.add(current)\n        \n        for succ in get_successors(current):\n            if succ not in visited and succ not in queue:\n                parent[succ] = current\n                queue.append(succ)\n                \n    return None  # no solution found\n`\n  }), \"\\n\", React.createElement(_components.p, null, \"BFS is \", React.createElement(_components.strong, null, \"complete\"), \" if the branching factor is finite. The time and space complexity can be expressed in terms of the branching factor \", React.createElement(Latex, {\n    text: \"\\\\(b\\\\)\"\n  }), \" and the depth of the shallowest goal \", React.createElement(Latex, {\n    text: \"\\\\(d\\\\)\"\n  }), \". In the worst case, BFS visits on the order of \", React.createElement(Latex, {\n    text: \"\\\\(O(b^d)\\\\)\"\n  }), \" nodes, which can be prohibitive. Nonetheless, BFS remains popular in scenarios where the state space is small or when we prioritize finding the shallowest solution.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"depth-first-search-dfs\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#depth-first-search-dfs\",\n    \"aria-label\": \"depth first search dfs permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"depth-first search (DFS)\"), \"\\n\", React.createElement(_components.p, null, \"Depth-first search, in contrast, explores one branch of the tree deeply before backtracking. This approach is easy to implement using recursion or a stack, and it uses far less memory than BFS. However, DFS can get stuck exploring an extremely deep (or infinite) branch, making it incomplete for some unbounded state spaces.\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Algorithm (informal outline)\"), \":\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"Start at \", React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"Follow one child from \", React.createElement(Latex, {\n    text: \"\\\\(s_0\\\\)\"\n  }), \" to the greatest depth until you reach a goal or can go no further.\"), \"\\n\", React.createElement(_components.li, null, \"Backtrack to the first sibling node and continue.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"A simple Python DFS (recursive version) might look like this:\"), \"\\n\", React.createElement(Code, {\n    text: `\ndef dfs(start, goal_test, get_successors, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(start)\n    \n    if goal_test(start):\n        return [start]\n    \n    for succ in get_successors(start):\n        if succ not in visited:\n            path = dfs(succ, goal_test, get_successors, visited)\n            if path is not None:\n                return [start] + path\n    \n    return None\n`\n  }), \"\\n\", React.createElement(_components.p, null, \"DFS has a worst-case time complexity of \", React.createElement(Latex, {\n    text: \"\\\\(O(b^m)\\\\)\"\n  }), \" where \", React.createElement(Latex, {\n    text: \"\\\\(m\\\\)\"\n  }), \" is the maximum depth of the search tree. If the search space is deep or unbounded, this can be extremely large. However, DFS typically has more manageable memory requirements (proportional to \", React.createElement(Latex, {\n    text: \"\\\\(O(bm)\\\\)\"\n  }), \" in the worst case).\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"uniform-cost-search-dijkstras-algorithm\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#uniform-cost-search-dijkstras-algorithm\",\n    \"aria-label\": \"uniform cost search dijkstras algorithm permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"uniform-cost search (dijkstra's algorithm)\"), \"\\n\", React.createElement(_components.p, null, \"Uniform-cost search expands the node with the lowest path cost \", React.createElement(Latex, {\n    text: \"\\\\(g(n)\\\\)\"\n  }), \" from the initial state to \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \". It is in fact Dijkstra's algorithm applied to search graphs, commonly used to find the shortest path in a weighted graph. Instead of searching by shallowest depth, it searches by the least cumulative cost so far.\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Key idea\"), \": Keep a priority queue (often implemented as a min-heap) that orders states by their cumulative path cost. The algorithm always expands the node that has the smallest \", React.createElement(Latex, {\n    text: \"\\\\(g(n)\\\\)\"\n  }), \". Thus, if costs are non-negative, uniform-cost search is guaranteed to find the optimal solution.\"), \"\\n\", React.createElement(_components.p, null, \"Uniform-cost search often outperforms BFS in cases where the step costs differ because BFS implicitly assumes uniform step cost. However, uniform-cost search can degrade in performance if there are many small-cost edges near the root, as it could expand a large set of low-cost partial paths.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"comparison-of-time-and-space-complexities\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#comparison-of-time-and-space-complexities\",\n    \"aria-label\": \"comparison of time and space complexities permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"comparison of time and space complexities\"), \"\\n\", React.createElement(_components.p, null, \"Uninformed search strategies often suffer from exponential time complexity relative to the search depth. The choice between BFS, DFS, and uniform-cost search will hinge on whether:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"The solution is known to be at a shallow depth (BFS might be favored).\"), \"\\n\", React.createElement(_components.li, null, \"We have a limited memory budget (DFS might be the only feasible option).\"), \"\\n\", React.createElement(_components.li, null, \"We care about path cost optimality (uniform-cost search is essential if costs vary).\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"A general complexity measure for BFS is \", React.createElement(Latex, {\n    text: \"\\\\(O(b^d)\\\\)\"\n  }), \", while DFS is \", React.createElement(Latex, {\n    text: \"\\\\(O(b^m)\\\\)\"\n  }), \" where \", React.createElement(Latex, {\n    text: \"\\\\(m\\\\)\"\n  }), \" can be much larger than \", React.createElement(Latex, {\n    text: \"\\\\(d\\\\)\"\n  }), \". Uniform-cost search complexity depends on the path cost distribution and still might become large, but it guarantees optimality under non-negative edge costs.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"informed-heuristic-search-strategies\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#informed-heuristic-search-strategies\",\n    \"aria-label\": \"informed heuristic search strategies permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"informed (heuristic) search strategies\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"heuristic-functions-and-their-role-in-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#heuristic-functions-and-their-role-in-search\",\n    \"aria-label\": \"heuristic functions and their role in search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"heuristic functions and their role in search\"), \"\\n\", React.createElement(_components.p, null, \"A \\\"heuristic function\\\" \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" provides an estimate of the cost (or distance) from node \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \" to a goal. It encodes additional domain knowledge that helps guide search toward the goal more efficiently. Well-chosen heuristics can dramatically reduce the number of states visited, often turning an otherwise intractable problem into something solvable in practice.\"), \"\\n\", React.createElement(_components.p, null, \"Heuristics are particularly well-studied in puzzles and pathfinding problems. For instance, in the \\\"8-puzzle,\\\" a common heuristic is the sum of Manhattan distances of each tile from its goal position, ignoring potential interactions between tiles. This heuristic is \", React.createElement(_components.strong, null, \"admissible\"), \", meaning it never overestimates the actual distance to the goal. Admissible heuristics ensure that certain algorithms (like A*) will find an optimal solution.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"heuristic-evaluations-admissibility-and-consistency\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#heuristic-evaluations-admissibility-and-consistency\",\n    \"aria-label\": \"heuristic evaluations admissibility and consistency permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"heuristic evaluations (admissibility and consistency)\"), \"\\n\", React.createElement(_components.p, null, \"Two critical properties for heuristics in the context of informed search algorithms are:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Admissibility\"), \": A heuristic \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" is admissible if \", React.createElement(Latex, {\n    text: \"\\\\(h(n) \\\\leq h^*(n)\\\\)\"\n  }), \" for all \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \" (where \", React.createElement(Latex, {\n    text: \"\\\\(h^*(n)\\\\)\"\n  }), \" is the true minimum cost to reach a goal from \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \"). This ensures the heuristic never overestimates the cost.\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Consistency (or Monotonicity)\"), \": A heuristic is consistent if \", React.createElement(Latex, {\n    text: \"\\\\(h(n) \\\\leq c(n, a, n') + h(n')\\\\)\"\n  }), \" for every successor \", React.createElement(Latex, {\n    text: \"\\\\(n'\\\\)\"\n  }), \" of \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \" generated by action \", React.createElement(Latex, {\n    text: \"\\\\(a\\\\)\"\n  }), \" with cost \", React.createElement(Latex, {\n    text: \"\\\\(c(n, a, n')\\\\)\"\n  }), \". Consistency implies admissibility, and it ensures that the values of the heuristic function do not \\\"jump\\\" in a way that can break search algorithms.\"), \"\\n\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"greedy-best-first-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#greedy-best-first-search\",\n    \"aria-label\": \"greedy best first search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"greedy best-first search\"), \"\\n\", React.createElement(_components.p, null, \"Greedy best-first search expands nodes in the order of their heuristic value \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" alone. In other words, it always pursues the path that appears to lead most directly to the goal, ignoring the cost it took to get there.\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Strength\"), \": It can be extremely fast in guiding the search toward the goal if the heuristic is strong.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Weakness\"), \": It is not optimal and can sometimes behave like a naive depth-first approach, wandering down a path that seems promising according to \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" but is actually expensive overall.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"a-search-algorithm\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#a-search-algorithm\",\n    \"aria-label\": \"a search algorithm permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"a* search algorithm\"), \"\\n\", React.createElement(_components.p, null, \"A* is one of the most famous and widely used informed search algorithms, balancing both the cost so far and the heuristic estimate:\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\nf(n) = g(n) + h(n)\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"where \", React.createElement(Latex, {\n    text: \"\\\\(g(n)\\\\)\"\n  }), \" is the cost from the initial state to \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \", and \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" is the heuristic estimate from \", React.createElement(Latex, {\n    text: \"\\\\(n\\\\)\"\n  }), \" to the goal. A* always expands the node with the smallest \", React.createElement(Latex, {\n    text: \"\\\\(f(n)\\\\)\"\n  }), \". With an admissible heuristic \", React.createElement(Latex, {\n    text: \"\\\\(h\\\\)\"\n  }), \", A* is guaranteed to find an optimal solution. If \", React.createElement(Latex, {\n    text: \"\\\\(h\\\\)\"\n  }), \" is also consistent, A* is optimally efficient among optimal algorithms (no other optimal algorithm can expand fewer states than A* does with a consistent heuristic).\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Pseudocode snippet\"), \":\"), \"\\n\", React.createElement(Code, {\n    text: `\nimport heapq\n\ndef a_star_search(start, goal_test, get_successors, h):\n    \"\"\"\n    start: initial state\n    goal_test: function(state) -> bool\n    get_successors: function(state) -> list of (successor, cost)\n    h: heuristic function(state) -> float\n    \"\"\"\n    open_list = []\n    heapq.heappush(open_list, (h(start), 0, start))  # (f(n), g(n), state)\n    \n    closed_set = set()\n    parent = {start: None}\n    \n    while open_list:\n        f_val, g_val, current = heapq.heappop(open_list)\n        \n        if goal_test(current):\n            # reconstruct path\n            path = []\n            while current is not None:\n                path.append(current)\n                current = parent[current]\n            path.reverse()\n            return path\n        \n        closed_set.add(current)\n        \n        for succ, cost in get_successors(current):\n            new_g = g_val + cost\n            new_f = new_g + h(succ)\n            \n            if succ in closed_set:\n                continue\n            \n            # You can also keep a visited dict to store best g-values so far \n            heapq.heappush(open_list, (new_f, new_g, succ))\n            if succ not in parent:\n                parent[succ] = current\n    \n    return None\n`\n  }), \"\\n\", React.createElement(_components.p, null, \"A*'s performance depends heavily on the quality of the heuristic. A perfect heuristic that exactly computes the remaining distance (i.e., \", React.createElement(Latex, {\n    text: \"\\\\(h^*(n)\\\\)\"\n  }), \") will guide the search in a straight line toward the goal, effectively turning A* into a uniform-cost search in a drastically reduced state space.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"analysis-of-performance-and-optimality\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#analysis-of-performance-and-optimality\",\n    \"aria-label\": \"analysis of performance and optimality permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"analysis of performance and optimality\"), \"\\n\", React.createElement(_components.p, null, \"With an admissible heuristic, A* is guaranteed to find an optimal solution if the branching factor is finite. Its time complexity can still be exponential in the worst case, but in many practical applications (like real-world pathfinding or moderately sized puzzles), it performs impressively. The memory footprint can also become a limiting factor since it stores all generated nodes in memory (open and closed sets). Variants like IDA* (Iterative Deepening A*) address this issue, which I will touch on in the \\\"Advanced Topics\\\" section.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"local-search-and-optimization-problems\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#local-search-and-optimization-problems\",\n    \"aria-label\": \"local search and optimization problems permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"local search and optimization problems\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"motivation-for-local-search-large-or-infinite-state-spaces\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#motivation-for-local-search-large-or-infinite-state-spaces\",\n    \"aria-label\": \"motivation for local search large or infinite state spaces permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"motivation for local search (large or infinite state spaces)\"), \"\\n\", React.createElement(_components.p, null, \"For real-world problems that can involve extremely large or even unbounded state spaces, traditional systematic searches (like BFS, DFS, or A*) can run out of memory or time. Moreover, some problems, such as continuous optimization tasks, do not even have a neatly defined discrete state space to traverse in a graph-like manner. In these cases, local search methods provide a viable solution by iteratively improving (or attempting to improve) a single candidate state (or a small population of states in the case of evolutionary methods) until a stopping criterion is reached.\"), \"\\n\", React.createElement(_components.p, null, \"Local search is also quite practical for problems that do not require an absolutely optimal solution but instead a \\\"good enough\\\" solution. This is typical in many scheduling and design optimization tasks.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"hill-climbing-and-variants\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#hill-climbing-and-variants\",\n    \"aria-label\": \"hill climbing and variants permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"hill-climbing and variants\"), \"\\n\", React.createElement(_components.p, null, \"Hill-climbing is perhaps the simplest local search technique. Starting from an initial candidate, it attempts small modifications (moves) that improve the objective or heuristic value, continuing until no neighbor offers improvement. This approach can easily get stuck in local optima, hence the existence of variants:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Stochastic hill-climbing\"), \": Randomly chooses among neighboring states that improve the evaluation, introducing some randomness.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"First-choice hill-climbing\"), \": Evaluates neighbors in random order until it finds a move that results in a net improvement, typically used when the branching factor is large.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Random restarts\"), \": Repeatedly restarts hill-climbing from random initial states to attempt escaping local optima.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"simulated-annealing\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#simulated-annealing\",\n    \"aria-label\": \"simulated annealing permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"simulated annealing\"), \"\\n\", React.createElement(_components.p, null, \"Simulated annealing is inspired by the physical process of heating and slowly cooling metal to relieve internal stresses and achieve a strong crystal lattice. In the algorithmic analogy, the \\\"temperature\\\" parameter starts high, allowing random moves that may worsen the objective function, and gradually decreases to reduce the probability of such moves. This mechanism helps the search escape local optima by occasionally allowing a \\\"bad\\\" move with a probability that decreases over time.\"), \"\\n\", React.createElement(_components.p, null, \"A commonly used acceptance probability for a move from state \", React.createElement(Latex, {\n    text: \"\\\\(s\\\\)\"\n  }), \" to state \", React.createElement(Latex, {\n    text: \"\\\\(s'\\\\)\"\n  }), \" with evaluation difference \", React.createElement(Latex, {\n    text: \"\\\\(\\\\Delta E = E(s') - E(s)\\\\)\"\n  }), \" is:\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\nP(\\\\Delta E) = \\\\exp\\\\left(-\\\\frac{\\\\Delta E}{T}\\\\right)\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"where \", React.createElement(Latex, {\n    text: \"\\\\(T\\\\)\"\n  }), \" is the current temperature. If \", React.createElement(Latex, {\n    text: \"\\\\(\\\\Delta E < 0\\\\)\"\n  }), \" (the move is better), it is always accepted.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"genetic-algorithms-and-other-evolutionary-methods\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#genetic-algorithms-and-other-evolutionary-methods\",\n    \"aria-label\": \"genetic algorithms and other evolutionary methods permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"genetic algorithms and other evolutionary methods\"), \"\\n\", React.createElement(_components.p, null, \"Genetic algorithms (GAs) operate on a population of candidate solutions (often encoded as \\\"chromosomes\\\") and use biologically inspired operations — selection, crossover, mutation — to iteratively evolve better solutions. The main steps are:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Initialization\"), \" of the population.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Selection\"), \" of the fittest individuals to reproduce.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Crossover\"), \" between selected individuals to create new offspring.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Mutation\"), \" of offspring to maintain diversity in the population.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Replacement\"), \" of part of the population with new offspring.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Over many generations, GAs can yield high-quality solutions even for complex search spaces, given sufficient time and a well-designed fitness function.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"local-search-in-continuous-spaces\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#local-search-in-continuous-spaces\",\n    \"aria-label\": \"local search in continuous spaces permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"local search in continuous spaces\"), \"\\n\", React.createElement(_components.p, null, \"Local search algorithms also extend to continuous domains. Gradient-based methods like \", React.createElement(_components.strong, null, \"gradient descent\"), \" or \", React.createElement(_components.strong, null, \"stochastic gradient descent\"), \" (though typically used in machine learning contexts) can be seen as local search strategies that move in the direction of steepest descent in the solution space. Such methods can be combined with heuristics, momentum terms, or advanced adaptation techniques (e.g., Adam optimizer in deep learning) to refine local search performance in high-dimensional continuous optimization.\"), \"\\n\", React.createElement(_components.p, null, \"Local search algorithms are essential in engineering, finance, and operations research, where solution spaces might be enormous, and a thoroughly systematic search would be entirely impractical. Although local search does not guarantee an optimal solution, it is often one of the few feasible approaches for large-scale problems.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"search-in-complex-and-uncertain-environments\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#search-in-complex-and-uncertain-environments\",\n    \"aria-label\": \"search in complex and uncertain environments permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"search in complex and uncertain environments\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"dealing-with-nondeterministic-actions\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#dealing-with-nondeterministic-actions\",\n    \"aria-label\": \"dealing with nondeterministic actions permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"dealing with nondeterministic actions\"), \"\\n\", React.createElement(_components.p, null, \"In real-world scenarios, actions might not always have a single guaranteed effect. A delivery robot, for instance, could slip or face unexpected obstructions. In such nondeterministic environments, an action might lead to several possible outcomes. When formulating a search problem, we can represent this by branching into multiple successor states for each action, each with a certain probability or range of outcomes.\"), \"\\n\", React.createElement(_components.p, null, \"Algorithms like \", React.createElement(_components.strong, null, \"AND-OR search\"), \" can handle environments in which the agent must succeed under the worst-case outcome or must handle branching contingencies. If there is a nontrivial probability associated with each outcome, we can incorporate expected cost or utility in the search framework.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"search-in-partially-observable-environments\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#search-in-partially-observable-environments\",\n    \"aria-label\": \"search in partially observable environments permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"search in partially observable environments\"), \"\\n\", React.createElement(_components.p, null, \"When the agent does not fully observe the underlying state, we can adopt a \", React.createElement(_components.strong, null, \"belief state\"), \" approach, in which each \\\"state\\\" in our search representation is actually a set (or distribution) of possible real states. Searching in the space of belief states often leads to combinatorial explosions, but techniques like \", React.createElement(_components.strong, null, \"Partially Observable Markov Decision Processes (POMDPs)\"), \" provide a framework for acting optimally under uncertainty and partial observability.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"online-search-agents-for-unknown-environments\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#online-search-agents-for-unknown-environments\",\n    \"aria-label\": \"online search agents for unknown environments permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"online search agents for unknown environments\"), \"\\n\", React.createElement(_components.p, null, \"Sometimes the agent must act before it has complete knowledge of the environment, known as \", React.createElement(_components.strong, null, \"online search\"), \". Here, the agent might not know the transition model or the cost structure in advance. It must actively explore and discover the environment while still striving toward a goal. Online versions of BFS or DFS can be used, but they need to incorporate real-time updates to the state space. Some algorithms maintain a learned map of the environment and replan incrementally (e.g., \", React.createElement(_components.strong, null, \"LRTA\"), \"*, or Learning Real-Time A*, which updates its heuristic values based on local experiences).\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"constraint-satisfaction-problems-csps\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#constraint-satisfaction-problems-csps\",\n    \"aria-label\": \"constraint satisfaction problems csps permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"constraint satisfaction problems (csps)\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"defining-csps-variables-domains-constraints\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#defining-csps-variables-domains-constraints\",\n    \"aria-label\": \"defining csps variables domains constraints permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"defining csps (variables, domains, constraints)\"), \"\\n\", React.createElement(_components.p, null, \"Constraint Satisfaction Problems are a specialized form of search where states are defined by the values of a fixed set of variables. The goal is to find an assignment of values to variables that satisfies all the given constraints. Examples include \", React.createElement(_components.strong, null, \"map coloring\"), \" (assigning colors to regions on a map so that no two adjacent regions have the same color), \", React.createElement(_components.strong, null, \"cryptarithmetic puzzles\"), \", \", React.createElement(_components.strong, null, \"Sudoku\"), \", and various scheduling and resource allocation tasks.\"), \"\\n\", React.createElement(_components.p, null, \"A CSP is typically specified by:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"A set of variables \", React.createElement(Latex, {\n    text: \"\\\\(X = \\\\{ x_1, x_2, \\\\dots, x_n \\\\}\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"Domains for each variable \", React.createElement(Latex, {\n    text: \"\\\\(D(x_i)\\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"Constraints \", React.createElement(Latex, {\n    text: \"\\\\(C\\\\)\"\n  }), \" that specify allowable combinations of values.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"constraint-propagation-and-inference-in-csps\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#constraint-propagation-and-inference-in-csps\",\n    \"aria-label\": \"constraint propagation and inference in csps permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"constraint propagation and inference in csps\"), \"\\n\", React.createElement(_components.p, null, \"Instead of blindly enumerating all possible value assignments, CSP solvers can use constraint propagation to reduce the search space. By systematically applying constraints, we can eliminate impossible or inconsistent values early. For example, \", React.createElement(_components.strong, null, \"Arc Consistency\"), \" algorithms (like AC-3) propagate domain reductions: if a certain value of \", React.createElement(Latex, {\n    text: \"\\\\(x\\\\)\"\n  }), \" is incompatible with every possible value of \", React.createElement(Latex, {\n    text: \"\\\\(y\\\\)\"\n  }), \", then we can remove that value from \", React.createElement(Latex, {\n    text: \"\\\\(x\\\\)\"\n  }), \"'s domain.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"backtracking-search-for-csps\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#backtracking-search-for-csps\",\n    \"aria-label\": \"backtracking search for csps permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"backtracking search for csps\"), \"\\n\", React.createElement(_components.p, null, \"Backtracking is essentially a depth-first search that attempts to assign values to variables sequentially. If a partial assignment violates any constraint, the algorithm backtracks immediately. Intelligent ordering heuristics (like the \", React.createElement(_components.strong, null, \"minimum remaining values\"), \" heuristic) can greatly enhance efficiency by choosing the variable that is most constrained first.\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Example\"), \": Suppose you have a CSP with variables \", React.createElement(Latex, {\n    text: \"\\\\(x_1, x_2, x_3\\\\)\"\n  }), \" each with domain \", (1, 2, 3), \", and constraints that \", React.createElement(Latex, {\n    text: \"\\\\(x_1 \\\\neq x_2\\\\)\"\n  }), \", \", React.createElement(Latex, {\n    text: \"\\\\(x_2 \\\\neq x_3\\\\)\"\n  }), \", and \", React.createElement(Latex, {\n    text: \"\\\\(x_1 \\\\neq x_3\\\\)\"\n  }), \". A naive approach enumerates all combinations (27 total). A backtracking approach with intelligent ordering might reduce the expansions drastically by pruning inconsistent partial solutions as soon as they appear.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"local-search-for-csps\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#local-search-for-csps\",\n    \"aria-label\": \"local search for csps permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"local search for csps\"), \"\\n\", React.createElement(_components.p, null, \"Local search can also solve CSPs by starting with a complete but inconsistent assignment (e.g., assign all variables random values) and then iteratively making changes that reduce the number of violated constraints. For example, in a map-coloring CSP, you could randomly color each region, then repeatedly pick a conflicted region and change its color to reduce the conflict count. This is the essence of the \", React.createElement(_components.strong, null, \"min-conflicts\"), \" algorithm, famously applied to the n-queens problem for extremely large n.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"the-structure-of-problems-constraint-graphs-problem-decomposition\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#the-structure-of-problems-constraint-graphs-problem-decomposition\",\n    \"aria-label\": \"the structure of problems constraint graphs problem decomposition permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"the structure of problems (constraint graphs, problem decomposition)\"), \"\\n\", React.createElement(_components.p, null, \"CSPs can be visualized using \", React.createElement(_components.strong, null, \"constraint graphs\"), \", where each node is a variable, and edges denote constraints between variables. Some graphs have specific structures (like trees or bipartite forms) that admit polynomial-time solutions (tree-structured CSPs can be solved efficiently via dynamic programming over the tree). More advanced decomposition methods, like \", React.createElement(_components.strong, null, \"cycle cutset\"), \" or \", React.createElement(_components.strong, null, \"tree decomposition\"), \", can also reduce the complexity of certain CSPs by transforming them into simpler subproblems.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"adversarial-search-and-games\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#adversarial-search-and-games\",\n    \"aria-label\": \"adversarial search and games permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"adversarial search and games\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"motivation-for-adversarial-search-two-player-games-competitive-environments\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#motivation-for-adversarial-search-two-player-games-competitive-environments\",\n    \"aria-label\": \"motivation for adversarial search two player games competitive environments permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"motivation for adversarial search (two-player games, competitive environments)\"), \"\\n\", React.createElement(_components.p, null, \"Adversarial search arises in game-playing scenarios where two (or more) agents compete. One agent's gain is often another's loss, so the search problem is no longer about finding a single path to a goal but maximizing a utility function in the presence of an opponent who tries to minimize it.\"), \"\\n\", React.createElement(_components.p, null, \"Classic examples include board games like chess, checkers, Go, or tic-tac-toe. The hallmark of adversarial search is the presence of a second player (or multiple players) whose actions directly impact your outcome.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"optimal-decisions-in-games-minimax\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#optimal-decisions-in-games-minimax\",\n    \"aria-label\": \"optimal decisions in games minimax permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"optimal decisions in games (minimax)\"), \"\\n\", React.createElement(_components.p, null, \"Minimax is the foundational technique for deterministic, perfect-information games involving two players: the \\\"maximizing\\\" player tries to maximize the score, while the \\\"minimizing\\\" player tries to minimize it. A minimax tree alternates layers labeled \\\"max\\\" and \\\"min\\\". The leaf nodes are assigned utility values (the outcome from the perspective of the maximizing player), and these values get backed up to the root by alternating min or max operations at each layer.\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Formal definition\"), \":\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\n\\\\text{Minimax}(n) = \\n\\\\begin{cases}\\n\\\\max_{n' \\\\in \\\\text{children}(n)} \\\\text{Minimax}(n'), & \\\\text{if } n \\\\text{ is a max node};\\\\\\\\[6pt]\\n\\\\min_{n' \\\\in \\\\text{children}(n)} \\\\text{Minimax}(n'), & \\\\text{if } n \\\\text{ is a min node}.\\n\\\\end{cases}\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"This works perfectly for small game trees but becomes infeasible for large games like chess or Go because the branching factor is huge.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"heuristic-alpha-beta-tree-search-and-pruning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#heuristic-alpha-beta-tree-search-and-pruning\",\n    \"aria-label\": \"heuristic alpha beta tree search and pruning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"heuristic alpha-beta tree search and pruning\"), \"\\n\", React.createElement(_components.p, null, \"Alpha-beta pruning enhances minimax search by pruning branches that cannot affect the final decision. It maintains two bounds: \", React.createElement(Highlight, null, \"alpha\"), \" (the best value so far for the maximizing player) and \", React.createElement(Highlight, null, \"beta\"), \" (the best value so far for the minimizing player). When alpha becomes greater than or equal to beta, further exploration of that branch can be cut off. This yields the same result as pure minimax but often with much fewer node expansions, particularly in well-ordered trees.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"monte-carlo-tree-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#monte-carlo-tree-search\",\n    \"aria-label\": \"monte carlo tree search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"monte carlo tree search\"), \"\\n\", React.createElement(_components.p, null, \"Monte Carlo Tree Search (MCTS) gained prominence through successes in games with enormous branching factors, such as Go (famously used in AlphaGo by DeepMind). MCTS incrementally builds a game tree through repeated random simulations. The four phases of MCTS are:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Selection\"), \": Start at the root and select child nodes according to some policy (e.g., UCB1) until you reach a leaf.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Expansion\"), \": Expand the leaf node by generating one or more child nodes.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Simulation\"), \": Play out random moves from the expanded node until a terminal state is reached.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Backpropagation\"), \": Propagate the simulation result back up the tree, updating statistics (win rates, Q-values, etc.) at each node.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"After many iterations, the most visited or highest-value child of the root is typically chosen as the next move. MCTS is widely cited in top-tier AI game research (Browne and gang, IEEE Trans. on CI in Games 2012).\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"stochastic-games-and-partially-observable-games\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#stochastic-games-and-partially-observable-games\",\n    \"aria-label\": \"stochastic games and partially observable games permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"stochastic games and partially observable games\"), \"\\n\", React.createElement(_components.p, null, \"In some games, chance (dice rolls, card draws) or hidden information (opponent's cards) must be taken into account, leading to a more general search approach that includes chance nodes in the game tree or a belief-based representation. Pioneering approaches combine minimax or alpha-beta style expansions with expected utility calculations to handle chance nodes effectively (e.g., searching game trees for backgammon or poker).\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"limitations-of-game-search-algorithms\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#limitations-of-game-search-algorithms\",\n    \"aria-label\": \"limitations of game search algorithms permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"limitations of game search algorithms\"), \"\\n\", React.createElement(_components.p, null, \"Even with alpha-beta pruning or MCTS, game search can run into severe computational challenges. Real games like chess have an astronomically large state space. Heuristic evaluation functions become indispensable, domain knowledge is often incorporated (e.g., advanced piece-value heuristics in chess), and specialized data structures (like transposition tables) help avoid repeated expansions of identical positions. Nonetheless, building a strong game-playing AI often demands sophisticated engineering, search enhancements, and efficient parallelization.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"classical-search-and-its-extensions\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#classical-search-and-its-extensions\",\n    \"aria-label\": \"classical search and its extensions permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"classical search and its extensions\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"review-of-classic-search-algorithms-bfs-dfs-uniform-cost-a\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#review-of-classic-search-algorithms-bfs-dfs-uniform-cost-a\",\n    \"aria-label\": \"review of classic search algorithms bfs dfs uniform cost a permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"review of classic search algorithms (bfs, dfs, uniform cost, a*)\"), \"\\n\", React.createElement(_components.p, null, \"Classical search provides the building blocks for problem-solving in AI:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"BFS\"), \": Guaranteed to find the shallowest solution, but can be memory-intensive.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"DFS\"), \": Efficient memory usage, but can get stuck in deep or infinite paths.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Uniform-cost search\"), \": Extends BFS to handle varying costs, guaranteeing an optimal solution.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"A*\"), \": Incorporates heuristics to guide search more intelligently.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"when-to-use-informed-vs-uninformed-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#when-to-use-informed-vs-uninformed-search\",\n    \"aria-label\": \"when to use informed vs uninformed search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"when to use informed vs. uninformed search\"), \"\\n\", React.createElement(_components.p, null, \"Informed (heuristic) search methods (like A*) should be used whenever a useful heuristic function is available. If no heuristic is readily available or one can't be reliably derived, uninformed approaches may be the only choice. However, in real-world projects, domain knowledge is often gleaned from subject matter experts to craft heuristics, or we might adopt learning methods to generate approximate heuristics.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"iterative-deepening-search-strategies\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#iterative-deepening-search-strategies\",\n    \"aria-label\": \"iterative deepening search strategies permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"iterative deepening search strategies\"), \"\\n\", React.createElement(_components.p, null, \"Iterative deepening depth-first search (IDDFS) is a strategy that runs DFS with a depth limit of \", React.createElement(Latex, {\n    text: \"\\\\(l\\\\)\"\n  }), \" and increments \", React.createElement(Latex, {\n    text: \"\\\\(l\\\\)\"\n  }), \" in each iteration until the goal is found. This approach combines the memory advantage of DFS with the completeness of BFS. IDDFS re-explores states multiple times but still often proves effective, especially when the search space is large but solutions exist at relatively shallow depths.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"bidirectional-search\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#bidirectional-search\",\n    \"aria-label\": \"bidirectional search permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"bidirectional search\"), \"\\n\", React.createElement(_components.p, null, \"Bidirectional search runs two simultaneous searches: one forward from the initial state and one backward from the goal (or a set of goals). By meeting in the middle, the search can drastically reduce the search space from \", React.createElement(Latex, {\n    text: \"\\\\(O(b^d)\\\\)\"\n  }), \" to approximately \", React.createElement(Latex, {\n    text: \"\\\\(O(b^{d/2})\\\\)\"\n  }), \" in each direction, yielding \", React.createElement(Latex, {\n    text: \"\\\\(O(b^{d/2})\\\\)\"\n  }), \" overall. The challenge often lies in implementing the backward search if the goal is not a single explicit state, or if the actions are not easily reversible.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"advanced-topics\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#advanced-topics\",\n    \"aria-label\": \"advanced topics permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"advanced topics\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"algorithmic-problem-solving-at-scale\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#algorithmic-problem-solving-at-scale\",\n    \"aria-label\": \"algorithmic problem solving at scale permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"algorithmic problem solving at scale\"), \"\\n\", React.createElement(_components.p, null, \"Real-world problems often require searching huge state spaces under strict time or memory constraints. Researchers in conferences like NeurIPS or ICML regularly propose advanced search methods that incorporate sampling, parallelization, or advanced data structures to handle scale:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Parallel and distributed search\"), \": Use multiple processors/GPUs to expand states in parallel.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Hierarchical planning\"), \": Divide a problem into subproblems or layers.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Symbolic search\"), \": Represent states and expansions in a compressed symbolic form (Binary Decision Diagrams, for example) to handle large state spaces.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"enhancing-heuristic-functions-pattern-databases-learning-heuristics\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#enhancing-heuristic-functions-pattern-databases-learning-heuristics\",\n    \"aria-label\": \"enhancing heuristic functions pattern databases learning heuristics permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"enhancing heuristic functions (pattern databases, learning heuristics)\"), \"\\n\", React.createElement(_components.p, null, \"Well-designed heuristic functions can drastically improve search. \\\"Pattern databases\\\" store exact solutions for smaller subproblems and use them to create perfect heuristics for partial configurations. For instance, in the 15-puzzle, a pattern database might store the exact moves needed to place a subset of tiles correctly, ignoring others. Summing multiple pattern databases (carefully to preserve admissibility) can offer powerful heuristics.\"), \"\\n\", React.createElement(_components.p, null, \"Machine learning techniques can also learn heuristics from experience. Reinforcement learning or self-play methods (like those used in AlphaZero) can generalize heuristics for complex domains, surpassing human-engineered knowledge in some cases.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"incorporating-domain-specific-knowledge\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#incorporating-domain-specific-knowledge\",\n    \"aria-label\": \"incorporating domain specific knowledge permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"incorporating domain-specific knowledge\"), \"\\n\", React.createElement(_components.p, null, \"A large part of success in AI search often hinges on domain-specific knowledge that drastically prunes the state space. In scheduling, for instance, knowledge about priority constraints or typical resource bottlenecks can guide the search away from obviously infeasible or suboptimal paths. In puzzle solving, specific transformations or known patterns can skip large swaths of states.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"memory-bounded-search-ida-sma\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#memory-bounded-search-ida-sma\",\n    \"aria-label\": \"memory bounded search ida sma permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"memory-bounded search (ida*, sma*)\"), \"\\n\", React.createElement(_components.p, null, \"To handle the excessive memory usage of algorithms like A*, researchers introduced depth-first variants that iteratively deepen on \", React.createElement(Latex, {\n    text: \"\\\\(f(n)\\\\)\"\n  }), \" instead of depth:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"IDA*\"), \" (Iterative Deepening A*) uses successive depth limits in terms of the \", React.createElement(Latex, {\n    text: \"\\\\(f(n)\\\\)\"\n  }), \" value, not the level in the tree.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"SMA*\"), \" (Simplified Memory-bounded A*) is similar to A* but discards the worst node when memory is full, storing only essential parts of the tree.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"These methods aim to preserve the optimality of A* while managing memory constraints more gracefully.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"dealing-with-real-time-constraints\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#dealing-with-real-time-constraints\",\n    \"aria-label\": \"dealing with real time constraints permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"dealing with real-time constraints\"), \"\\n\", React.createElement(_components.p, null, \"Sometimes, the agent must produce an action within a strict time limit (real-time decision-making). In these cases, the search might be truncated after exploring some limited number of states. A partial plan can be executed, with re-planning happening on the fly. Real-time heuristic search algorithms (like RTA*, LRTA*) adapt the heuristic based on actual outcomes in the environment, gradually improving their estimates over repeated trials.\"), \"\\n\", React.createElement(_components.p, null, \"This style of search is especially relevant in robotics and real-time strategy games, where actions must be taken continuously, and the environment might change faster than a comprehensive search can complete.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"putting-it-all-together\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#putting-it-all-together\",\n    \"aria-label\": \"putting it all together permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"putting it all together\"), \"\\n\", React.createElement(_components.p, null, \"AI search is more than just BFS or A*; it's a broad family of algorithms and techniques designed to navigate complex spaces of possibilities and to systematically (or sometimes stochastically) pinpoint solutions in an efficient manner. Search methods range from naive to highly informed, from exhaustive expansions to local or evolutionary methods, from deterministic to probabilistic approaches, and from single-agent optimization to adversarial game-playing scenarios. Understanding these methods — as well as how to select, configure, or combine them — is critical for designing intelligent agents capable of tackling a variety of tasks.\"), \"\\n\", React.createElement(_components.p, null, \"Modern research extends classical search concepts in fascinating ways. For instance, advanced heuristics might be learned via neural networks, as seen in the latest chess, shogi, or Go engines (Silver and gang, Science 2018), where search complements deep learning. Constraint satisfaction has advanced to handle dynamic and distributed CSPs, and local search has evolved into large-scale optimization frameworks used in myriad industries. Adversarial search strategies form the foundation of many game-playing AIs and even negotiation or bidding agents in economic domains. Meanwhile, real-time search, belief state representation, or hierarchical expansions cater to partial observability and uncertain or rapidly changing environments.\"), \"\\n\", React.createElement(_components.p, null, \"In practice, the best approach to any search problem often involves a combination of these methods, along with domain-specific tricks, data structures (like transposition tables or pattern databases), or real-time learning of heuristics. Many of the underlying frameworks introduced here continue to inspire new research directions, from partial expansions to incorporate machine learning predictions, to memory-bounded or distributed solutions for massive search tasks, to synergy with reinforcement learning and generative models for complex decision-making.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"illustrative-figures-and-code\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#illustrative-figures-and-code\",\n    \"aria-label\": \"illustrative figures and code permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"illustrative figures and code\"), \"\\n\", React.createElement(_components.p, null, \"Below, I'll add a few schematic images to help visualize key concepts:\"), \"\\n\", React.createElement(Image, {\n    alt: \"Example of a search tree\",\n    path: \"\",\n    caption: \"A basic search tree expanding from an initial state. Each branching factor leads to a new set of states. Dashed lines can represent pruned branches.\",\n    zoom: \"false\"\n  }), \"\\n\", React.createElement(Image, {\n    alt: \"Constraint graph illustration\",\n    path: \"\",\n    caption: \"Constraint graph for a simple coloring problem. Each node is a region/variable, edges denote adjacency constraints.\",\n    zoom: \"false\"\n  }), \"\\n\", React.createElement(_components.p, null, \"And, for completeness, here's a more detailed code snippet demonstrating a local search approach (a simple hill-climbing variant with random restarts for a TSP-like problem in pseudocode form):\"), \"\\n\", React.createElement(Code, {\n    text: `\nimport random\n\ndef cost_function(solution, distances):\n    total_dist = 0\n    for i in range(len(solution) - 1):\n        total_dist += distances[solution[i]][solution[i+1]]\n    # Add distance for returning to start if needed\n    total_dist += distances[solution[-1]][solution[0]]\n    return total_dist\n\ndef get_random_neighbor(solution):\n    # swap two random indices\n    new_solution = solution[:]\n    i, j = random.sample(range(len(solution)), 2)\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    return new_solution\n\ndef hill_climb_random_restart(nodes, distances, num_restarts=10):\n    best_solution = None\n    best_cost = float('inf')\n    \n    for _ in range(num_restarts):\n        # Generate a random initial solution\n        current_solution = nodes[:]\n        random.shuffle(current_solution)\n        current_cost = cost_function(current_solution, distances)\n        \n        improved = True\n        while improved:\n            improved = False\n            neighbor = get_random_neighbor(current_solution)\n            neighbor_cost = cost_function(neighbor, distances)\n            \n            if neighbor_cost < current_cost:\n                current_solution = neighbor\n                current_cost = neighbor_cost\n                improved = True\n        \n        if current_cost < best_cost:\n            best_cost = current_cost\n            best_solution = current_solution[:]\n    \n    return best_solution, best_cost\n`\n  }), \"\\n\", React.createElement(_components.p, null, \"This code outlines a basic approach: for a given set of nodes (cities) and a distance matrix, it tries to reorder them to minimize the total travel distance. It performs multiple restarts to avoid local minima. In practice, you can refine such a method with more sophisticated strategies, advanced metaheuristics, or domain-specific constraints and optimizations.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"final-remarks\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#final-remarks\",\n    \"aria-label\": \"final remarks permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"final remarks\"), \"\\n\", React.createElement(_components.p, null, \"Search is a fundamental pillar of AI, providing general-purpose methods to systematically explore sets of possible solutions. Practically every AI curriculum includes search early on because it not only clarifies how intelligent agents tackle problems but also reveals the key challenges — like exponential growth in complexity and the potential for sophisticated heuristic guidance or partial expansions.\"), \"\\n\", React.createElement(_components.p, null, \"Selecting or designing the right search approach involves carefully weighing problem size, available domain knowledge (to craft heuristics or constraints), memory limits, time requirements, and whether we're dealing with single-agent optimization, multiagent adversarial scenarios, or uncertain and partially observable worlds. From BFS to A* to local search, from CSP solvers to adversarial and real-time search, these techniques shape the backbone of problem-solving in AI. Research continues to refine and innovate upon these core concepts, integrating them with modern machine learning and domain-specific knowledge, pushing the frontiers of what search-based AI can achieve.\"), \"\\n\", React.createElement(_components.p, null, \"I hope this comprehensive deep dive into AI search strategies provides clarity and sparks ideas for applying these concepts to your own projects, research, and further study.\"));\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? React.createElement(MDXLayout, props, React.createElement(_createMdxContent, props)) : _createMdxContent(props);\n}\nexport default MDXContent;\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","import GATSBY_COMPILED_MDX from \"/home/avrtt/Repos/avrtt.github.io/src/pages/posts/research/ai_search.mdx\";\nimport React, {useState, useEffect} from 'react';\nimport {useSiteMetadata} from \"../hooks/useSiteMetadata\";\nimport RemoveMarkdown from 'remove-markdown';\nimport {ImageContext} from '../context/ImageContext';\nimport {MDXProvider} from '@mdx-js/react';\nimport Image from '../components/PostImage';\nimport {motion} from 'framer-motion';\nimport SEO from \"../components/seo\";\nimport PostBanner from '../components/PostBanner';\nimport PostBottom from '../components/PostBottom';\nimport {wordsPerMinuteAdventures, wordsPerMinuteResearch, wordsPerMinuteThoughts} from '../data/commonVariables';\nimport {graphql} from 'gatsby';\nimport PartOfCourseNotice from \"../components/PartOfCourseNotice\";\nimport * as stylesButtonsCommon from \"../styles/buttons_common.module.scss\";\nimport * as stylesCustomPostLayouts from \"../styles/custom_post_layouts.module.scss\";\nimport * as stylesTableOfContents from \"../styles/table_of_contents.module.scss\";\nimport * as stylesTagBadges from \"../styles/tag_badges.module.scss\";\nfunction formatReadTime(minutes) {\n  if (minutes <= 10) return '~10 min';\n  if (minutes <= 20) return '~20 min';\n  if (minutes <= 30) return '~30 min';\n  if (minutes <= 40) return '~40 min';\n  if (minutes <= 50) return '~50 min';\n  if (minutes <= 60) return '~1 h';\n  const hours = Math.floor(minutes / 60);\n  const remainder = minutes % 60;\n  if (remainder <= 30) {\n    return `~${hours}${remainder > 0 ? '.5' : ''} h`;\n  }\n  return `~${hours + 1} h`;\n}\nconst TableOfContents = ({toc}) => {\n  if (!toc || !toc.items) return null;\n  const handleClick = (e, url) => {\n    e.preventDefault();\n    const targetId = url.replace('#', '');\n    const targetElement = document.getElementById(targetId);\n    if (targetElement) {\n      targetElement.scrollIntoView({\n        behavior: 'smooth',\n        block: 'start'\n      });\n    }\n  };\n  return React.createElement(\"nav\", {\n    className: stylesTableOfContents.toc\n  }, React.createElement(\"ul\", null, toc.items.map((item, index) => React.createElement(\"li\", {\n    key: index\n  }, React.createElement(\"a\", {\n    href: item.url,\n    onClick: e => handleClick(e, item.url)\n  }, item.title), item.items && React.createElement(TableOfContents, {\n    toc: {\n      items: item.items\n    }\n  })))));\n};\nexport function PostTemplate({data: {mdx, allMdx, allPostImages}, children}) {\n  const {frontmatter, body, tableOfContents} = mdx;\n  const index = frontmatter.index;\n  const slug = frontmatter.slug;\n  const section = slug.split('/')[1];\n  const posts = allMdx.nodes.filter(post => post.frontmatter.slug.includes(`/${section}/`));\n  const sortedPosts = posts.sort((a, b) => a.frontmatter.index - b.frontmatter.index);\n  const currentIndex = sortedPosts.findIndex(post => post.frontmatter.index === index);\n  const nextPost = sortedPosts[currentIndex + 1];\n  const lastPost = sortedPosts[currentIndex - 1];\n  const trimmedSlug = frontmatter.slug.replace(/\\/$/, '');\n  const keyCurrent = (/[^/]*$/).exec(trimmedSlug)[0];\n  const basePath = `posts/${section}/content/${keyCurrent}/`;\n  const [isWideLayout, setIsWideLayout] = useState(frontmatter.flagWideLayoutByDefault);\n  const [isAnimating, setIsAnimating] = useState(false);\n  const toggleLayout = () => {\n    setIsWideLayout(!isWideLayout);\n  };\n  useEffect(() => {\n    setIsAnimating(true);\n    const timer = setTimeout(() => setIsAnimating(false), 340);\n    return () => clearTimeout(timer);\n  }, [isWideLayout]);\n  var wordsPerMinute;\n  if (section === \"adventures\") {\n    wordsPerMinute = wordsPerMinuteAdventures;\n  } else if (section === \"research\") {\n    wordsPerMinute = wordsPerMinuteResearch;\n  } else if (section === \"thoughts\") {\n    wordsPerMinute = wordsPerMinuteThoughts;\n  }\n  const plainTextBody = RemoveMarkdown(body).replace(/import .*? from .*?;/g, '').replace(/<.*?>/g, '').replace(/\\{\\/\\*[\\s\\S]*?\\*\\/\\}/g, '').trim();\n  const wordCount = plainTextBody.split(/\\s+/).length;\n  const baseReadTimeMinutes = Math.ceil(wordCount / wordsPerMinute);\n  const extraTime = frontmatter.extraReadTimeMin || 0;\n  const totalReadTime = baseReadTimeMinutes + extraTime;\n  const readTime = formatReadTime(totalReadTime);\n  const notices = [{\n    flag: frontmatter.flagDraft,\n    component: () => import(\"../components/NotFinishedNotice\")\n  }, {\n    flag: frontmatter.flagMindfuckery,\n    component: () => import(\"../components/MindfuckeryNotice\")\n  }, {\n    flag: frontmatter.flagRewrite,\n    component: () => import(\"../components/RewriteNotice\")\n  }, {\n    flag: frontmatter.flagOffensive,\n    component: () => import(\"../components/OffensiveNotice\")\n  }, {\n    flag: frontmatter.flagProfane,\n    component: () => import(\"../components/ProfanityNotice\")\n  }, {\n    flag: frontmatter.flagMultilingual,\n    component: () => import(\"../components/MultilingualNotice\")\n  }, {\n    flag: frontmatter.flagUnreliably,\n    component: () => import(\"../components/UnreliablyNotice\")\n  }, {\n    flag: frontmatter.flagPolitical,\n    component: () => import(\"../components/PoliticsNotice\")\n  }, {\n    flag: frontmatter.flagCognitohazard,\n    component: () => import(\"../components/CognitohazardNotice\")\n  }, {\n    flag: frontmatter.flagHidden,\n    component: () => import(\"../components/HiddenNotice\")\n  }];\n  const [loadedNotices, setLoadedNotices] = useState([]);\n  useEffect(() => {\n    notices.forEach(({flag, component}) => {\n      if (flag) {\n        component().then(module => {\n          setLoadedNotices(prev => [...prev, module.default]);\n        });\n      }\n    });\n  }, []);\n  return React.createElement(motion.div, {\n    initial: {\n      opacity: 0\n    },\n    animate: {\n      opacity: 1\n    },\n    exit: {\n      opacity: 0\n    },\n    transition: {\n      duration: 0.15\n    }\n  }, React.createElement(PostBanner, {\n    postNumber: frontmatter.index,\n    date: frontmatter.date,\n    updated: frontmatter.updated,\n    readTime: readTime,\n    difficulty: frontmatter.difficultyLevel,\n    title: frontmatter.title,\n    desc: frontmatter.desc,\n    banner: frontmatter.banner,\n    section: section,\n    postKey: keyCurrent,\n    isMindfuckery: frontmatter.flagMindfuckery,\n    mainTag: frontmatter.mainTag\n  }), React.createElement(\"div\", {\n    style: {\n      display: \"flex\",\n      justifyContent: \"flex-end\",\n      flexWrap: \"wrap\",\n      maxWidth: \"75%\",\n      marginLeft: \"auto\",\n      paddingRight: \"1vw\",\n      marginTop: \"-6vh\",\n      marginBottom: \"4vh\"\n    }\n  }, frontmatter.otherTags.map((tag, index) => React.createElement(\"span\", {\n    key: index,\n    className: `noselect ${stylesTagBadges.tagPosts}`,\n    style: {\n      margin: \"0 5px 5px 0\"\n    }\n  }, tag))), React.createElement(\"div\", {\n    class: \"postBody\"\n  }, React.createElement(TableOfContents, {\n    toc: tableOfContents\n  })), React.createElement(\"br\"), React.createElement(\"div\", {\n    style: {\n      margin: \"0 10% -2vh 30%\",\n      textAlign: \"right\"\n    }\n  }, React.createElement(motion.button, {\n    class: \"noselect\",\n    className: stylesCustomPostLayouts.postButton,\n    id: stylesCustomPostLayouts.postLayoutSwitchButton,\n    onClick: toggleLayout,\n    whileTap: {\n      scale: 0.93\n    }\n  }, React.createElement(motion.div, {\n    className: stylesButtonsCommon.buttonTextWrapper,\n    key: isWideLayout,\n    initial: {\n      opacity: 0\n    },\n    animate: {\n      opacity: 1\n    },\n    exit: {\n      opacity: 0\n    },\n    transition: {\n      duration: 0.3,\n      ease: \"easeInOut\"\n    }\n  }, isWideLayout ? \"Switch to default layout\" : \"Switch to wide layout\"))), React.createElement(\"br\"), React.createElement(\"div\", {\n    class: \"postBody\",\n    style: {\n      margin: isWideLayout ? \"0 -14%\" : \"\",\n      maxWidth: isWideLayout ? \"200%\" : \"\",\n      transition: \"margin 1s ease, max-width 1s ease, padding 1s ease\"\n    }\n  }, React.createElement(\"div\", {\n    className: `${stylesCustomPostLayouts.textContent} ${isAnimating ? stylesCustomPostLayouts.fadeOut : stylesCustomPostLayouts.fadeIn}`\n  }, loadedNotices.map((NoticeComponent, index) => React.createElement(NoticeComponent, {\n    key: index\n  })), frontmatter.indexCourse ? React.createElement(PartOfCourseNotice, {\n    index: frontmatter.indexCourse,\n    category: frontmatter.courseCategoryName\n  }) : \"\", React.createElement(ImageContext.Provider, {\n    value: {\n      images: allPostImages.nodes,\n      basePath: basePath.replace(/\\/$/, '') + '/'\n    }\n  }, React.createElement(MDXProvider, {\n    components: {\n      Image\n    }\n  }, children)))), React.createElement(PostBottom, {\n    nextPost: nextPost,\n    lastPost: lastPost,\n    keyCurrent: keyCurrent,\n    section: section\n  }));\n}\nPostTemplate\nexport default function GatsbyMDXWrapper(props) {\n  return React.createElement(PostTemplate, props, React.createElement(GATSBY_COMPILED_MDX, props));\n}\nexport function Head({data}) {\n  const {frontmatter} = data.mdx;\n  const title = frontmatter.titleSEO || frontmatter.title;\n  const titleOG = frontmatter.titleOG || title;\n  const titleTwitter = frontmatter.titleTwitter || title;\n  const description = frontmatter.descSEO || frontmatter.desc;\n  const descriptionOG = frontmatter.descOG || description;\n  const descriptionTwitter = frontmatter.descTwitter || description;\n  const schemaType = frontmatter.schemaType || \"BlogPosting\";\n  const keywords = frontmatter.keywordsSEO;\n  const datePublished = frontmatter.date;\n  const dateModified = frontmatter.updated || datePublished;\n  const imageOG = frontmatter.imageOG || frontmatter.banner?.childImageSharp?.gatsbyImageData?.images?.fallback?.src;\n  const imageAltOG = frontmatter.imageAltOG || descriptionOG;\n  const imageTwitter = frontmatter.imageTwitter || imageOG;\n  const imageAltTwitter = frontmatter.imageAltTwitter || descriptionTwitter;\n  const canonicalUrl = frontmatter.canonicalURL;\n  const flagHidden = frontmatter.flagHidden || false;\n  const mainTag = frontmatter.mainTag || \"Posts\";\n  const section = frontmatter.slug.split('/')[1] || \"posts\";\n  const type = \"article\";\n  const {siteUrl} = useSiteMetadata();\n  const breadcrumbJSON = {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"BreadcrumbList\",\n    \"itemListElement\": [{\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Home\",\n      \"item\": siteUrl\n    }, {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": mainTag,\n      \"item\": `${siteUrl}/${frontmatter.slug.split('/')[1]}`\n    }, {\n      \"@type\": \"ListItem\",\n      \"position\": 3,\n      \"name\": title,\n      \"item\": `${siteUrl}${frontmatter.slug}`\n    }]\n  };\n  return React.createElement(SEO, {\n    title: title + \" - avrtt.blog\",\n    titleOG: titleOG,\n    titleTwitter: titleTwitter,\n    description: description,\n    descriptionOG: descriptionOG,\n    descriptionTwitter: descriptionTwitter,\n    schemaType: schemaType,\n    keywords: keywords,\n    datePublished: datePublished,\n    dateModified: dateModified,\n    imageOG: imageOG,\n    imageAltOG: imageAltOG,\n    imageTwitter: imageTwitter,\n    imageAltTwitter: imageAltTwitter,\n    canonicalUrl: canonicalUrl,\n    flagHidden: flagHidden,\n    mainTag: mainTag,\n    section: section,\n    type: type\n  }, React.createElement(\"script\", {\n    type: \"application/ld+json\"\n  }, JSON.stringify(breadcrumbJSON)));\n}\nexport const query = graphql`\n  query($id: String!, $postsFilterRegex: String!, $imagePathRegex: String!) {\n    mdx(id: { eq: $id }) {\n      frontmatter {\n        index\n        indexCourse\n        title\n        titleSEO\n        titleOG\n        titleTwitter\n        courseCategoryName\n        desc\n        descSEO\n        descOG\n        descTwitter\n        date\n        updated\n        extraReadTimeMin\n        difficultyLevel\n        flagDraft\n        flagMindfuckery\n        flagRewrite\n        flagOffensive\n        flagProfane\n        flagMultilingual\n        flagUnreliably\n        flagPolitical\n        flagCognitohazard\n        flagHidden\n        flagWideLayoutByDefault\n        schemaType\n        mainTag\n        otherTags\n        keywordsSEO\n        banner {\n          childImageSharp {\n            gatsbyImageData(\n\t\t\t\t\t\t\tformats: [JPG, WEBP], \n\t\t\t\t\t\t\tplaceholder: BLURRED, \n\t\t\t\t\t\t\tquality: 100\n\t\t\t\t\t\t)\n          }\n        }\n        imageOG\n        imageAltOG\n        imageTwitter\n        imageAltTwitter\n        canonicalURL\n        slug\n      }\n      body\n      tableOfContents(maxDepth: 3)\n    }\n    allMdx(filter: {frontmatter: {slug: {regex: $postsFilterRegex}}}) {\n      nodes {\n        frontmatter {\n          index\n          slug\n          banner {\n            childImageSharp {\n              gatsbyImageData(\n                formats: [JPG, WEBP],\n                placeholder: BLURRED,\n                quality: 100\n              )\n            }\n          }\n        }\n      }\n    }\n    allPostImages: allFile(\n      filter: { \n        sourceInstanceName: { eq: \"images\" },\n        relativePath: { regex: $imagePathRegex }\n      }\n    ) {\n      nodes {\n        relativePath\n        childImageSharp {\n          gatsbyImageData(\n            layout: CONSTRAINED\n            placeholder: DOMINANT_COLOR\n            quality: 100\n          )\n        }\n      }\n    }\n  }\n`;\n","import React from \"react\";\nimport Latex from 'react-latex-next';\nimport 'katex/dist/katex.min.css'; \n  \nconst L = ({ text }) => {\n  return (\n    <Latex>{text}</Latex>\n  );\n};\nexport default L;\n"],"names":["_createMdxContent","props","_components","Object","assign","p","ol","li","br","h2","a","span","h3","ul","strong","_provideComponents","components","Image","id","component","Error","_missingMdxReference","React","style","position","href","className","dangerouslySetInnerHTML","__html","Latex","text","Code","Highlight","alt","path","caption","zoom","wrapper","MDXLayout","TableOfContents","_ref","toc","items","stylesTableOfContents","map","item","index","key","url","onClick","e","handleClick","preventDefault","targetId","replace","targetElement","document","getElementById","scrollIntoView","behavior","block","title","PostTemplate","_ref2","data","mdx","allMdx","allPostImages","children","frontmatter","body","tableOfContents","section","slug","split","sortedPosts","nodes","filter","post","includes","sort","b","currentIndex","findIndex","nextPost","lastPost","trimmedSlug","keyCurrent","exec","basePath","isWideLayout","setIsWideLayout","useState","flagWideLayoutByDefault","isAnimating","setIsAnimating","wordsPerMinute","useEffect","timer","setTimeout","clearTimeout","wordsPerMinuteAdventures","wordsPerMinuteResearch","wordsPerMinuteThoughts","wordCount","RemoveMarkdown","trim","length","readTime","minutes","hours","Math","floor","remainder","formatReadTime","ceil","extraReadTimeMin","notices","flag","flagDraft","flagMindfuckery","flagRewrite","flagOffensive","flagProfane","flagMultilingual","flagUnreliably","flagPolitical","flagCognitohazard","flagHidden","loadedNotices","setLoadedNotices","forEach","_ref3","then","module","prev","concat","_toConsumableArray","default","motion","div","initial","opacity","animate","exit","transition","duration","PostBanner","postNumber","date","updated","difficulty","difficultyLevel","desc","banner","postKey","isMindfuckery","mainTag","display","justifyContent","flexWrap","maxWidth","marginLeft","paddingRight","marginTop","marginBottom","otherTags","tag","stylesTagBadges","margin","class","textAlign","button","stylesCustomPostLayouts","toggleLayout","whileTap","scale","stylesButtonsCommon","ease","NoticeComponent","indexCourse","PartOfCourseNotice","category","courseCategoryName","ImageContext","Provider","value","images","MDXProvider","PostBottom","GatsbyMDXWrapper","GATSBY_COMPILED_MDX","Head","_ref4","_frontmatter$banner","_frontmatter$banner$c","_frontmatter$banner$c2","_frontmatter$banner$c3","_frontmatter$banner$c4","titleSEO","titleOG","titleTwitter","description","descSEO","descriptionOG","descOG","descriptionTwitter","descTwitter","schemaType","keywords","keywordsSEO","datePublished","dateModified","imageOG","childImageSharp","gatsbyImageData","fallback","src","imageAltOG","imageTwitter","imageAltTwitter","canonicalUrl","canonicalURL","siteUrl","useSiteMetadata","breadcrumbJSON","SEO","type","JSON","stringify"],"sourceRoot":""}