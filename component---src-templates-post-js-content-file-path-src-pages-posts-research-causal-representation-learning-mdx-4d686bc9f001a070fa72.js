"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[8474],{3962:function(e,t){t.A="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iaXNvLTg4NTktMSI/Pgo8IS0tIEdlbmVyYXRvcjogQWRvYmUgSWxsdXN0cmF0b3IgMTYuMC4wLCBTVkcgRXhwb3J0IFBsdWctSW4gLiBTVkcgVmVyc2lvbjogNi4wMCBCdWlsZCAwKSAgLS0+CjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+CjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iQ2FwYV8xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB4PSIwcHgiIHk9IjBweCIKCSB3aWR0aD0iNDE2Ljk3OXB4IiBoZWlnaHQ9IjQxNi45NzlweCIgdmlld0JveD0iMCAwIDQxNi45NzkgNDE2Ljk3OSIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNDE2Ljk3OSA0MTYuOTc5OyIKCSB4bWw6c3BhY2U9InByZXNlcnZlIj4KPGc+Cgk8cGF0aCBkPSJNMzU2LjAwNCw2MS4xNTZjLTgxLjM3LTgxLjQ3LTIxMy4zNzctODEuNTUxLTI5NC44NDgtMC4xODJjLTgxLjQ3LDgxLjM3MS04MS41NTIsMjEzLjM3OS0wLjE4MSwyOTQuODUKCQljODEuMzY5LDgxLjQ3LDIxMy4zNzgsODEuNTUxLDI5NC44NDksMC4xODFDNDM3LjI5MywyNzQuNjM2LDQzNy4zNzUsMTQyLjYyNiwzNTYuMDA0LDYxLjE1NnogTTIzNy42LDM0MC43ODYKCQljMCwzLjIxNy0yLjYwNyw1LjgyMi01LjgyMiw1LjgyMmgtNDYuNTc2Yy0zLjIxNSwwLTUuODIyLTIuNjA1LTUuODIyLTUuODIyVjE2Ny44ODVjMC0zLjIxNywyLjYwNy01LjgyMiw1LjgyMi01LjgyMmg0Ni41NzYKCQljMy4yMTUsMCw1LjgyMiwyLjYwNCw1LjgyMiw1LjgyMlYzNDAuNzg2eiBNMjA4LjQ5LDEzNy45MDFjLTE4LjYxOCwwLTMzLjc2Ni0xNS4xNDYtMzMuNzY2LTMzLjc2NQoJCWMwLTE4LjYxNywxNS4xNDctMzMuNzY2LDMzLjc2Ni0zMy43NjZjMTguNjE5LDAsMzMuNzY2LDE1LjE0OCwzMy43NjYsMzMuNzY2QzI0Mi4yNTYsMTIyLjc1NSwyMjcuMTA3LDEzNy45MDEsMjA4LjQ5LDEzNy45MDF6Ii8+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPGc+CjwvZz4KPC9zdmc+Cg=="},66501:function(e,t,n){n.d(t,{A:function(){return o}});var a=n(96540),i=n(3962),r="styles-module--tooltiptext--a263b";var o=e=>{let{text:t,isBadge:n=!1}=e;const{0:o,1:l}=(0,a.useState)(!1),s=(0,a.useRef)(null);return(0,a.useEffect)((()=>{function e(e){s.current&&!s.current.contains(e.target)&&l(!1)}return document.addEventListener("click",e),()=>{document.removeEventListener("click",e)}}),[]),a.createElement("span",{className:"styles-module--tooltipWrapper--75ebf",ref:s},a.createElement("img",{id:n?"styles-module--infoBadge--e3d66":"styles-module--info--26c1f",src:i.A,alt:"info",onClick:e=>{e.stopPropagation(),l((e=>!e))}}),a.createElement("span",{className:o?`${r} styles-module--visible--c063c`:r},t))}},96098:function(e,t,n){var a=n(96540),i=n(7978);t.A=e=>{let{text:t}=e;return a.createElement(i.A,null,t)}},99521:function(e,t,n){n.r(t),n.d(t,{Head:function(){return _},PostTemplate:function(){return T},default:function(){return k}});var a=n(54506),i=n(28453),r=n(96540),o=n(16886),l=(n(46295),n(96098)),s=n(66501);function c(e){const t=Object.assign({p:"p",h3:"h3",a:"a",span:"span",br:"br",h2:"h2",ol:"ol",li:"li",strong:"strong",h4:"h4"},(0,i.RP)(),e.components),{Image:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),r.createElement(r.Fragment,null,"\n",r.createElement("br"),"\n","\n","\n",r.createElement(t.p,null,"Causal representation learning, often abbreviated as ",r.createElement(o.A,null,"CRL"),", stands as a rapidly advancing branch of machine learning research that aims to identify, disentangle, and utilize latent causal variables from observed data. Unlike conventional statistical learning approaches that concentrate almost exclusively on correlations and large-scale pattern finding, CRL emphasizes the intricate relationships that encode how and why specific factors interact to shape observed outcomes. My purpose in this extensive article is to walk you through the important concepts, theoretical underpinnings, practical frameworks, relevant literature, and outstanding future directions in CRL. By the time you complete reading, I hope you will have a profound understanding of how causal representations make machine learning models more transparent, robust to out-of-domain shifts, and better able to handle interventions, planning, and decision-making in dynamic environments."),"\n",r.createElement(t.p,null,"It should be acknowledged that causal representation learning has been influenced by, and indeed builds upon, a variety of intellectual contributions spanning decades of research in statistics, artificial intelligence, philosophy of science, and computer vision. These influences include, but are not limited to: Pearl's structural causal models (Pearl, 2009), Rubin's potential outcomes framework, Spirtes–Glymour–Scheines's approaches to causal discovery, and more recent works in disentangled representation learning. Over time, the synergy between representation learning and causality has produced methods—like CITRIS (Lippe and gang, 2022a)—that explicitly leverage constraints arising from interventions, domain shifts, and temporal dependencies to recover meaningful latent factors."),"\n",r.createElement(t.h3,{id:"11-motivation-and-scope-of-causal-representation-learning-crl",style:{position:"relative"}},r.createElement(t.a,{href:"#11-motivation-and-scope-of-causal-representation-learning-crl","aria-label":"11 motivation and scope of causal representation learning crl permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"1.1 Motivation and scope of causal representation learning (CRL)"),"\n",r.createElement(t.p,null,"One of the major drivers behind CRL is the recognition that machine learning models too often rely on superficial patterns in data. While these correlations might suffice for i.i.d. ",r.createElement(s.A,{text:"independent and identically distributed"})," tasks within relatively static environments, they can fall short when presented with a shift in domain conditions or when asked to reason about interventions. For instance, if you have a computer vision model that classifies objects under standard lighting conditions, the model might fail when the illumination changes dramatically. The reason is often that the model latched onto statistical regularities that do not correspond to fundamental causal relationships in the world."),"\n",r.createElement(t.p,null,"This shortcoming has led many researchers to focus on the concept of causality, which is about more than just correlation. Causal representations provide a vantage point from which models can separate essential causal mechanisms from superficial confounders. CRL is motivated by the notion that by modeling the true underlying factors of variation, we can achieve greater robustness, interpretability, and adaptability. Once we have identified these causal factors, we can intervene on them—potentially in a controlled manner—and predict how the system will behave under those interventions."),"\n",r.createElement(t.p,null,"The scope of CRL, then, is incredibly broad. It strives to be applicable to a wide range of tasks: from image recognition and time-series forecasting to sequential decision-making in reinforcement learning. CRL is not merely an abstract theoretical exercise; it brings profound implications for real-world settings where we want stable, generalizable, and interpretable models across varied conditions."),"\n",r.createElement(t.h3,{id:"12-authors-and-context-angelos-nalmpantis-danilo-de-goede",style:{position:"relative"}},r.createElement(t.a,{href:"#12-authors-and-context-angelos-nalmpantis-danilo-de-goede","aria-label":"12 authors and context angelos nalmpantis danilo de goede permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"1.2 Authors and context (Angelos Nalmpantis, Danilo de Goede)"),"\n",r.createElement(t.p,null,"Before diving more deeply into the formalisms and frameworks of CRL, it is worth noting that much of the work on CITRIS and the TRIS (TempoRal Intervened Sequences) setting has been spearheaded by researchers such as Angelos Nalmpantis and Danilo de Goede, in close corroboration with other leading groups studying causality and representation learning. The impetus for their research emerges from an intersection of time-series data analysis, Bayesian networks, and advanced deep learning, with a particular interest in how minimal causal variables can be identified and leveraged for tasks requiring interventions over time."),"\n",r.createElement(t.p,null,"Specifically, Nalmpantis and de Goede, alongside various collaborators, have also explored how the interplay of representation learning and causal reasoning can lead to new insights in robotics, healthcare, and even economic forecasting. Their focus on the synergy between interventions and temporal dependencies is a critical piece of the broader puzzle: Many real-world domains—like autonomous driving or industrial control systems—are dynamic, with sequential dependencies that cannot be neglected. It is in precisely these environments that CRL can demonstrate its full strength by generating representations that not only reflect what is happening now, but also how that might change if certain variables are intervened upon."),"\n",r.createElement(t.h3,{id:"13-overview-of-the-tutorial-notebooks-and-pre-trained-models",style:{position:"relative"}},r.createElement(t.a,{href:"#13-overview-of-the-tutorial-notebooks-and-pre-trained-models","aria-label":"13 overview of the tutorial notebooks and pre trained models permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"1.3 Overview of the tutorial notebooks and pre-trained models"),"\n",r.createElement(t.p,null,"To facilitate hands-on learning, there exist a variety of resources, including open-source GitHub repositories, Colab notebooks, and specialized workflows, that showcase how to implement and test CRL methods in practice. These tutorials often provide:"),"\n",r.createElement(t.p,null,"• ",r.createElement(o.A,null,"Pre-trained models")," that have already been optimized on certain tasks, saving researchers from the initial overhead of lengthy training.",r.createElement(t.br),"\n","• Jupyter/Colab notebooks illustrating the decomposition of data into causal factors, how interventions are encoded, and how to visualize results.",r.createElement(t.br),"\n","• Guidelines on hyperparameter tuning, best practices for handling large datasets, and stable training heuristics."),"\n",r.createElement(t.p,null,"Many references point to a well-documented pipeline (for instance, Lipschitz-limited architectures for CITRIS or normalizing flow-based expansions for iCITRIS). Even if you are new to the codebase, these tutorials are structured so you can gradually build your understanding of the entire system: from ingestion of observational data to the final step of performing manipulated predictions."),"\n",r.createElement(t.p,null,"I recommend leveraging these resources as you progress through the rest of this article, because they will allow you to anchor the theoretical concepts presented here in practical code examples. By working through the notebooks, you can see exactly how CITRIS handles interventions in a temporal sequence, how the model's latent space representation emerges, and how to interpret the metrics that quantify disentanglement or causal identifiability."),"\n",r.createElement(t.h2,{id:"2-foundations-of-causal-representation-learning",style:{position:"relative"}},r.createElement(t.a,{href:"#2-foundations-of-causal-representation-learning","aria-label":"2 foundations of causal representation learning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2. Foundations of causal representation learning"),"\n",r.createElement(t.p,null,'Long before the era of large neural networks, causality researchers grappled with the question: "What does it mean to identify a cause-and-effect structure from data?". Early milestones in this field included the so-called "do-calculus" introduced by Judea Pearl, which provides a formal language for expressing interventions, and structural equation models that define explicit functional relationships among variables. However, as deep learning ascended to the forefront of machine learning, the combination of high-capacity representational power and rigorous causal inference frameworks became a natural focal point. Enter causal representation learning, which merges these two previously disparate paradigms.'),"\n",r.createElement(t.h3,{id:"21-definition-and-importance-of-crl",style:{position:"relative"}},r.createElement(t.a,{href:"#21-definition-and-importance-of-crl","aria-label":"21 definition and importance of crl permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.1 Definition and importance of CRL"),"\n",r.createElement(t.p,null,r.createElement(o.A,null,"Causal representation learning (CRL)")," can be loosely defined as a subdiscipline that aims to discover or leverage latent causal factors in high-dimensional data, typically with the goal of enabling robust predictions, interventions, and interpretations. It transcends the purely correlation-based viewpoint to specifically target the variables that carry causal significance. In a typical scenario, you might have an observed dataset of images (each containing objects in different positions, colors, or under different lighting conditions) and you suspect that behind these images lie a handful of generative factors (shape, position, color, lighting) that combine to create the final observed outcome. CRL tries to invert this generative process by learning a representation that recovers precisely those factors."),"\n",r.createElement(t.p,null,"The importance of CRL stems from the tangible benefits it brings to real-world scenarios:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Out-of-domain generalization"),": If a model has learned a purely correlational relationship that only holds for the training distribution, any domain shift could cause performance degradation. Conversely, a model that recovers the underlying causal variables is better positioned to generalize because those variables remain invariant across domains, or at least they provide well-defined transformations for how the domain shift might affect the data."),"\n"),"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Interventions and counterfactuals"),": CRL also matters for scenarios in which you want to predict how the world would change if you took a specific action. For example, if you intervene on the hue of an object, how does that affect classification? A causal representation is precisely the tool you need to perform such manipulations reliably in your latent space without breaking the internal consistency of the generative factors."),"\n"),"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Interpretability and transparency"),": In many regulated industries—such as healthcare or finance—understanding why a model made a particular prediction is essential. Causal variables often come with real-world semantics, making the model's decision process far more interpretable than black-box correlation-based methods."),"\n"),"\n"),"\n",r.createElement(t.h3,{id:"22-statistical-learning-vs-causal-learning",style:{position:"relative"}},r.createElement(t.a,{href:"#22-statistical-learning-vs-causal-learning","aria-label":"22 statistical learning vs causal learning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.2 Statistical learning vs. causal learning"),"\n",r.createElement(t.p,null,"Statistical learning primarily focuses on patterns of association. If you see a large dataset of input–output pairs, you craft a function that tries to minimize some form of predictive error. Causal learning, however, requires that you understand which variables are drives of change versus those that are simply changing in tandem. Indeed, you can have two variables that are strongly correlated but have no causal relationship, perhaps due to a shared hidden parent or confounding factor. Identifying the correct directionality or incapacitating the confounding effect is precisely where causal inference steps in."),"\n",r.createElement(t.p,null,"In the classical sense, suppose you have a dataset of variables ",r.createElement(l.A,{text:"\\(X, Y, Z\\)"}),"; a purely statistical approach might find correlations like ",r.createElement(l.A,{text:"\\(X \\leftrightarrow Y\\)"})," is strong. But causal learning attempts to ascertain if ",r.createElement(l.A,{text:"\\(X\\)"})," causes ",r.createElement(l.A,{text:"\\(Y\\)"})," or ",r.createElement(l.A,{text:"\\(Y\\)"})," causes ",r.createElement(l.A,{text:"\\(X\\)"})," or whether a confounder ",r.createElement(l.A,{text:"\\(Z\\)"})," is the real cause of both. The difference is crucial: if you are trying to design an intervention, you need to know which variables to push to obtain a desired effect."),"\n",r.createElement(t.p,null,"From a representation learning standpoint, bridging statistical and causal learning means designing flexible neural architectures that can untangle underlying generative processes, while also systematically enforcing constraints that lead to identifiable causal structures. This can be accomplished through domain knowledge, controlled interventions, or temporal consistency, among other approaches."),"\n",r.createElement(t.h3,{id:"23-key-challenges-out-of-domain-generalization-and-planning",style:{position:"relative"}},r.createElement(t.a,{href:"#23-key-challenges-out-of-domain-generalization-and-planning","aria-label":"23 key challenges out of domain generalization and planning permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"2.3 Key challenges: out-of-domain generalization and planning"),"\n",r.createElement(t.p,null,"Despite the attractiveness of CRL, major challenges exist in bridging theory and practice:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Out-of-domain generalization"),": A central ambition of CRL is to ensure that the learned representation remains valid under distribution shifts—where either the distribution of inputs changes or new causal variables appear in the environment. This is significantly more challenging than the typical i.i.d. assumption, which is standard in short-sighted machine learning paradigms."),"\n"),"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Planning"),": When latency or real-time decision needs are introduced—such as in robotic control tasks or dynamic scheduling systems—having the ability to plan forward, test hypothetical scenarios, and choose interventions that yield beneficial outcomes becomes paramount. CRL frameworks must be integrated with sequential decision-making architectures so that the model can, in effect, simulate different interventions in latent space and choose the best path."),"\n"),"\n"),"\n",r.createElement(t.p,null,"From a pipeline perspective, these two challenges demand specialized solutions: robust architectures, novel training regimes, and a synergy between knowledge-driven constraints and data-driven inference. In subsequent chapters, you'll see how the TRIS setting, CITRIS, and other frameworks attempt to address these points."),"\n",r.createElement(t.h2,{id:"3-the-temporal-intervened-sequences-tris-setting",style:{position:"relative"}},r.createElement(t.a,{href:"#3-the-temporal-intervened-sequences-tris-setting","aria-label":"3 the temporal intervened sequences tris setting permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3. The tempoRal intervened sequences (TRIS) setting"),"\n",r.createElement(t.p,null,"Moving from fundamentals to a specialized scenario, we encounter the TRIS setting, short for ",r.createElement(o.A,null,"TempoRal Intervened Sequences"),". This approach focuses on sequences of data—like videos or time-series logs—where one can apply interventions at specific time steps, thereby influencing future observations. In the real world, many phenomena unfold over time, so the ability to incorporate a temporal dimension into causal inference is crucial. The TRIS perspective ensures that changes induced by interventions are tracked as they propagate from one time step to the next."),"\n",r.createElement(t.h3,{id:"31-defining-tris-temporal-bayesian-networks-and-interventions",style:{position:"relative"}},r.createElement(t.a,{href:"#31-defining-tris-temporal-bayesian-networks-and-interventions","aria-label":"31 defining tris temporal bayesian networks and interventions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.1 Defining TRIS: temporal Bayesian networks and interventions"),"\n",r.createElement(t.p,null,"Arguably, the simplest conceptual mechanism for capturing temporal structure is a temporal Bayesian network. In the TRIS context, you have a set of latent causal variables ",r.createElement(l.A,{text:"\\(z_t\\)"})," that evolve over time, and each ",r.createElement(l.A,{text:"\\(z_t\\)"})," can be intervened upon to yield a new configuration at ",r.createElement(l.A,{text:"\\(z_{t+1}\\)"})," or subsequent time steps. Formally, you can think of the generative process as:"),"\n",r.createElement(l.A,{text:"\\[\nz_{t+1} = f_{\\theta}(z_t, a_t, \\epsilon_t)\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(z_t\\)"})," denotes the state of the latent causal variables at time ",r.createElement(l.A,{text:"\\(t\\)"}),", ",r.createElement(l.A,{text:"\\(a_t\\)"})," is the applied intervention (or action), ",r.createElement(l.A,{text:"\\(\\epsilon_t\\)"})," is noise or exogenous variation, and ",r.createElement(l.A,{text:"\\(f_{\\theta}\\)"})," is a parametric function capturing the transition dynamics. Observed data ",r.createElement(l.A,{text:"\\(x_t\\)"})," is then generated from ",r.createElement(l.A,{text:"\\(z_t\\)"})," through some emission function ",r.createElement(l.A,{text:"\\(g_{\\phi}\\)"}),". Thus:"),"\n",r.createElement(l.A,{text:"\\[\nx_t = g_{\\phi}(z_t) \n\\]"}),"\n",r.createElement(t.p,null,"The intervention ",r.createElement(l.A,{text:"\\(a_t\\)"})," effectively modifies the generative trajectory, letting you see how the system changes as a result. In standard supervised or unsupervised learning, you seldom have the capacity to systematically manipulate variables. TRIS, in contrast, sets up the scenario explicitly: you get data that show how the system evolves with and without interventions, giving the model strong cues about the causal structure."),"\n",r.createElement(t.h3,{id:"32-causal-variables-intervention-targets-and-observational-data",style:{position:"relative"}},r.createElement(t.a,{href:"#32-causal-variables-intervention-targets-and-observational-data","aria-label":"32 causal variables intervention targets and observational data permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.2 Causal variables, intervention targets, and observational data"),"\n",r.createElement(t.p,null,"An essential concept in TRIS is ",r.createElement(o.A,null,"causal variables"),". These are the distinct factors in the latent space that genuinely drive changes in the observed data. Intervention targets specify which causal variables are manipulated and how. Finally, observational data in this setting is the set of recorded sequences under various interventions. For instance:"),"\n",r.createElement(t.p,null,"• You might have a robot pushing objects in different directions. Each push is an intervention on position or velocity.",r.createElement(t.br),"\n","• You might have an environment where you systematically alter lighting conditions (an intervention on a lighting factor) and observe the impact on object appearance."),"\n",r.createElement(t.p,null,"Crucially, the observational data alone (with no known interventions) is insufficient to unravel the complete causal structure. Only by pairing observational sequences with intervened data can the model separate correlation from genuine causation. This synergy between the observational dimension—what naturally happens over time—and the intervened dimension—how the system changes when you intentionally manipulate it—underpins the TRIS approach."),"\n",r.createElement(t.h3,{id:"33-multidimensional-causal-variables-and-minimal-causal-variables",style:{position:"relative"}},r.createElement(t.a,{href:"#33-multidimensional-causal-variables-and-minimal-causal-variables","aria-label":"33 multidimensional causal variables and minimal causal variables permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.3 Multidimensional causal variables and minimal causal variables"),"\n",r.createElement(t.p,null,"In many real-world scenarios, each ",r.createElement(l.A,{text:"\\(z_t\\)"})," is not a single scalar variable but a collection of factors—like ",r.createElement(l.A,{text:"\\(z_t^1, z_t^2, \\ldots, z_t^k\\)"}),"—each controlling a different aspect of the observed phenomenon. For instance in a 3D scene: ",r.createElement(l.A,{text:"\\(z_t^1\\)"})," might govern the horizontal position of an object, ",r.createElement(l.A,{text:"\\(z_t^2\\)"})," might govern its color, ",r.createElement(l.A,{text:"\\(z_t^3\\)"})," might control the background hue, and so on. Each dimension can be intervened upon, either individually or collectively."),"\n",r.createElement(t.p,null,"A topic of intense inquiry is identifying ",r.createElement(o.A,null,"minimal causal variables"),"—the smallest set of variables that suffice to describe the system's causal dynamics. This is concerned with parsimony: we prefer a minimal set of factors, as that fosters better interpretability and reduces superfluous modeling overhead. Moreover, minimality is often tied to better identifiability properties. If the model lumps multiple distinct factors into a single dimension, it can obscure which interventions specifically affected the observed changes."),"\n",r.createElement(t.h3,{id:"34-connection-to-the-broader-crl-field",style:{position:"relative"}},r.createElement(t.a,{href:"#34-connection-to-the-broader-crl-field","aria-label":"34 connection to the broader crl field permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"3.4 Connection to the broader CRL field"),"\n",r.createElement(t.p,null,"TRIS is not an isolated phenomenon, but rather one instance of a broader push within CRL to incorporate real-world complexities like time, interactions, and direct manipulations. Indeed, one might see parallels with frameworks such as structural recurrent neural networks, partially observable Markov decision processes, or other sequential generative models. What sets TRIS apart is the explicit notion that we do not just passively track data over time; we actively intervene and measure the consequences. This is why TRIS is such an attractive setting for methodologists seeking to push the boundaries of causal representation discovery."),"\n",r.createElement(t.h2,{id:"4-introducing-citris",style:{position:"relative"}},r.createElement(t.a,{href:"#4-introducing-citris","aria-label":"4 introducing citris permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4. Introducing CITRIS"),"\n",r.createElement(t.p,null,"Now that you have a grasp on how CRL differs from statistical learning and how the TRIS setting encodes temporal interventions, we move on to a specific framework known as CITRIS (",r.createElement(s.A,{text:"Causal Identifiability from Temporal Intervened Sequences"}),"). Proposed in Lippe and gang (2022a), CITRIS takes a stance that by combining temporal consistency with strategic interventions, one can learn an invertible mapping from high-dimensional observations to stable causal factors. The name CITRIS is a direct nod to the fact that it is designed to exploit the TRIS setup in order to achieve identifiability of causal variables."),"\n",r.createElement(t.h3,{id:"41-motivation-learning-causal-variables-from-high-dimensional-data",style:{position:"relative"}},r.createElement(t.a,{href:"#41-motivation-learning-causal-variables-from-high-dimensional-data","aria-label":"41 motivation learning causal variables from high dimensional data permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.1 Motivation: learning causal variables from high-dimensional data"),"\n",r.createElement(t.p,null,"The impetus behind CITRIS is straightforward if you consider the typical challenges of modern data. Real-world data—especially images or sensor readings—are massive in dimension. A single raw image might contain thousands of pixels, each with multiple color channels. Identifying the underlying causal factors from such unstructured data can feel akin to searching for a needle in a cosmic-scale haystack. CITRIS addresses this by imposing structure on the problem:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Temporal consistency"),": Observations close in time should share consistent factors."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Interventions"),": The moments when these factors are forcibly changed reveal which dimension is truly controlling which aspect in the observed domain."),"\n",r.createElement(t.li,null,r.createElement(t.strong,null,"Invertibility"),": A structure in the latent space ensures that each dimension corresponds to a genuinely distinct causal factor."),"\n"),"\n",r.createElement(t.h3,{id:"42-citris-at-a-glance-lippe-and-gang-2022a",style:{position:"relative"}},r.createElement(t.a,{href:"#42-citris-at-a-glance-lippe-and-gang-2022a","aria-label":"42 citris at a glance lippe and gang 2022a permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.2 CITRIS at a glance (Lippe and gang, 2022a)"),"\n",r.createElement(t.p,null,"CITRIS can be conceptualized as a family of generative or inference-based models that incorporate both a forward mapping from latent factors to observations and a backward (i.e., encoder) mapping from observations to latent factors. The forward pass can be described as:"),"\n",r.createElement(l.A,{text:"\\[\nx_t = G(z_t; \\theta)\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(z_t\\)"})," is the vector of latent causal variables at time ",r.createElement(l.A,{text:"\\(t\\)"})," and ",r.createElement(l.A,{text:"\\(\\theta\\)"})," are the parameters. The backward pass involves an encoder:"),"\n",r.createElement(l.A,{text:"\\[\nq_{\\phi}(z_t \\mid x_t)\n\\]"}),"\n",r.createElement(t.p,null,"that attempts to invert ",r.createElement(l.A,{text:"\\(G\\)"})," and uncover the latent interacting components from the high-dimensional data. CITRIS extends these building blocks by layering in a transition prior that captures how ",r.createElement(l.A,{text:"\\(z_t\\)"})," evolves under interventions, as well as constraints that enforce partial or full invertibility. Additionally:"),"\n",r.createElement(t.p,null,"• The approach exploits ",r.createElement(o.A,null,"minimal causal variables")," to ensure a principled factorization.",r.createElement(t.br),"\n","• A ",r.createElement(o.A,null,"target classifier")," might be tacked on to help ensure that the assigned factors are indeed relevant to the interventions or targets of interest."),"\n",r.createElement(t.h3,{id:"43-citris-vs-earlier-causal-representation-learning-methods",style:{position:"relative"}},r.createElement(t.a,{href:"#43-citris-vs-earlier-causal-representation-learning-methods","aria-label":"43 citris vs earlier causal representation learning methods permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.3 CITRIS vs. earlier causal representation learning methods"),"\n",r.createElement(t.p,null,"Prior CRL methods—like the CausalVAE or other approaches that rely on factor disentanglement—often focus predominantly on observational data or assume that certain strong supervision signals are available. While those methods show promise, they sometimes fail to disentangle or identify the truly causal factors if the data do not exhibit enough variability or if the model does not have any direct means of seeing how the environment changes under interventions."),"\n",r.createElement(t.p,null,"CITRIS, by contrast, leverages the TRIS strategy to provide strong supervision in the form of interventions. This leads to the significantly improved identifiability that was previously elusive. In essence, CITRIS stands on the shoulders of earlier works in the sense that it uses data-driven autoencoders or generative frameworks, but it augments them with explicit mechanisms to incorporate knowledge gleaned from manipulated transitions in time."),"\n",r.createElement(t.h3,{id:"44-icitris-brief-note-on-lippe-and-gang-2022b",style:{position:"relative"}},r.createElement(t.a,{href:"#44-icitris-brief-note-on-lippe-and-gang-2022b","aria-label":"44 icitris brief note on lippe and gang 2022b permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"4.4 iCITRIS (brief note on Lippe and gang, 2022b)"),"\n",r.createElement(t.p,null,"Shortly after CITRIS was introduced, Lippe and gang (2022b) proposed an incremental extension named ",r.createElement(o.A,null,"iCITRIS"),", where additional attention was paid to scaling the model up to more complex scenarios and refining the invertibility constraints even further. iCITRIS also dives deeper into the potential for more flexible normalizing flow-based transformations. In practice, iCITRIS can be seen as a continuing push to handle broader classes of interventions and data modalities, including multi-object scenes, videos with complex lighting, and partial or uncertain knowledge about which interventions were performed at each time step."),"\n",r.createElement(t.h2,{id:"5-citris-framework-in-detail",style:{position:"relative"}},r.createElement(t.a,{href:"#5-citris-framework-in-detail","aria-label":"5 citris framework in detail permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5. CITRIS framework in detail"),"\n",r.createElement(t.p,null,"After introducing CITRIS conceptually, let us now go under the hood to see what truly makes this framework tick. A hallmark of CITRIS is that it incorporates guarantees for identifying minimal causal variables, uses invertibility to ensure a one-to-one mapping between latent factors and generative processes, and trains using an interplay between temporal consistency constraints and explicit intervention-based constraints."),"\n",r.createElement(t.h3,{id:"51-minimal-causal-variables-and-invertible-mappings",style:{position:"relative"}},r.createElement(t.a,{href:"#51-minimal-causal-variables-and-invertible-mappings","aria-label":"51 minimal causal variables and invertible mappings permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.1 Minimal causal variables and invertible mappings"),"\n",r.createElement(t.p,null,"At the core of CITRIS, one finds the principle that each dimension in the latent space should correspond to precisely one causal variable, and that each causal variable shows up in the learned representation unequivocally. In simpler terms, CITRIS tries to avoid the phenomenon in which two separate latent dimensions are partially responsible for controlling the same factor. Achieving this property requires you to give up certain degrees of freedom in the representation—specifically, you impose invertibility constraints so that each dimension in the latent space can be inverted to yield a unique factor."),"\n",r.createElement(t.p,null,"A common technique for achieving invertibility (a one-to-one mapping between latent space and data space) is to use a ",r.createElement(o.A,null,"normalizing flow")," or various bijective transformations in the generative model. Another approach is to carefully design the neural networks so that they remain invertible by construction, an approach sometimes observed in RealNVP or other flow-based frameworks. By ensuring invertibility, we drastically reduce the risk of an arbitrary collapse of multiple latent factors into a single dimension."),"\n",r.createElement(t.h3,{id:"52-learning-approach-combining-temporal-consistency-with-interventions",style:{position:"relative"}},r.createElement(t.a,{href:"#52-learning-approach-combining-temporal-consistency-with-interventions","aria-label":"52 learning approach combining temporal consistency with interventions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.2 Learning approach: combining temporal consistency with interventions"),"\n",r.createElement(t.p,null,"The CITRIS training regime typically has two main objectives:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Temporal consistency"),": Observations ",r.createElement(l.A,{text:"\\(x_t\\)"})," and ",r.createElement(l.A,{text:"\\(x_{t+1}\\)"})," that are close in time share many of the same latent factors, unless an intervention ",r.createElement(l.A,{text:"\\(a_t\\)"})," modifies them. This is enforced by a prior or cost function that rewards the model for mapping successive frames to similar latent representations."),"\n"),"\n",r.createElement(t.li,null,"\n",r.createElement(t.p,null,r.createElement(t.strong,null,"Intervention-based constraints"),": CITRIS explicitly encodes knowledge about where and how an intervention took place. If an intervention modifies only factor ",r.createElement(l.A,{text:"\\(z_t^k\\)"}),", then the model is penalized if other factors ",r.createElement(l.A,{text:"\\(z_t^j\\)"})," (",r.createElement(l.A,{text:"\\(j \\neq k\\)"}),") also move in latent space. This constraint effectively teaches the model that each dimension is only sensitive to specific interventions."),"\n"),"\n"),"\n",r.createElement(t.p,null,"Conceptually, this can be expressed via a custom loss function. We might define:"),"\n",r.createElement(l.A,{text:"\\[\n\\mathcal{L}( \\phi, \\theta ) = \\mathcal{L}_{\\mathrm{rec}}( x, z ) + \\lambda_{\\mathrm{temp}} \\mathcal{L}_{\\mathrm{temp}}( z_t, z_{t+1} ) + \\lambda_{\\mathrm{int}} \\mathcal{L}_{\\mathrm{int}}( z_t, a_t )\n\\]"}),"\n",r.createElement(t.p,null,"Here, ",r.createElement(l.A,{text:"\\(\\mathcal{L}_{\\mathrm{rec}}\\)"})," is a reconstruction loss that ensures the model reconstructs the observed data well, ",r.createElement(l.A,{text:"\\(\\mathcal{L}_{\\mathrm{temp}}\\)"})," enforces temporal consistency, and ",r.createElement(l.A,{text:"\\(\\mathcal{L}_{\\mathrm{int}}\\)"})," penalizes incorrect changes in latent factors during interventions. The hyperparameters ",r.createElement(l.A,{text:"\\(\\lambda_{\\mathrm{temp}}\\)"})," and ",r.createElement(l.A,{text:"\\(\\lambda_{\\mathrm{int}}\\)"})," control how strongly the model weighs each constraint."),"\n",r.createElement(t.h3,{id:"53-transition-prior-in-latent-space",style:{position:"relative"}},r.createElement(t.a,{href:"#53-transition-prior-in-latent-space","aria-label":"53 transition prior in latent space permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.3 Transition prior in latent space"),"\n",r.createElement(t.p,null,"One of CITRIS's distinguishing features is its usage of a transition prior. Rather than letting ",r.createElement(l.A,{text:"\\(z_t\\)"})," float freely through time, CITRIS posits a model:"),"\n",r.createElement(l.A,{text:"\\[\nz_{t+1} = h_\\psi(z_t, a_t) + \\eta_t\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(h_\\psi\\)"})," is a trainable function capturing how the latent state changes in response to the intervention ",r.createElement(l.A,{text:"\\(a_t\\)"}),". The residual noise ",r.createElement(l.A,{text:"\\(\\eta_t\\)"})," accounts for unobserved variations or measurement errors. By modeling the transition explicitly, CITRIS ensures consistent evolution of latent factors, thereby reinforcing the view that these latent factors constitute true states of the system over time."),"\n",r.createElement(t.h3,{id:"54-identifiability-guarantees-intuitive-explanation",style:{position:"relative"}},r.createElement(t.a,{href:"#54-identifiability-guarantees-intuitive-explanation","aria-label":"54 identifiability guarantees intuitive explanation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"5.4 Identifiability guarantees (intuitive explanation)"),"\n",r.createElement(t.p,null,'When a model is said to be "identifiable", it means that, given enough data and certain mild assumptions, the model will recover the "correct" underlying factors rather than an arbitrary transformation of them. In the CRL context, identifiability is paramount because you want to be certain that the factor labeled "position" in your latent space is indeed the position in the real world, and not some mixture of position and color.'),"\n",r.createElement(t.p,null,"In CITRIS, identifiability arises from the interplay of three factors: (i) invertible mappings ensure that no factor gets lost; (ii) knowledge of interventions ensures that the model has unambiguous signals about how each factor can be altered; and (iii) temporal consistency ensures that consecutive observations remain aligned except for the factor that was manipulated. Under fairly general conditions spelled out in Lippe and gang (2022a), these constraints collectively pin down a unique mapping from data to latent factors, making CITRIS one of the first frameworks with robust identifiability claims in a practical domain."),"\n",r.createElement(t.h2,{id:"6-practical-implementations",style:{position:"relative"}},r.createElement(t.a,{href:"#6-practical-implementations","aria-label":"6 practical implementations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6. Practical implementations"),"\n",r.createElement(t.p,null,"With the conceptual architecture of CITRIS in mind, the next question is: How do we implement it concretely? This section dives into real-world CITRIS frameworks that—for clarity—are grouped under titles like CITRIS-VAE and CITRIS-NF, each with slightly different design choices. Additionally, a target classifier can be integrated to further enhance the method's ability to capture meaningful causal factors."),"\n",r.createElement(t.h3,{id:"61-citris-vae",style:{position:"relative"}},r.createElement(t.a,{href:"#61-citris-vae","aria-label":"61 citris vae permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1 CITRIS-VAE"),"\n",r.createElement(t.p,null,"CITRIS-VAE draws on the ",r.createElement(o.A,null,"variational autoencoder")," (VAE) paradigm. VAEs are a mainstay in modern representation learning: they marry an encoder ",r.createElement(l.A,{text:"\\(q_\\phi(z \\mid x)\\)"})," and a decoder ",r.createElement(l.A,{text:"\\(p_\\theta(x \\mid z)\\)"})," while optimizing a variational objective known as the ELBO (Evidence Lower BOund). In CITRIS-VAE, the standard VAE structure is augmented with the CITRIS constraints around temporal transitions and interventions."),"\n",r.createElement(t.h4,{id:"611-encoder-decoder-structure",style:{position:"relative"}},r.createElement(t.a,{href:"#611-encoder-decoder-structure","aria-label":"611 encoder decoder structure permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1.1 Encoder-decoder structure"),"\n",r.createElement(t.p,null,"The ",r.createElement(o.A,null,"encoder")," translates the input ",r.createElement(l.A,{text:"\\(x_t\\)"})," into ",r.createElement(l.A,{text:"\\(z_t\\)"}),", while the ",r.createElement(o.A,null,"decoder")," attempts to reconstruct ",r.createElement(l.A,{text:"\\(x_t\\)"})," from ",r.createElement(l.A,{text:"\\(z_t\\)"}),". However, CITRIS-VAE's encoder is mindful of the fact that ",r.createElement(l.A,{text:"\\(z_t\\)"})," evolves from ",r.createElement(l.A,{text:"\\(z_{t-1}\\)"})," under the transition prior, and also that certain factors in ",r.createElement(l.A,{text:"\\(z_t\\)"})," might have been directly intervened upon. Plotting out the architecture might show multiple branches: one for forward transitions, one for bridging intervention information, and one for standard VAE analysis."),"\n",r.createElement(t.h4,{id:"612-elbo-objective-and-kl-divergence-under-the-transition-prior",style:{position:"relative"}},r.createElement(t.a,{href:"#612-elbo-objective-and-kl-divergence-under-the-transition-prior","aria-label":"612 elbo objective and kl divergence under the transition prior permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1.2 ELBO objective and KL divergence under the transition prior"),"\n",r.createElement(t.p,null,"In a classical VAE, the ELBO objective is:"),"\n",r.createElement(l.A,{text:"\\[\n\\mathcal{L}_{\\text{ELBO}}(\\phi,\\theta) = \\mathbb{E}_{q_\\phi(z \\mid x)} \\big[ \\log p_\\theta(x \\mid z) \\big] - \\beta \\, D_{\\mathrm{KL}}\\big(q_\\phi(z \\mid x) \\parallel p(z)\\big)\n\\]"}),"\n",r.createElement(t.p,null,"where ",r.createElement(l.A,{text:"\\(D_{\\mathrm{KL}}\\)"})," denotes the Kullback–Leibler divergence and ",r.createElement(l.A,{text:"\\(\\beta\\)"})," is a hyperparameter that can be used to control the emphasis on the KL term. In CITRIS-VAE, however, the prior ",r.createElement(l.A,{text:"\\(p(z)\\)"})," is replaced by a transition prior ",r.createElement(l.A,{text:"\\(p(z_{t} \\mid z_{t-1}, a_{t-1})\\)"}),". Consequently, the KL term becomes:"),"\n",r.createElement(l.A,{text:"\\[\nD_{\\mathrm{KL}}\\Big(q_\\phi(z_t \\mid x_t) \\;\\Big\\|\\; p\\big(z_t \\mid z_{t-1}, a_{t-1}\\big)\\Big).\n\\]"}),"\n",r.createElement(t.p,null,"This means the model must respect not just reconstruction fidelity at each time step, but also the correct trajectory of latent states across time according to the known or learned transitions."),"\n",r.createElement(t.h4,{id:"613-assignment-function-via-gumbel-softmax",style:{position:"relative"}},r.createElement(t.a,{href:"#613-assignment-function-via-gumbel-softmax","aria-label":"613 assignment function via gumbel softmax permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.1.3 Assignment function via Gumbel-Softmax"),"\n",r.createElement(t.p,null,"Another critical piece of CITRIS-VAE is the notion of discrete variable assignment if the interventions can only target a subset of factors or if the representation needs to partition ",r.createElement(l.A,{text:"\\(z\\)"})," into categories. A popular technique for dealing with discrete variables in neural networks—and for enabling backpropagation through sampling steps—is the ",r.createElement(o.A,null,"Gumbel-Softmax")," trick. In essence, Gumbel-Softmax reparametrizes the categorical sampling process to produce a differentiable approximation, making it possible to optimize the assignment of factors to different intervention targets in an end-to-end manner."),"\n",r.createElement(t.p,null,"Below is a small code snippet illustrating how one might incorporate a Gumbel-Softmax approach in PyTorch:"),"\n",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\nimport torch\nimport torch.nn.functional as F\n\ndef gumbel_softmax_sample(logits, temperature=1.0):\n    # Sample Gumbel noise\n    gumbel_noise = -torch.log(-torch.log(torch.rand_like(logits) + 1e-10) + 1e-10)\n    # Combine logits with Gumbel noise\n    y = logits + gumbel_noise\n    # Apply softmax with temperature\n    return F.softmax(y / temperature, dim=-1)\n\n# Example usage\nlogits = torch.randn((16, 10))  # 16 samples, 10 categories\nsamples = gumbel_softmax_sample(logits, temperature=0.5)\n`}/></code></pre></div>'}}),"\n",r.createElement(t.p,null,"In CITRIS-VAE, these discrete assignments can track which latent factor was manipulated by an intervention, or which factor belongs to which dimension if partial factorization is used."),"\n",r.createElement(t.h3,{id:"62-citris-nf",style:{position:"relative"}},r.createElement(t.a,{href:"#62-citris-nf","aria-label":"62 citris nf permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2 CITRIS-NF"),"\n",r.createElement(t.p,null,"While CITRIS-VAE leverages the convenience of variational inference, a complementary approach is ",r.createElement(o.A,null,"CITRIS-NF"),", which stands for CITRIS using normalizing flows. Normalizing flows have gained popularity thanks to their ability to produce invertible transformations with tractable exact likelihoods."),"\n",r.createElement(t.h4,{id:"621-motivation-for-normalizing-flows",style:{position:"relative"}},r.createElement(t.a,{href:"#621-motivation-for-normalizing-flows","aria-label":"621 motivation for normalizing flows permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2.1 Motivation for normalizing flows"),"\n",r.createElement(t.p,null,"In a standard VAE, the decoder function ",r.createElement(l.A,{text:"\\(p_\\theta(x \\mid z)\\)"})," might be flexible, but it is not necessarily invertible. If invertibility is a cornerstone of your CRL approach, normalizing flows are a natural fit. They ensure a one-to-one mapping that not only provides powerful density estimation capabilities, but also fosters a strong disentanglement of factors."),"\n",r.createElement(t.h4,{id:"622-autoencoder--flow-decomposition",style:{position:"relative"}},r.createElement(t.a,{href:"#622-autoencoder--flow-decomposition","aria-label":"622 autoencoder  flow decomposition permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2.2 Autoencoder + flow decomposition"),"\n",r.createElement(t.p,null,"In practice, CITRIS-NF might look like an autoencoder where, after an initial compression of ",r.createElement(l.A,{text:"\\(x\\)"})," into ",r.createElement(l.A,{text:"\\(z\\)"}),", you apply a sequence of invertible transformations ",r.createElement(l.A,{text:"\\(f_1, f_2, \\ldots, f_L\\)"}),". Each ",r.createElement(l.A,{text:"\\(f_i\\)"})," is designed such that it can be inverted analytically. A typical normalizing flow uses coupling layers, split transformations, or masked autoregressive flows that ensure invertibility with relatively low computational overhead."),"\n",r.createElement(l.A,{text:"\\[\nz_t^{(L)} = f_L \\circ f_{L-1} \\circ \\ldots \\circ f_1\\big(z_t^{(0)}\\big).\n\\]"}),"\n",r.createElement(t.p,null,"Because these transformations are fully invertible, each dimension in ",r.createElement(l.A,{text:"\\(z_t^{(L)}\\)"})," can correspond to a unique causal factor. One simply inverts the flow to map that dimension back to the original data."),"\n",r.createElement(t.h4,{id:"623-invertibility-and-disentanglement-benefits",style:{position:"relative"}},r.createElement(t.a,{href:"#623-invertibility-and-disentanglement-benefits","aria-label":"623 invertibility and disentanglement benefits permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.2.3 Invertibility and disentanglement benefits"),"\n",r.createElement(t.p,null,"The advantage of using flows within CITRIS is that you have a built-in mechanism for invertibility—no ad-hoc constraints require you to approximate inverses. Disentanglement of causal variables is consequently more direct: if you discover that dimension ",r.createElement(l.A,{text:"\\(k\\)"})," of ",r.createElement(l.A,{text:"\\(z_t^{(L)}\\)"})," is responsible for object size, you can easily intervene on that dimension, run the inverse flow, and see how the entire image changes."),"\n",r.createElement(t.h3,{id:"63-target-classifier-optional-component",style:{position:"relative"}},r.createElement(t.a,{href:"#63-target-classifier-optional-component","aria-label":"63 target classifier optional component permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.3 Target classifier (optional component)"),"\n",r.createElement(t.p,null,"An additional module sometimes included in CITRIS is a ",r.createElement(o.A,null,"target classifier"),". This classifier is trained (or co-trained) to predict which intervention was applied based on the latent representation. By maximizing the mutual information between the latent factors and the intervention targets, you inject an even stronger signal that the representation should separate out the manipulated dimension from the unaffected ones."),"\n",r.createElement(t.h4,{id:"631-purpose-and-mutual-information-with-intervention-targets",style:{position:"relative"}},r.createElement(t.a,{href:"#631-purpose-and-mutual-information-with-intervention-targets","aria-label":"631 purpose and mutual information with intervention targets permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.3.1 Purpose and mutual information with intervention targets"),"\n",r.createElement(t.p,null,"Intuitively, if interventions are labeled (e.g., you know exactly which factor was changed), the target classifier can help supervise the representation. The model learns that dimension ",r.createElement(l.A,{text:"\\(z^i\\)"})," is a strong predictor of whether a color intervention happened, while dimension ",r.createElement(l.A,{text:"\\(z^j\\)"})," might reflect a shape intervention. This synergy between CITRIS's generative or flow-based structure and a classifier is key to reinforcing factor disentanglement."),"\n",r.createElement(t.h4,{id:"632-example-configurations",style:{position:"relative"}},r.createElement(t.a,{href:"#632-example-configurations","aria-label":"632 example configurations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"6.3.2 Example configurations"),"\n",r.createElement(t.p,null,"Depending on how your dataset is set up, you might have multiple classifiers each focusing on a particular subset of interventions. Alternatively, you might combine them into a single multi-class network. Either way, the presence of these classifiers can significantly speed up convergence, reduce identifiability ambiguities, and allow for easy debugging of which latent dimension is corresponding to which real-world factor."),"\n",r.createElement(t.h2,{id:"7-experiments-and-evaluations",style:{position:"relative"}},r.createElement(t.a,{href:"#7-experiments-and-evaluations","aria-label":"7 experiments and evaluations permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7. Experiments and evaluations"),"\n",r.createElement(t.p,null,"The true litmus test of any CRL framework, especially CITRIS-based methods, lies in how effectively they disentangle and identify causal factors under controlled or semi-controlled settings. While real-world data is the ultimate domain of interest, standardized datasets—like Causal3DIdent—have been curated to test systematically whether a model can discover genuine causal variables and remain robust to interventions."),"\n",r.createElement(t.h3,{id:"71-the-causal3dident-dataset",style:{position:"relative"}},r.createElement(t.a,{href:"#71-the-causal3dident-dataset","aria-label":"71 the causal3dident dataset permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1 The Causal3DIdent dataset"),"\n",r.createElement(t.p,null,"A widely cited toy dataset for CRL experiments is ",r.createElement(o.A,null,"Causal3DIdent"),". It provides rendered 3D objects under various transformations—like changes in rotation, color, background, or lighting. The dataset is specifically structured to incorporate known interventions, making it an excellent test bed for CITRIS."),"\n",r.createElement(t.h4,{id:"711-variables-interventions-and-dataset-structure",style:{position:"relative"}},r.createElement(t.a,{href:"#711-variables-interventions-and-dataset-structure","aria-label":"711 variables interventions and dataset structure permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1.1 Variables, interventions, and dataset structure"),"\n",r.createElement(t.p,null,"In Causal3DIdent, each image is generated by sampling from a set of causal factors. For example:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,"Object shape (e.g., sphere, cube)."),"\n",r.createElement(t.li,null,"Object color (various possible hues)."),"\n",r.createElement(t.li,null,"Background hue."),"\n",r.createElement(t.li,null,"Lighting angle (spotlight rotation)."),"\n",r.createElement(t.li,null,"Object position in the 2D plane."),"\n",r.createElement(t.li,null,"Object scale (sometimes included in extended versions)."),"\n"),"\n",r.createElement(t.p,null,"Interventions might specify that only the object color was changed, or that the background color was held constant while the object was rotated. The dataset includes sequences, so one can see how applying an intervention modifies a particular factor over time."),"\n",r.createElement(t.h4,{id:"712-loading-sampling-and-visualization",style:{position:"relative"}},r.createElement(t.a,{href:"#712-loading-sampling-and-visualization","aria-label":"712 loading sampling and visualization permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.1.2 Loading, sampling, and visualization"),"\n",r.createElement(t.p,null,"The dataset is typically available in a .npy or .h5 format, where each entry is a sequence of images, possibly with meta-information about which interventions were taken at each time step. A typical CITRIS-based experiment might:"),"\n",r.createElement(t.p,null,"• Load the dataset into memory, with each entry consisting of ",r.createElement(l.A,{text:"\\((x_t, a_t)\\)"})," pairs.",r.createElement(t.br),"\n","• Feed these pairs into the CITRIS encoder to produce ",r.createElement(l.A,{text:"\\(z_t\\)"}),".",r.createElement(t.br),"\n","• Evaluate how well the model reconstructs ",r.createElement(l.A,{text:"\\(x_t\\)"})," and how precisely it identifies the factor impacted by ",r.createElement(l.A,{text:"\\(a_t\\)"}),"."),"\n",r.createElement(t.p,null,"For quick debugging, you might visualize random samples of images before and after interventions to confirm that the dataset was loaded correctly and that the model sees meaningful differences between time steps."),"\n",r.createElement(t.h3,{id:"72-triplet-evaluation",style:{position:"relative"}},r.createElement(t.a,{href:"#72-triplet-evaluation","aria-label":"72 triplet evaluation permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2 Triplet evaluation"),"\n",r.createElement(t.p,null,"One interesting method used in some CRL experiments—and specifically for CITRIS-based tasks—is a ",r.createElement(o.A,null,"triplet evaluation")," approach. The rationale is to measure whether the model can encode and recombine factors in a way that respects the real-world causal structure."),"\n",r.createElement(t.h4,{id:"721-constructing-image-triplets-and-masks",style:{position:"relative"}},r.createElement(t.a,{href:"#721-constructing-image-triplets-and-masks","aria-label":"721 constructing image triplets and masks permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2.1 Constructing image triplets and masks"),"\n",r.createElement(t.p,null,"In the triplet approach, you take three images sampled from the dataset:"),"\n",r.createElement(t.ol,null,"\n",r.createElement(t.li,null,r.createElement(l.A,{text:"\\(x_a\\)"}),": reference image"),"\n",r.createElement(t.li,null,r.createElement(l.A,{text:"\\(x_b\\)"}),": an image that differs from ",r.createElement(l.A,{text:"\\(x_a\\)"})," in exactly one factor (e.g., background color)"),"\n",r.createElement(t.li,null,r.createElement(l.A,{text:"\\(x_c\\)"}),": an image that might differ from ",r.createElement(l.A,{text:"\\(x_a\\)"})," in another factor (e.g., object shape)"),"\n"),"\n",r.createElement(t.p,null,"You then encode these images into ",r.createElement(l.A,{text:"\\(z_a, z_b, z_c\\)"})," and produce a latent mask that indicates which dimensions differ. The expectation is that if ",r.createElement(l.A,{text:"\\(x_a\\)"})," and ",r.createElement(l.A,{text:"\\(x_b\\)"})," differ in background color only, then the difference ",r.createElement(l.A,{text:"\\(z_b - z_a\\)"})," should show up in precisely the dimension that controls background color—and not in dimensions controlling shape or lighting."),"\n",r.createElement(t.h4,{id:"722-encoding-and-recombining-latent-factors",style:{position:"relative"}},r.createElement(t.a,{href:"#722-encoding-and-recombining-latent-factors","aria-label":"722 encoding and recombining latent factors permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2.2 Encoding and recombining latent factors"),"\n",r.createElement(t.p,null,"After obtaining these encodings, you can try to combine them to synthesize new images that mix factors from ",r.createElement(l.A,{text:"\\(x_a\\)"})," and ",r.createElement(l.A,{text:"\\(x_b\\)"}),". For instance, you might keep the shape from ",r.createElement(l.A,{text:"\\(x_a\\)"})," but adopt the background color from ",r.createElement(l.A,{text:"\\(x_b\\)"}),". The newly generated image is then inspected to see if it matches the expected causal manipulation. If successful, this is strong evidence that the model has correctly disentangled each factor."),"\n",r.createElement(t.h4,{id:"723-qualitative-and-quantitative-metrics",style:{position:"relative"}},r.createElement(t.a,{href:"#723-qualitative-and-quantitative-metrics","aria-label":"723 qualitative and quantitative metrics permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.2.3 Qualitative and quantitative metrics"),"\n",r.createElement(t.p,null,"Qualitatively, you can see if the newly generated images look consistent when you attempt to combine or swap factors. Quantitatively, you can measure how well each latent dimension lines up with explicit ground-truth factors. Simple correlation or classification metrics might suffice, or you can compute metrics like the Adjusted Rand Index or Mutual Information Gap. The key takeaway is whether CITRIS is truly isolating each factor, thereby enabling easy recombination without cross-talk."),"\n",r.createElement(t.h3,{id:"73-performing-interventions-via-latent-space",style:{position:"relative"}},r.createElement(t.a,{href:"#73-performing-interventions-via-latent-space","aria-label":"73 performing interventions via latent space permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3 Performing interventions via latent space"),"\n",r.createElement(t.p,null,"Another hallmark experiment is to perform direct interventions in latent space and examine how the generated observations change. Because CITRIS is built for interventions, this step verifies its capacity to handle manipulations consistent with the real-world notion of causality."),"\n",r.createElement(t.h4,{id:"731-object-rotation-example",style:{position:"relative"}},r.createElement(t.a,{href:"#731-object-rotation-example","aria-label":"731 object rotation example permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3.1 Object rotation example"),"\n",r.createElement(t.p,null,"Consider controlling an object's rotation angle in the dataset. If ",r.createElement(l.A,{text:"\\(z_{\\text{rotation}}\\)"})," is indeed capturing rotation, then you should be able to fix all other dimensions in ",r.createElement(l.A,{text:"\\(z\\)"})," while systematically stepping through different values of ",r.createElement(l.A,{text:"\\(z_{\\text{rotation}}\\)"}),". Decoding these values using ",r.createElement(l.A,{text:"\\(G(z)\\)"})," should yield images of the object rotating, with no other changes in color, background, scale, or position."),"\n",r.createElement(t.p,null,"To implement this:"),"\n",r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">&lt;Code text={`\n# Hypothetical code snippet\nimport torch\n\ndef intervene_on_rotation(z, rotation_index, values):\n    # z is the latent representation\n    # rotation_index is the dimension controlling rotation\n    # values is a list of angles or latent codes to test\n    outputs = []\n    for val in values:\n        z_mod = z.clone()\n        z_mod[:, rotation_index] = val\n        outputs.append(decode(z_mod))\n    return outputs\n`}/></code></pre></div>'}}),"\n",r.createElement(t.p,null,"You can then visually inspect or compare these output images to see if the rotation is indeed the only change."),"\n",r.createElement(t.h4,{id:"732-randomizing-individual-causal-factors",style:{position:"relative"}},r.createElement(t.a,{href:"#732-randomizing-individual-causal-factors","aria-label":"732 randomizing individual causal factors permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3.2 Randomizing individual causal factors"),"\n",r.createElement(t.p,null,"Besides rotating an object, you can selectively randomize certain latent factors while freezing the others. If the model has learned a factor ",r.createElement(l.A,{text:"\\(z_{\\text{color}}\\)"})," that controls hue, randomizing just that factor should produce images in which only color changes. This procedure is a robust way to check for so-called ",r.createElement(s.A,{text:"conditional independence"})," among latent factors: if color is truly separate, you can vary it without inadvertently affecting shape or position."),"\n",r.createElement(t.h4,{id:"733-visualizing-the-intervention-results",style:{position:"relative"}},r.createElement(t.a,{href:"#733-visualizing-the-intervention-results","aria-label":"733 visualizing the intervention results permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.3.3 Visualizing the intervention results"),"\n",r.createElement(t.p,null,"To confirm that everything is working properly, it helps to produce side-by-side images showing ",r.createElement(l.A,{text:"\\(z\\)"})," with baseline factor settings and ",r.createElement(l.A,{text:"\\(z\\)"})," with the altered factor. You might place these images in a grid that highlights each factor's different levels. For instance:"),"\n",r.createElement(n,{alt:"Visualization of rotating object",path:"",caption:"A grid of images where each row corresponds to a different shape, and each column to a different rotation angle.",zoom:"false"}),"\n",r.createElement(t.p,null,"Such visualizations provide immediate qualitative evidence of whether the interventions are performing as expected."),"\n",r.createElement(t.h3,{id:"74-analyzing-the-latent-space",style:{position:"relative"}},r.createElement(t.a,{href:"#74-analyzing-the-latent-space","aria-label":"74 analyzing the latent space permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4 Analyzing the latent space"),"\n",r.createElement(t.p,null,"Last but not least, we come to the analytical tools that let you see how CITRIS organizes the latent space under the constraints of identifiability and minimality."),"\n",r.createElement(t.h4,{id:"741-tracking-changes-to-position-spotlight-rotation-and-background-hue",style:{position:"relative"}},r.createElement(t.a,{href:"#741-tracking-changes-to-position-spotlight-rotation-and-background-hue","aria-label":"741 tracking changes to position spotlight rotation and background hue permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4.1 Tracking changes to position, spotlight rotation, and background hue"),"\n",r.createElement(t.p,null,"One approach is to track how each latent dimension correlates to a known ground-truth factor. For instance, you can measure the correlation between ",r.createElement(l.A,{text:"\\(z^k\\)"})," and the horizontal position of the object across many images. If ",r.createElement(l.A,{text:"\\(z^k\\)"})," is indeed controlling horizontal position, the correlation should be near 1, and you should find minimal correlation with other factors."),"\n",r.createElement(t.h4,{id:"742-bar-plots-of-latent-dimensions-per-causal-variable",style:{position:"relative"}},r.createElement(t.a,{href:"#742-bar-plots-of-latent-dimensions-per-causal-variable","aria-label":"742 bar plots of latent dimensions per causal variable permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4.2 Bar plots of latent dimensions per causal variable"),"\n",r.createElement(t.p,null,"A convenient visualization is to create a bar plot that, for each ground-truth factor, shows the magnitude of correlation with each latent dimension. If CITRIS is working perfectly, you would see each factor strongly correlated with exactly one latent dimension, and near-zero correlation with all others. The bar plot might reveal a neat diagonal structure, confirming a near-perfect disentanglement."),"\n",r.createElement(t.h4,{id:"743-insights-on-disentanglement-and-factor-independence",style:{position:"relative"}},r.createElement(t.a,{href:"#743-insights-on-disentanglement-and-factor-independence","aria-label":"743 insights on disentanglement and factor independence permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"7.4.3 Insights on disentanglement and factor independence"),"\n",r.createElement(t.p,null,"Ultimately, the best-case scenario is that each dimension in ",r.createElement(l.A,{text:"\\(z\\)"})," lines up with a single real-world cause. In such a scenario, CITRIS has successfully delivered on the promise of causal representation learning: you can manipulate a dimension confident that it corresponds to a meaningful causal property, and every other dimension remains untouched by that intervention."),"\n",r.createElement(t.h2,{id:"8-conclusion-and-future-directions",style:{position:"relative"}},r.createElement(t.a,{href:"#8-conclusion-and-future-directions","aria-label":"8 conclusion and future directions permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8. Conclusion and future directions"),"\n",r.createElement(t.p,null,"CITRIS stands as one of the more compelling frameworks for bridging the gap between theoretical desiderata—like identifiability and disentanglement—and the messy reality of real-world data. By explicitly leveraging the TRIS assumption, CITRIS obtains stronger causal learning signals than purely observational or purely generative models can. The result is a method that does not merely capture correlations; it identifies minimal causal variables that can be manipulated, recombined, and tested across different domains or tasks."),"\n",r.createElement(t.h3,{id:"81-key-takeaways-from-citris",style:{position:"relative"}},r.createElement(t.a,{href:"#81-key-takeaways-from-citris","aria-label":"81 key takeaways from citris permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.1 Key takeaways from CITRIS"),"\n",r.createElement(t.p,null,"Several central insights emerge from the CITRIS blueprint:"),"\n",r.createElement(t.p,null,"• ",r.createElement(t.strong,null,"Temporal consistency"),": By aligning consecutive frames unless intervened upon, CITRIS can infer stable causal factors over time.",r.createElement(t.br),"\n","• ",r.createElement(t.strong,null,"Interventions"),": Observing how interventions selectively change certain latent dimensions is a powerful way to disambiguate correlation from real causation.",r.createElement(t.br),"\n","• ",r.createElement(t.strong,null,"Invertibility"),": Enforcing a one-to-one mapping between latent codes and data fosters disentanglement and helps CITRIS secure identifiability guarantees.",r.createElement(t.br),"\n","• ",r.createElement(t.strong,null,"Scalability"),": Although CITRIS is far from trivial to implement, certain versions (like iCITRIS and CITRIS-NF) demonstrate that normalizing flows and advanced autoencoder structures can scale to moderately complex data and interventions."),"\n",r.createElement(t.h3,{id:"82-strengths-and-limitations-of-current-crl-methods",style:{position:"relative"}},r.createElement(t.a,{href:"#82-strengths-and-limitations-of-current-crl-methods","aria-label":"82 strengths and limitations of current crl methods permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.2 Strengths and limitations of current CRL methods"),"\n",r.createElement(t.p,null,"Like any new research domain, CRL, including CITRIS, is a work in progress:"),"\n",r.createElement(t.p,null,"• ",r.createElement(t.strong,null,"Strengths"),": Substantial progress has been made in formulating theoretical guarantees for identifiability, in designing frameworks that handle interventions elegantly, and in structuring networks that remain faithful to causal constraints.",r.createElement(t.br),"\n","• ",r.createElement(t.strong,null,"Limitations"),": Real-world data rarely offers neat, labeled interventions. In many domains, interventions might be partial, noisy, or confounded by unobserved external factors. Additionally, scaling CRL methods to extremely large or multi-object scenes (like entire cityscapes) remains an ongoing challenge. Finally, perfect invertibility assumptions can be strong, and approximate solutions might be needed in practice."),"\n",r.createElement(t.h3,{id:"83-potential-applications-and-next-steps",style:{position:"relative"}},r.createElement(t.a,{href:"#83-potential-applications-and-next-steps","aria-label":"83 potential applications and next steps permalink",className:"anchor before"},r.createElement(t.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"8.3 Potential applications and next steps"),"\n",r.createElement(t.p,null,"The future of CRL holds a wealth of opportunities. In reinforcement learning contexts, CRL could enable an agent to systematically plan interventions and interpret them as desired outcomes, leading to more sample-efficient training. In computer vision, CRL can help disentangle factors of variation for tasks such as scene editing, domain adaptation, and semantic manipulation of images and videos. In robotics, it can help decipher which aspects of a system's state truly matter for control and which aspects are merely ephemeral byproducts."),"\n",r.createElement(t.p,null,"For ongoing research, questions like how to handle partial observability, how to combine CRL with large-scale foundation models, and how to systematically evaluate real vs. spurious causal factors remain frontiers. Another open-ended inquiry is bridging CITRIS with more rigorous Bayesian frameworks, thereby combining interpretability and uncertainty quantification. Researchers have begun to explore expansions of CITRIS that incorporate more flexible priors, more advanced normalizing flow architectures, or additional structured interventions."),"\n",r.createElement(t.p,null,"Ultimately, the quest to discover and manipulate true causal variables in data aligns closely with the overarching ambition of AI: to build models that do not just reflect the world as is, but that can robustly reason about—and act within—it. As CRL matures, expect to see it increasingly embedded in real-world applications, from automated medical diagnosis to interactive content-generation pipelines, forging a path toward machine learning models that are stable, interpretable, and capable of informed decision-making under interventions."),"\n",r.createElement(t.p,null,"I encourage you to revisit the tutorial notebooks and pre-trained models mentioned earlier. Attempt the recommended tasks, replicate the CITRIS experiments on Causal3DIdent, manipulate latent factors, and evaluate the results. Reflect on how well the method generalizes across diverse settings and whether it lives up to theoretical claims. With a solid grounding in these key ideas, you will be poised to explore the wide-open horizon of causal representation learning research, fueled by frameworks like CITRIS and its successors."))}var h=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,i.RP)(),e.components);return t?r.createElement(t,e,r.createElement(c,e)):c(e)};var d=n(36710),m=n(58481),u=n.n(m),p=n(36310),g=n(87245),f=n(27042),v=n(59849),b=n(5591),y=n(61122),w=n(9219),E=n(33203),S=n(95751),x=n(94328),I=n(80791),z=n(78137);const C=e=>{let{toc:t}=e;if(!t||!t.items)return null;return r.createElement("nav",{className:I.R},r.createElement("ul",null,t.items.map(((e,t)=>r.createElement("li",{key:t},r.createElement("a",{href:e.url,onClick:t=>((e,t)=>{e.preventDefault();const n=t.replace("#",""),a=document.getElementById(n);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(t,e.url)},e.title),e.items&&r.createElement(C,{toc:{items:e.items}}))))))};function T(e){let{data:{mdx:t,allMdx:o,allPostImages:l},children:s}=e;const{frontmatter:c,body:h,tableOfContents:d}=t,m=c.index,v=c.slug.split("/")[1],I=o.nodes.filter((e=>e.frontmatter.slug.includes(`/${v}/`))).sort(((e,t)=>e.frontmatter.index-t.frontmatter.index)),T=I.findIndex((e=>e.frontmatter.index===m)),k=I[T+1],_=I[T-1],H=c.slug.replace(/\/$/,""),L=/[^/]*$/.exec(H)[0],A=`posts/${v}/content/${L}/`,{0:M,1:R}=(0,r.useState)(c.flagWideLayoutByDefault),{0:N,1:V}=(0,r.useState)(!1);var j;(0,r.useEffect)((()=>{V(!0);const e=setTimeout((()=>V(!1)),340);return()=>clearTimeout(e)}),[M]),"adventures"===v?j=w.cb:"research"===v?j=w.Qh:"thoughts"===v&&(j=w.T6);const B=u()(h).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,D=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const t=Math.floor(e/60),n=e%60;return n<=30?`~${t}${n>0?".5":""} h`:`~${t+1} h`}(Math.ceil(B/j)+(c.extraReadTimeMin||0)),O=[{flag:c.flagDraft,component:()=>Promise.all([n.e(3231),n.e(8809)]).then(n.bind(n,28809))},{flag:c.flagMindfuckery,component:()=>Promise.all([n.e(3231),n.e(2471)]).then(n.bind(n,67709))},{flag:c.flagRewrite,component:()=>Promise.all([n.e(3231),n.e(6764)]).then(n.bind(n,62002))},{flag:c.flagOffensive,component:()=>Promise.all([n.e(3231),n.e(2443)]).then(n.bind(n,17681))},{flag:c.flagProfane,component:()=>Promise.all([n.e(3231),n.e(8048)]).then(n.bind(n,53286))},{flag:c.flagMultilingual,component:()=>Promise.all([n.e(3231),n.e(4069)]).then(n.bind(n,78831))},{flag:c.flagUnreliably,component:()=>Promise.all([n.e(3231),n.e(3417)]).then(n.bind(n,8179))},{flag:c.flagPolitical,component:()=>Promise.all([n.e(3231),n.e(5195)]).then(n.bind(n,30433))},{flag:c.flagCognitohazard,component:()=>Promise.all([n.e(3231),n.e(3175)]).then(n.bind(n,8413))},{flag:c.flagHidden,component:()=>Promise.all([n.e(3231),n.e(9556)]).then(n.bind(n,14794))}],{0:P,1:q}=(0,r.useState)([]);return(0,r.useEffect)((()=>{O.forEach((e=>{let{flag:t,component:n}=e;t&&n().then((e=>{q((t=>[].concat((0,a.A)(t),[e.default])))}))}))}),[]),r.createElement(f.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},r.createElement(b.A,{postNumber:c.index,date:c.date,updated:c.updated,readTime:D,difficulty:c.difficultyLevel,title:c.title,desc:c.desc,banner:c.banner,section:v,postKey:L,isMindfuckery:c.flagMindfuckery,mainTag:c.mainTag}),r.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},c.otherTags.map(((e,t)=>r.createElement("span",{key:t,className:`noselect ${z.MW}`,style:{margin:"0 5px 5px 0"}},e)))),r.createElement("div",{class:"postBody"},r.createElement(C,{toc:d})),r.createElement("br"),r.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},r.createElement(f.P.button,{class:"noselect",className:x.pb,id:x.xG,onClick:()=>{R(!M)},whileTap:{scale:.93}},r.createElement(f.P.div,{className:S.DJ,key:M,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},M?"Switch to default layout":"Switch to wide layout"))),r.createElement("br"),r.createElement("div",{class:"postBody",style:{margin:M?"0 -14%":"",maxWidth:M?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},r.createElement("div",{className:`${x.P_} ${N?x.Xn:x.qG}`},P.map(((e,t)=>r.createElement(e,{key:t}))),c.indexCourse?r.createElement(E.A,{index:c.indexCourse,category:c.courseCategoryName}):"",r.createElement(p.Z.Provider,{value:{images:l.nodes,basePath:A.replace(/\/$/,"")+"/"}},r.createElement(i.xA,{components:{Image:g.A}},s)))),r.createElement(y.A,{nextPost:k,lastPost:_,keyCurrent:L,section:v}))}function k(e){return r.createElement(T,e,r.createElement(h,e))}function _(e){var t,n,a,i,o;let{data:l}=e;const{frontmatter:s}=l.mdx,c=s.titleSEO||s.title,h=s.titleOG||c,m=s.titleTwitter||c,u=s.descSEO||s.desc,p=s.descOG||u,g=s.descTwitter||u,f=s.schemaType||"BlogPosting",b=s.keywordsSEO,y=s.date,w=s.updated||y,E=s.imageOG||(null===(t=s.banner)||void 0===t||null===(n=t.childImageSharp)||void 0===n||null===(a=n.gatsbyImageData)||void 0===a||null===(i=a.images)||void 0===i||null===(o=i.fallback)||void 0===o?void 0:o.src),S=s.imageAltOG||p,x=s.imageTwitter||E,I=s.imageAltTwitter||g,z=s.canonicalURL,C=s.flagHidden||!1,T=s.mainTag||"Posts",k=s.slug.split("/")[1]||"posts",{siteUrl:_}=(0,d.Q)(),H={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:_},{"@type":"ListItem",position:2,name:T,item:`${_}/${s.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${_}${s.slug}`}]};return r.createElement(v.A,{title:c+" - avrtt.blog",titleOG:h,titleTwitter:m,description:u,descriptionOG:p,descriptionTwitter:g,schemaType:f,keywords:b,datePublished:y,dateModified:w,imageOG:E,imageAltOG:S,imageTwitter:x,imageAltTwitter:I,canonicalUrl:z,flagHidden:C,mainTag:T,section:k,type:"article"},r.createElement("script",{type:"application/ld+json"},JSON.stringify(H)))}}}]);
//# sourceMappingURL=component---src-templates-post-js-content-file-path-src-pages-posts-research-causal-representation-learning-mdx-4d686bc9f001a070fa72.js.map