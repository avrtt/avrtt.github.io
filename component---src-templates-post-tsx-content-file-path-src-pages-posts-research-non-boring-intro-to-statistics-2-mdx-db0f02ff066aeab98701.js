"use strict";(self.webpackChunkavrtt_blog=self.webpackChunkavrtt_blog||[]).push([[397],{14222:function(e,n,t){var a=t(96540);const s={hater:()=>t.e(1448).then(t.bind(t,31448)),babel_tower:()=>t.e(6588).then(t.bind(t,66588)),bibizan:()=>t.e(5830).then(t.bind(t,95830)),cursed_emoji2:()=>t.e(5943).then(t.bind(t,95943)),cursed_emoji1:()=>t.e(7468).then(t.bind(t,27468)),mda:()=>t.e(4666).then(t.bind(t,54666)),cat_shake:()=>t.e(9690).then(t.bind(t,59690)),nerazdyplenish3:()=>t.e(1992).then(t.bind(t,51992)),burnt:()=>t.e(7656).then(t.bind(t,17656)),chad:()=>t.e(9365).then(t.bind(t,99365)),hedgehog:()=>t.e(6096).then(t.bind(t,86096)),yoba_dovolen:()=>t.e(6937).then(t.bind(t,46937)),pug_dance:()=>t.e(333).then(t.bind(t,30333)),pepe_chair:()=>t.e(689).then(t.bind(t,20689)),pepe_serious:()=>t.e(1808).then(t.bind(t,21808)),pepe_run:()=>t.e(8777).then(t.bind(t,8777)),pepe_punch:()=>t.e(7350).then(t.bind(t,87350)),pepe_agree:()=>t.e(5670).then(t.bind(t,85670)),pepe_pledik:()=>t.e(5650).then(t.bind(t,75650)),cat_stand:()=>t.e(8399).then(t.bind(t,38399)),cat_sleep:()=>t.e(8966).then(t.bind(t,88966)),nerazdyplenish2:()=>t.e(4498).then(t.bind(t,52117)),nerazdyplenish1:()=>t.e(9033).then(t.bind(t,39033)),morshu_gnome:()=>t.e(561).then(t.bind(t,30561)),cat_bw:()=>t.e(5302).then(t.bind(t,45302)),pepe_mage:()=>t.e(7239).then(t.bind(t,47239)),pepe_linux:()=>t.e(6083).then(t.bind(t,16083)),yoba_pledik:()=>t.e(5655).then(t.bind(t,45655)),pepe_chill:()=>t.e(3507).then(t.bind(t,23507)),pepe_meditation:()=>t.e(8125).then(t.bind(t,68125)),trollface:()=>t.e(8272).then(t.bind(t,78272)),cat_smile:()=>t.e(3987).then(t.bind(t,63987)),beluga:()=>t.e(5314).then(t.bind(t,35314)),pepe_money:()=>t.e(6674).then(t.bind(t,66674)),pepe_cry:()=>t.e(726).then(t.bind(t,10726)),pepe_dance:()=>t.e(3691).then(t.bind(t,93691)),dog_nerd:()=>t.e(1896).then(t.bind(t,61896)),cat_ya_piska:()=>t.e(7040).then(t.bind(t,17040)),gandonio:()=>t.e(49).then(t.bind(t,49)),pepe_wink:()=>t.e(435).then(t.bind(t,20435))};n.A=e=>{let{sticker:n,marginLeft:t="4px",marginRight:i="0px"}=e;const{0:l,1:r}=(0,a.useState)(null);if((0,a.useEffect)((()=>{const e=n;s[e]&&s[e]().then((e=>r(e.default)))}),[n]),!l)return null;const o={width:"1.8em",height:"1.8em",verticalAlign:"middle",marginTop:"-10px",marginRight:i,marginLeft:t};return a.createElement("img",{alt:"sticker",style:o,src:l})}},62374:function(e,n,t){t.r(n),t.d(n,{Head:function(){return M},PostTemplate:function(){return z},default:function(){return C}});var a=t(28453),s=t(96540),i=t(14222),l=t(61992),r=t(62087),o=t(90548);function c(e){const n=Object.assign({p:"p",em:"em",h2:"h2",a:"a",span:"span",h3:"h3",ol:"ol",li:"li",strong:"strong",ul:"ul",hr:"hr",br:"br"},(0,a.RP)(),e.components),{Image:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Image",!0),s.createElement(s.Fragment,null,s.createElement(n.p,null,s.createElement(n.em,null,"Statistically, a liar is believed more if he cites statistics.")),"\n",s.createElement("br"),"\n","\n","\n",s.createElement(n.h2,{id:"sampling",style:{position:"relative"}},s.createElement(n.a,{href:"#sampling","aria-label":"sampling permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Sampling"),"\n",s.createElement(n.p,null,"Let's get a bit closer to machine learning."),"\n",s.createElement(n.p,null,"Sampling is the process of selecting a subset of data points or observations from a larger population. This is done so we can analyze the subset and make reasonable inferences about the entire population — without having to collect or observe every possible data point. In data science and machine learning, sampling is pervasive: from building training sets to constructing test sets, we rely on carefully chosen samples to train and evaluate our models. When done correctly, sampling can save enormous resources (time, cost, computational effort) while preserving the essential characteristics of the overall population."),"\n",s.createElement(n.h3,{id:"sampling-methods-and-strategies",style:{position:"relative"}},s.createElement(n.a,{href:"#sampling-methods-and-strategies","aria-label":"sampling methods and strategies permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Sampling methods and strategies"),"\n",s.createElement(n.p,null,"Sampling methods can be broadly divided into ",s.createElement(l.A,null,"probability-based")," and ",s.createElement(l.A,null,"non-probability-based")," strategies:"),"\n",s.createElement(n.ol,null,"\n",s.createElement(n.li,null,"\n",s.createElement(n.p,null,s.createElement(n.strong,null,"Probability-based sampling"),": Each member of the population has a known (and typically non-zero) probability of being selected."),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Simple random sampling"),": Every individual in the population has an equal chance of being selected. This is often done by assigning random numbers to the population and picking the smallest (or largest) subset or by using randomizing functions in software."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Systematic sampling"),": You pick a random start point and then select every ",s.createElement(o.A,{text:"\\(k\\)"}),"-th item, where ",s.createElement(o.A,{text:"\\(k\\)"})," is determined by dividing the population size by the desired sample size."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Stratified sampling"),": The population is divided into homogeneous subgroups, or strata (e.g., by age group, region, or income bracket). You then randomly select individuals from each stratum in proportion to that stratum's size in the population."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Cluster sampling"),": The population is split into clusters (e.g., geographical areas, organizational units). A subset of clusters is then selected randomly, and within each chosen cluster, you either collect data from every member or again select a random subset."),"\n"),"\n"),"\n",s.createElement(n.li,null,"\n",s.createElement(n.p,null,s.createElement(n.strong,null,"Non-probability-based sampling"),":"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Convenience sampling"),": Selecting participants or data points based on their easy availability (e.g., surveying people in a mall)."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Quota sampling"),": Ensuring that the sample meets certain quotas for predefined categories (e.g., 40% female, 60% male) but otherwise using a non-random approach within each category."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Snowball sampling"),": Typically used when the population is hard to reach or hidden. Existing participants recruit future ones (e.g., surveying members of niche online forums)."),"\n"),"\n"),"\n"),"\n",s.createElement(n.p,null,"Each approach has trade-offs. Probability-based methods typically allow for more rigorous statistical inference (e.g., confidence intervals, error bounds), whereas non-probability methods are sometimes faster or more practical in real-world settings."),"\n",s.createElement(n.h3,{id:"importance-of-representative-samples",style:{position:"relative"}},s.createElement(n.a,{href:"#importance-of-representative-samples","aria-label":"importance of representative samples permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Importance of representative samples"),"\n",s.createElement(n.p,null,"A ",s.createElement(l.A,null,"representative sample")," is one that captures the essential characteristics of the broader population. If the sample systematically overrepresents or underrepresents certain features, any statistical inference from that sample could be biased or misleading. For instance, if you are polling political opinions and only sample individuals who frequently use social media, your results might not represent those who rarely use the internet — leading to skewed conclusions."),"\n",s.createElement(n.h3,{id:"importance-of-sampling-in-statistics",style:{position:"relative"}},s.createElement(n.a,{href:"#importance-of-sampling-in-statistics","aria-label":"importance of sampling in statistics permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Importance of sampling in statistics"),"\n",s.createElement(n.p,null,"Sampling underpins almost every statistical procedure. Many foundational techniques — like hypothesis testing, confidence interval construction, or regression analysis — depend on the assumption that the data analyzed are drawn from a representative sample. If this assumption is violated, our estimates of the population parameters (e.g., mean, variance) may be inaccurate, making all subsequent analyses questionable."),"\n",s.createElement(n.p,null,"Moreover, in ",s.createElement(l.A,null,"machine learning"),", we often split a dataset into training, validation, and test sets. Doing so correctly relies on sound sampling strategies that preserve overall class distributions (in classification) or other important characteristics. This helps ensure that model performance metrics generalize to the real-world data distribution."),"\n",s.createElement(n.h3,{id:"types-of-sampling",style:{position:"relative"}},s.createElement(n.a,{href:"#types-of-sampling","aria-label":"types of sampling permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Types of sampling"),"\n",s.createElement(n.p,null,"Here are the key types in concise form:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Random (simple random sampling)"),": Every member of the population has an equal probability of being included."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Stratified sampling"),": The population is split by known characteristics (strata), and a random sample is taken within each group to ensure representation."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Cluster sampling"),': Natural groupings in the population serve as "clusters." A random set of clusters is chosen, and data are collected from within each selected cluster.'),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Systematic sampling"),": A fixed, periodic interval is used after a random start."),"\n"),"\n",s.createElement(n.h3,{id:"sampling-bias-and-how-to-avoid-it",style:{position:"relative"}},s.createElement(n.a,{href:"#sampling-bias-and-how-to-avoid-it","aria-label":"sampling bias and how to avoid it permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Sampling bias and how to avoid it"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Sampling bias")," occurs when some members of the population are more likely to be chosen than others, distorting inferences about the population. Common causes include:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Selection bias"),": The way participants are selected (e.g., using only volunteers) is not representative."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Non-response bias"),": Individuals who choose not to respond differ systematically from those who do."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Undercoverage"),": Important segments of the population are insufficiently included (e.g., not having phone numbers for rural households)."),"\n"),"\n",s.createElement(n.p,null,"To mitigate sampling bias:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,"Use random selection whenever possible."),"\n",s.createElement(n.li,null,"Compare sample demographics to known population demographics (if available) to detect imbalances."),"\n",s.createElement(n.li,null,"Employ techniques like weighting to account for underrepresented groups."),"\n",s.createElement(n.li,null,"Ensure clear and accessible data-collection processes that minimize barriers to participation."),"\n"),"\n",s.createElement(n.h3,{id:"reservoir-sampling",style:{position:"relative"}},s.createElement(n.a,{href:"#reservoir-sampling","aria-label":"reservoir sampling permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Reservoir Sampling"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Reservoir sampling")," is a clever technique to draw a fixed-size random sample from a potentially large or unknown-size stream of data:"),"\n",s.createElement(n.ol,null,"\n",s.createElement(n.li,null,'Fill the "reservoir" array of size ',s.createElement(o.A,{text:"\\(k\\)"})," with the first ",s.createElement(o.A,{text:"\\(k\\)"})," items."),"\n",s.createElement(n.li,null,"For each item ",s.createElement(o.A,{text:"\\(i\\)"})," (counting from ",s.createElement(o.A,{text:"\\(k+1\\)"})," to ",s.createElement(o.A,{text:"\\(n\\)"}),") in the stream:","\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,"Generate a random number ",s.createElement(o.A,{text:"\\(r\\)"})," in ",s.createElement(o.A,{text:"\\([1, i]\\)"}),"."),"\n",s.createElement(n.li,null,"If ",s.createElement(o.A,{text:"\\(r \\le k\\)"}),", replace the item in the reservoir at index ",s.createElement(o.A,{text:"\\(r\\)"})," with the new item ",s.createElement(o.A,{text:"\\(i\\)"}),"."),"\n"),"\n"),"\n"),"\n",s.createElement(n.p,null,"This ensures that, after processing all ",s.createElement(o.A,{text:"\\(n\\)"})," items, each item has an equal probability (",s.createElement(o.A,{text:"\\(k/n\\)"}),") of appearing in the reservoir. It is especially useful for streaming data or extremely large datasets where storing the entire data in memory is impractical."),"\n",s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> random\n\n<span class="token keyword">def</span> <span class="token function">reservoir_sampling</span><span class="token punctuation">(</span>stream<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token triple-quoted-string string">"""Return k uniformly random items from a stream."""</span>\n    reservoir <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>\n    \n    <span class="token comment"># Fill reservoir with first k items</span>\n    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        reservoir<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stream<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>\n    \n    <span class="token comment"># Replace elements with gradually decreasing probability</span>\n    index <span class="token operator">=</span> k\n    <span class="token keyword">while</span> index <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        <span class="token comment"># Random integer in [0, index]</span>\n        r <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>\n        <span class="token keyword">if</span> r <span class="token operator">&lt;</span> k<span class="token punctuation">:</span>\n            reservoir<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> stream<span class="token punctuation">[</span>index<span class="token punctuation">]</span>\n        index <span class="token operator">+=</span> <span class="token number">1</span>\n    \n    <span class="token keyword">return</span> reservoir\n\n<span class="token comment"># Example usage</span>\ndata_stream <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10001</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\nsampled <span class="token operator">=</span> reservoir_sampling<span class="token punctuation">(</span>data_stream<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>\n<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Random sample from a large stream:"</span><span class="token punctuation">,</span> sampled<span class="token punctuation">)</span></code></pre></div>'}}),"\n",s.createElement(n.h3,{id:"handling-imbalanced-classes-with-smote",style:{position:"relative"}},s.createElement(n.a,{href:"#handling-imbalanced-classes-with-smote","aria-label":"handling imbalanced classes with smote permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Handling Imbalanced Classes with SMOTE"),"\n",s.createElement(n.p,null,"For ",s.createElement(l.A,null,"imbalanced classification")," problems (e.g., fraud detection, where the fraudulent cases are rare), standard random sampling often leads to models that overlook minority classes. ",s.createElement(l.A,null,"SMOTE (Synthetic Minority Over-sampling Technique)")," addresses this by generating synthetic samples of the minority class rather than merely duplicating existing points."),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Step 1"),": For each minority class instance, find its k-nearest neighbors in the minority class."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Step 2"),": Randomly select one of those neighbors and generate a synthetic point along the line joining the two samples."),"\n"),"\n",s.createElement(n.p,null,"This way, the minority class distribution is augmented in feature space, reducing the risk of overfitting and helping the model learn decision boundaries more effectively."),"\n",s.createElement(t,{alt:"SMOTE illustration",path:"",caption:"Synthetic samples are generated along the line segments between a minority sample and its neighbors."}),"\n",s.createElement(n.h3,{id:"weighted-sampling",style:{position:"relative"}},s.createElement(n.a,{href:"#weighted-sampling","aria-label":"weighted sampling permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Weighted Sampling"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Weighted sampling")," assigns different probabilities to different items based on importance or cost. In certain real-world scenarios, not all data points are equally informative or equally likely. Weighted sampling ensures that items of higher importance or underrepresented subpopulations are more likely to be included in the sample."),"\n",s.createElement(n.h3,{id:"bootstrap-sampling",style:{position:"relative"}},s.createElement(n.a,{href:"#bootstrap-sampling","aria-label":"bootstrap sampling permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Bootstrap Sampling"),"\n",s.createElement(n.p,null,"Although widely known for forming confidence intervals (via the bootstrap method), ",s.createElement(l.A,null,"bootstrap sampling"),' can also be used to evaluate the stability or variability of statistical estimates. In this approach, you resample (with replacement) from your original dataset to create many "bootstrapped" datasets of the same size as the original. Each bootstrapped dataset provides a slightly different estimate of your parameter (e.g., mean, correlation), allowing you to assess how much that estimate fluctuates.'),"\n",s.createElement(n.h2,{id:"exploring-relationships-between-variables",style:{position:"relative"}},s.createElement(n.a,{href:"#exploring-relationships-between-variables","aria-label":"exploring relationships between variables permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Exploring relationships between variables"),"\n",s.createElement(n.p,null,"Analyzing relationships between variables is central to understanding patterns in data. Correlation and covariance are two fundamental ways to measure how changes in one variable are associated with changes in another."),"\n",s.createElement(n.h3,{id:"correlation-positive-negative-and-zero-correlations",style:{position:"relative"}},s.createElement(n.a,{href:"#correlation-positive-negative-and-zero-correlations","aria-label":"correlation positive negative and zero correlations permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Correlation: positive, negative, and zero correlations"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Correlation")," measures the strength and direction of a linear relationship between two variables. The most common measure is the Pearson correlation coefficient ",s.createElement(o.A,{text:"\\(\\rho\\)"})," (for population) or ",s.createElement(o.A,{text:"\\(r\\)"})," (for sample):"),"\n",s.createElement(o.A,{text:"\\( r = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\sum_{i=1}^n (y_i - \\bar{y})^2}}. \\)"}),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Positive correlation"),": As one variable increases, the other tends to increase (e.g., height and weight)."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Negative correlation"),": As one variable increases, the other tends to decrease (e.g., the time spent studying might negatively correlate with error rates on a test)."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Zero (or near-zero) correlation"),": No linear relationship is observed (e.g., daily temperature vs. the number of letters in your name)."),"\n"),"\n",s.createElement(n.p,null,"A value of ",s.createElement(o.A,{text:"\\(r = 1\\)"})," indicates a perfect positive linear relationship, ",s.createElement(o.A,{text:"\\(r = -1\\)"})," indicates a perfect negative linear relationship, and ",s.createElement(o.A,{text:"\\(r = 0\\)"})," indicates no linear relationship. Real-world data rarely show perfect linearity, but even moderate correlations can be significant in certain contexts."),"\n",s.createElement(n.h3,{id:"covariance",style:{position:"relative"}},s.createElement(n.a,{href:"#covariance","aria-label":"covariance permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Covariance"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Covariance")," is a measure of how two variables vary together. It is given by:"),"\n",s.createElement(o.A,{text:"\\( \\mathrm{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])]. \\)"}),"\n",s.createElement(n.p,null,"In practice, we often estimate it using the sample covariance:"),"\n",s.createElement(o.A,{text:"\\( \\hat{\\mathrm{Cov}}(X, Y) = \\frac{1}{n - 1} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}). \\)"}),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,"If ",s.createElement(o.A,{text:"\\(\\mathrm{Cov}(X, Y) > 0\\)"}),", ",s.createElement(o.A,{text:"\\(X\\)"})," and ",s.createElement(o.A,{text:"\\(Y\\)"})," tend to move in the same direction."),"\n",s.createElement(n.li,null,"If ",s.createElement(o.A,{text:"\\(\\mathrm{Cov}(X, Y) < 0\\)"}),", ",s.createElement(o.A,{text:"\\(X\\)"})," and ",s.createElement(o.A,{text:"\\(Y\\)"})," tend to move in opposite directions."),"\n",s.createElement(n.li,null,"If ",s.createElement(o.A,{text:"\\(\\mathrm{Cov}(X, Y) = 0\\)"}),", there is no linear association."),"\n"),"\n",s.createElement(n.p,null,"Covariance is not standardized and depends on the units of the variables. By normalizing covariance (dividing by the standard deviations of both variables), you get the correlation coefficient."),"\n",s.createElement(n.h3,{id:"why-correlation-is-not-causation",style:{position:"relative"}},s.createElement(n.a,{href:"#why-correlation-is-not-causation","aria-label":"why correlation is not causation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),'Why "correlation is not causation"'),"\n",s.createElement(n.p,null,"It is a common misconception to interpret correlation as evidence of a cause-and-effect relationship. A high correlation might be due to:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Confounding factors"),": A third variable influences both ",s.createElement(o.A,{text:"\\(X\\)"})," and ",s.createElement(o.A,{text:"\\(Y\\)"}),' (e.g., "ice cream sales" and "drowning incidents" both increase in hot weather).'),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Reverse causality"),": Instead of ",s.createElement(o.A,{text:"\\(X\\)"})," causing ",s.createElement(o.A,{text:"\\(Y\\)"}),", it might be that ",s.createElement(o.A,{text:"\\(Y\\)"})," causes ",s.createElement(o.A,{text:"\\(X\\)"}),"."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Coincidence"),": Sometimes variables correlate purely by chance in finite samples."),"\n"),"\n",s.createElement(n.p,null,"In practice, establishing causality typically requires controlled experiments (e.g., randomized controlled trials) or robust observational study designs. Advanced methods such as causal graphs (e.g., Judea Pearl's work) or quasi-experimental designs (e.g., difference-in-differences) can also be used."),"\n",s.createElement(n.h3,{id:"spearmans-rank-correlation",style:{position:"relative"}},s.createElement(n.a,{href:"#spearmans-rank-correlation","aria-label":"spearmans rank correlation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Spearman's Rank Correlation"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Spearman's rank correlation coefficient")," is a non-parametric measure of correlation that assesses how well the relationship between two variables can be described using a monotonic function. Unlike Pearson correlation, it relies on the rank of the data rather than the actual numeric values, making it more robust to outliers or non-linear relationships."),"\n",s.createElement(n.p,null,"Formally, if ",s.createElement(o.A,{text:"\\(R(x_i)\\)"})," is the rank of ",s.createElement(o.A,{text:"\\(x_i\\)"})," and ",s.createElement(o.A,{text:"\\(R(y_i)\\)"})," is the rank of ",s.createElement(o.A,{text:"\\(y_i\\)"}),":"),"\n",s.createElement(o.A,{text:"\\( \\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}, \\)"}),"\n",s.createElement(n.p,null,"where ",s.createElement(o.A,{text:"\\(d_i = R(x_i) - R(y_i)\\)"}),"."),"\n",s.createElement(n.h3,{id:"kendalls-tau",style:{position:"relative"}},s.createElement(n.a,{href:"#kendalls-tau","aria-label":"kendalls tau permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Kendall's Tau"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Kendall's tau")," is another rank-based measure. It counts the number of concordant vs. discordant pairs in the data. While computationally slightly more involved, Kendall's tau can sometimes be more sensitive in capturing the strength of a monotonic relationship than Spearman's correlation."),"\n",s.createElement(n.h3,{id:"partial-correlation",style:{position:"relative"}},s.createElement(n.a,{href:"#partial-correlation","aria-label":"partial correlation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Partial Correlation"),"\n",s.createElement(n.p,null,"A ",s.createElement(l.A,null,"partial correlation")," measures the relationship between two variables while controlling for the effect of one or more additional variables. This is particularly useful in multivariate analyses where the direct relationship between two variables might be confounded by a third."),"\n",s.createElement(n.p,null,'For instance, if you want to see how "exercise frequency" (X) correlates with "blood pressure" (Y) while removing the effect of "age" (Z), partial correlation helps filter out the influence that age might have on both exercise frequency and blood pressure.'),"\n",s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np\n\n<span class="token keyword">def</span> <span class="token function">partial_correlation</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token triple-quoted-string string">"""\n    Compute the partial correlation matrix of X.\n    Each column of X is a variable.\n    """</span>\n    <span class="token comment"># Invert the covariance matrix</span>\n    cov <span class="token operator">=</span> np<span class="token punctuation">.</span>cov<span class="token punctuation">(</span>X<span class="token punctuation">,</span> rowvar<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>\n    inv_cov <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>cov<span class="token punctuation">)</span>\n\n    <span class="token comment"># Normalize to get partial correlation</span>\n    d <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>inv_cov<span class="token punctuation">)</span><span class="token punctuation">)</span>\n    P <span class="token operator">=</span> <span class="token operator">-</span>inv_cov <span class="token operator">/</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token punctuation">)</span>\n    \n    <span class="token comment"># Diagonal entries will be 1 (correlation with itself)</span>\n    np<span class="token punctuation">.</span>fill_diagonal<span class="token punctuation">(</span>P<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>\n    <span class="token keyword">return</span> P\n\n<span class="token comment"># Example usage</span>\n<span class="token comment"># Suppose we have columns: [exercise_frequency, blood_pressure, age, ...]</span>\ndata <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>\npcorr <span class="token operator">=</span> partial_correlation<span class="token punctuation">(</span>data<span class="token punctuation">)</span>\n<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Partial correlation matrix:\\n"</span><span class="token punctuation">,</span> pcorr<span class="token punctuation">)</span></code></pre></div>'}}),"\n",s.createElement(n.h2,{id:"the-likelihood-function",style:{position:"relative"}},s.createElement(n.a,{href:"#the-likelihood-function","aria-label":"the likelihood function permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"The likelihood function"),"\n",s.createElement(n.h3,{id:"definition-and-role-in-statistical-modeling-parameter-estimation",style:{position:"relative"}},s.createElement(n.a,{href:"#definition-and-role-in-statistical-modeling-parameter-estimation","aria-label":"definition and role in statistical modeling parameter estimation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Definition and role in statistical modeling, parameter estimation"),"\n",s.createElement(n.p,null,"In ",s.createElement(l.A,null,"statistical modeling"),", the ",s.createElement(l.A,null,"likelihood function")," expresses how likely the observed data are, given a set of parameters and an assumed model. Formally, if we have observations ",s.createElement(o.A,{text:"\\(x_1, x_2, \\dots, x_n\\)"})," and a statistical model with parameter ",s.createElement(o.A,{text:"\\(\\theta\\)"})," (which could be a scalar or vector), the likelihood is:"),"\n",s.createElement(o.A,{text:"\\( \\mathcal{L}(\\theta) = p(x_1, x_2, \\dots, x_n \\mid \\theta), \\)"}),"\n",s.createElement(n.p,null,"where ",s.createElement(o.A,{text:"\\(p(\\cdot \\mid \\theta)\\)"})," denotes the probability (or probability density) of the data under the parameter ",s.createElement(o.A,{text:"\\(\\theta\\)"}),". In practice, we often work with the ",s.createElement(l.A,null,"log-likelihood"),":"),"\n",s.createElement(o.A,{text:"\\( \\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^n \\log p(x_i \\mid \\theta). \\)"}),"\n",s.createElement(n.p,null,"Maximizing the log-likelihood (MLE: maximum likelihood estimation) is usually more convenient than maximizing ",s.createElement(o.A,{text:"\\(\\mathcal{L}(\\theta)\\)"})," directly, thanks to the property that the logarithm is a strictly increasing function. This leads to simpler sums (rather than products)."),"\n",s.createElement(n.h3,{id:"relationship-to-probability-and-inference-examples-of-likelihood-in-machine-learning-models",style:{position:"relative"}},s.createElement(n.a,{href:"#relationship-to-probability-and-inference-examples-of-likelihood-in-machine-learning-models","aria-label":"relationship to probability and inference examples of likelihood in machine learning models permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Relationship to probability and inference; examples of likelihood in machine learning models"),"\n",s.createElement(n.p,null,"The likelihood is closely tied to the idea of fitting a parameterized probability distribution to observed data. In parametric ",s.createElement(l.A,null,"machine learning"),", consider a logistic regression model:"),"\n",s.createElement(o.A,{text:"\\[\nP(y=1 \\mid x; \\theta) = \\sigma(\\theta^\\top x),\n\\]"}),"\n",s.createElement(n.p,null,"where ",s.createElement(o.A,{text:"\\(\\sigma(\\cdot)\\)"})," is the sigmoid function. We can interpret ",s.createElement(o.A,{text:"\\(\\theta\\)"})," as the parameters that maximize the likelihood of the observed labels ",s.createElement(o.A,{text:"\\(y\\)"}),". This concept generalizes to many models: from Gaussian mixture models to neural networks trained by minimizing cross-entropy (which can be derived as a negative log-likelihood)."),"\n",s.createElement(n.p,null,"Likelihood-based approaches also form the foundation for Bayesian methods, where we combine likelihood with a prior distribution to obtain a posterior via Bayes' theorem."),"\n",s.createElement(n.h2,{id:"mle-and-map",style:{position:"relative"}},s.createElement(n.a,{href:"#mle-and-map","aria-label":"mle and map permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"MLE and MAP"),"\n",s.createElement(n.p,null,"We introduced ",s.createElement(l.A,null,"maximum likelihood estimation (MLE)")," as a strategy to choose parameters ",s.createElement(o.A,{text:"\\(\\theta\\)"})," that maximize ",s.createElement(o.A,{text:"\\(p(x \\mid \\theta)\\)"}),". However, in a ",s.createElement(l.A,null,"Bayesian")," framework, we incorporate a prior distribution ",s.createElement(o.A,{text:"\\(p(\\theta)\\)"})," over parameters and update this belief in light of new data. This yields the posterior distribution:"),"\n",s.createElement(o.A,{text:"\\( p(\\theta \\mid x) \\propto p(x \\mid \\theta)\\, p(\\theta). \\)"}),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"MLE"),":","\n",s.createElement(o.A,{text:"\\( \\hat{\\theta}_{\\text{MLE}} = \\mathrm{argmax}_{\\theta} \\, p(x \\mid \\theta). \\)"}),"\n"),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"MAP (Maximum A Posteriori)"),":","\n",s.createElement(o.A,{text:"\\( \\hat{\\theta}_{\\text{MAP}} = \\mathrm{argmax}_{\\theta} \\, p(\\theta \\mid x) \\propto \\mathrm{argmax}_{\\theta} \\, p(x \\mid \\theta)\\, p(\\theta). \\)"}),"\n"),"\n"),"\n",s.createElement(n.p,null,"The ",s.createElement(l.A,null,"MAP")," estimator effectively combines observed data (likelihood) with prior knowledge or beliefs (the prior). When the prior is uninformative (uniform), MAP and MLE coincide. But with informative priors, MAP often yields parameter estimates that incorporate domain expertise or regularization-like effects."),"\n",s.createElement(n.h2,{id:"confidence-intervals",style:{position:"relative"}},s.createElement(n.a,{href:"#confidence-intervals","aria-label":"confidence intervals permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Confidence intervals"),"\n",s.createElement(n.h3,{id:"definition-of-confidence-interval-constructing-confidence-intervals",style:{position:"relative"}},s.createElement(n.a,{href:"#definition-of-confidence-interval-constructing-confidence-intervals","aria-label":"definition of confidence interval constructing confidence intervals permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Definition of confidence interval, constructing confidence intervals"),"\n",s.createElement(n.p,null,"A ",s.createElement(l.A,null,"confidence interval (CI)")," gives a range of plausible values for a population parameter based on sample data. A ",s.createElement(l.A,null,"95% confidence interval"),", for example, is often constructed so that if we were to repeat the sampling process many times, about 95% of such intervals would contain the true parameter value. One standard construction for a mean with a large sample size (and an approximately normal sample mean) is:"),"\n",s.createElement(o.A,{text:"\\( \\bar{x} \\pm z_{\\alpha/2} \\frac{s}{\\sqrt{n}}, \\)"}),"\n",s.createElement(n.p,null,"where:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(\\bar{x}\\)"})," is the sample mean."),"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(s\\)"})," is the sample standard deviation."),"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(n\\)"})," is the sample size."),"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(z_{\\alpha/2}\\)"})," is the critical value from the standard normal distribution (e.g., 1.96 for 95% confidence)."),"\n"),"\n",s.createElement(n.h3,{id:"interpreting-confidence-intervals",style:{position:"relative"}},s.createElement(n.a,{href:"#interpreting-confidence-intervals","aria-label":"interpreting confidence intervals permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Interpreting confidence intervals"),"\n",s.createElement(n.p,null,'A frequent misinterpretation is: "There is a 95% probability the true mean lies in this interval." Strictly speaking, in frequentist terms, the true mean is a fixed quantity. The correct interpretation is: "With repeated sampling and interval construction, 95% of those intervals would contain the true mean."'),"\n",s.createElement(n.p,null,"In practice, we use confidence intervals to convey the uncertainty around an estimate. Narrow intervals indicate higher precision (often due to a larger sample size or lower variability), whereas wide intervals indicate less precision."),"\n",s.createElement(n.h3,{id:"bootstrap-confidence-intervals",style:{position:"relative"}},s.createElement(n.a,{href:"#bootstrap-confidence-intervals","aria-label":"bootstrap confidence intervals permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Bootstrap Confidence Intervals"),"\n",s.createElement(n.p,null,"While a simple confidence interval for the mean often uses a normal approximation, ",s.createElement(l.A,null,"bootstrap confidence intervals")," are more flexible and can be applied to many statistics (medians, proportions, correlation coefficients, etc.). The procedure is:"),"\n",s.createElement(n.ol,null,"\n",s.createElement(n.li,null,"Draw a bootstrap sample (of the same size as the original) ",s.createElement(n.strong,null,"with replacement"),"."),"\n",s.createElement(n.li,null,"Compute the statistic of interest (e.g., sample mean) for this bootstrap sample."),"\n",s.createElement(n.li,null,"Repeat steps 1–2 many times (e.g., 1,000 or 10,000 replicates)."),"\n",s.createElement(n.li,null,"Use the distribution of the bootstrap replicates to form a confidence interval (e.g., the 2.5th and 97.5th percentiles for a 95% CI)."),"\n"),"\n",s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np\n\n<span class="token keyword">def</span> <span class="token function">bootstrap_ci</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> func<span class="token operator">=</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> n_boot<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token triple-quoted-string string">"""Compute a bootstrap confidence interval for func(data)."""</span>\n    stats <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>\n    n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>\n    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_boot<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        sample <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>data<span class="token punctuation">,</span> size<span class="token operator">=</span>n<span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>\n        stats<span class="token punctuation">.</span>append<span class="token punctuation">(</span>func<span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">)</span>\n    \n    stats <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>stats<span class="token punctuation">)</span>\n    lower_bound <span class="token operator">=</span> np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>stats<span class="token punctuation">,</span> <span class="token number">100</span><span class="token operator">*</span><span class="token punctuation">(</span>alpha<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n    upper_bound <span class="token operator">=</span> np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>stats<span class="token punctuation">,</span> <span class="token number">100</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n    <span class="token keyword">return</span> lower_bound<span class="token punctuation">,</span> upper_bound\n\n<span class="token comment"># Example usage</span>\nsamples <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>\nci <span class="token operator">=</span> bootstrap_ci<span class="token punctuation">(</span>samples<span class="token punctuation">,</span> func<span class="token operator">=</span>np<span class="token punctuation">.</span>median<span class="token punctuation">)</span>\n<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Bootstrap 95% CI for the median: </span><span class="token interpolation"><span class="token punctuation">{</span>ci<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></code></pre></div>'}}),"\n",s.createElement(n.p,null,"Bootstrap methods can be adapted for various estimators and provide more accurate intervals when parametric assumptions (e.g., normality) are questionable."),"\n",s.createElement(n.h2,{id:"quantiles",style:{position:"relative"}},s.createElement(n.a,{href:"#quantiles","aria-label":"quantiles permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Quantiles"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Quantiles")," partition data into segments based on rank order. The median is a special case (the 50th percentile). More generally:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Quartiles"),": Split the data into four parts (Q1 is the 25th percentile, Q2 is the 50th, Q3 is the 75th)."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Percentiles"),": Split the data into 100 equal parts; the ",s.createElement(o.A,{text:"\\(k\\)"}),"th percentile is the value at or below which ",s.createElement(o.A,{text:"\\(k\\)"}),"% of the observations lie."),"\n"),"\n",s.createElement(n.h3,{id:"definition-median-quartiles-percentiles-etc",style:{position:"relative"}},s.createElement(n.a,{href:"#definition-median-quartiles-percentiles-etc","aria-label":"definition median quartiles percentiles etc permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Definition (median, quartiles, percentiles, etc.)"),"\n",s.createElement(n.p,null,"Formally, the ",s.createElement(o.A,{text:"\\(\\alpha\\)"}),"-quantile ",s.createElement(o.A,{text:"\\(q_\\alpha\\)"})," of a distribution is the value such that:"),"\n",s.createElement(o.A,{text:"\\( P(X \\le q_\\alpha) = \\alpha. \\)"}),"\n",s.createElement(n.p,null,"For empirical data, we often approximate quantiles by sorting observations and finding the point(s) in the sorted list that correspond to the fraction ",s.createElement(o.A,{text:"\\(\\alpha\\)"}),"."),"\n",s.createElement(n.h3,{id:"uses-in-data-analysis",style:{position:"relative"}},s.createElement(n.a,{href:"#uses-in-data-analysis","aria-label":"uses in data analysis permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Uses in data analysis"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Detecting skewness"),": If the median differs significantly from the mean, it might indicate a skew."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Examining outliers"),": The 5th and 95th (or 1st and 99th) percentiles often highlight the tails of a distribution. Box plots, for instance, depict quartiles and help spot outliers."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Robust analysis"),": Median or other quantiles are less sensitive to outliers than the mean."),"\n"),"\n",s.createElement(n.h3,{id:"interquantile-ranges",style:{position:"relative"}},s.createElement(n.a,{href:"#interquantile-ranges","aria-label":"interquantile ranges permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Interquantile Ranges"),"\n",s.createElement(n.p,null,"Beyond the standard quartiles (25%, 50%, 75%), analysts often use ",s.createElement(n.strong,null,"interquantile ranges"),' (e.g., the 10%–90% range) to focus on the "core" portion of the data. This can be particularly informative for skewed distributions or distributions with heavy tails, where a large portion of the data may lie in some lower percentile range.'),"\n",s.createElement(n.h3,{id:"quantile-regression",style:{position:"relative"}},s.createElement(n.a,{href:"#quantile-regression","aria-label":"quantile regression permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Quantile Regression"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Quantile regression")," allows you to model specific quantiles (e.g., the median or 90th percentile) of the response variable rather than the mean. This is extremely useful in fields such as finance or economics, where you might care about worst-case (upper quantile) or best-case (lower quantile) scenarios, not just the average outcome."),"\n",s.createElement(n.h2,{id:"density-estimation",style:{position:"relative"}},s.createElement(n.a,{href:"#density-estimation","aria-label":"density estimation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Density estimation"),"\n",s.createElement(n.p,null,s.createElement(l.A,null,"Density estimation")," is about constructing an estimate of the probability density function (pdf) from observed data. Unlike parametric approaches (e.g., fitting a normal distribution), non-parametric density estimation makes fewer assumptions about the shape of the distribution."),"\n",s.createElement(n.h3,{id:"kernel-density-estimation",style:{position:"relative"}},s.createElement(n.a,{href:"#kernel-density-estimation","aria-label":"kernel density estimation permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Kernel density estimation"),"\n",s.createElement(n.p,null,"A popular non-parametric approach is ",s.createElement(l.A,null,"kernel density estimation (KDE)"),". Given data points ",s.createElement(o.A,{text:"\\(x_1, x_2, \\dots, x_n\\)"}),", the KDE at a point ",s.createElement(o.A,{text:"\\(x\\)"})," is often defined as:"),"\n",s.createElement(o.A,{text:"\\[\n\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^n K\\left(\\frac{x - x_i}{h}\\right),\n\\]"}),"\n",s.createElement(n.p,null,"where:"),"\n",s.createElement(n.ul,null,"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(K\\)"})," is a kernel function (e.g., Gaussian kernel)."),"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(h\\)"})," is the bandwidth (smoothing parameter)."),"\n",s.createElement(n.li,null,s.createElement(o.A,{text:"\\(n\\)"})," is the number of data points."),"\n"),"\n",s.createElement(n.p,null,"The kernel function ",s.createElement(o.A,{text:"\\(K(\\cdot)\\)"})," weights the contribution of observations near ",s.createElement(o.A,{text:"\\(x\\)"}),". The choice of ",s.createElement(o.A,{text:"\\(h\\)"})," greatly influences the smoothness of the estimated density. If ",s.createElement(o.A,{text:"\\(h\\)"})," is too large, the estimate is overly smooth (underfitting). If ",s.createElement(o.A,{text:"\\(h\\)"}),' is too small, the estimate is too "spiky" (overfitting to the sample points).'),"\n",s.createElement(n.h3,{id:"practical-steps-and-bandwidth-selection",style:{position:"relative"}},s.createElement(n.a,{href:"#practical-steps-and-bandwidth-selection","aria-label":"practical steps and bandwidth selection permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Practical steps and bandwidth selection"),"\n",s.createElement(n.p,null,"In practice, software libraries (e.g., ",s.createElement(l.A,null,"scikit-learn")," or ",s.createElement(l.A,null,"seaborn")," in Python) provide built-in KDE functions with sensible default bandwidth selection methods like Silverman's rule of thumb. Still, it is good to understand the trade-offs:"),"\n",s.createElement(n.ol,null,"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Rule-of-thumb methods"),": These are analytical approximations based on the standard deviation of the data and the sample size."),"\n",s.createElement(n.li,null,s.createElement(n.strong,null,"Cross-validation"),": Treat the bandwidth as a hyperparameter to be tuned by minimizing some error measure (e.g., mean integrated squared error) on a validation set."),"\n"),"\n",s.createElement(n.p,null,"Below is a simplified Python snippet illustrating KDE using ",s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">seaborn</code>'}}),":"),"\n",s.createElement(r.A,{text:'\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate some random data from a mixture of Gaussians\ndata_part1 = np.random.normal(loc=-2, scale=1, size=300)\ndata_part2 = np.random.normal(loc=3, scale=0.5, size=200)\ndata = np.concatenate([data_part1, data_part2])\n\n# Kernel Density Plot\nsns.kdeplot(data, shade=True, bw_adjust=1.0)\nplt.title("Kernel Density Estimation")\nplt.xlabel("Value")\nplt.ylabel("Density")\nplt.show()\n'}),"\n",s.createElement(t,{alt:"A KDE plot with bimodal data",path:"",caption:"An example of KDE on a bimodal dataset.",zoom:"false"}),"\n",s.createElement(n.p,null,"KDE is particularly useful for visualizing data distributions that don't necessarily fit common parametric models. In exploratory data analysis, comparing KDE plots of different groups can reveal differences in distribution shapes, medians, and tails."),"\n",s.createElement(n.h2,{id:"beyond-kde-mixture-models",style:{position:"relative"}},s.createElement(n.a,{href:"#beyond-kde-mixture-models","aria-label":"beyond kde mixture models permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Beyond KDE: mixture models"),"\n",s.createElement(n.p,null,"While ",s.createElement(l.A,null,"KDE")," is a powerful non-parametric method, many real-world distributions are well-modeled by mixtures of simpler parametric families (e.g., Gaussian mixture models).\n",s.createElement(n.strong,null,"EM Algorithm (Expectation-Maximization)")," is commonly used to fit mixture models by iteratively refining estimates of parameters (e.g., means, variances, and mixing proportions in a Gaussian mixture).\nBy comparing multiple approaches (e.g., KDE vs. mixture models), practitioners can decide which method best suits the underlying distribution and the interpretability needs of their application.\nWe'll discuss this cool method somewhere down the line in this course, but for now, let me use ChatGPT to write another summary. ",s.createElement(i.A,{sticker:"hedgehog"})),"\n",s.createElement("br"),"\n",s.createElement(n.hr),"\n",s.createElement("br"),"\n",s.createElement(n.h2,{id:"summary",style:{position:"relative"}},s.createElement(n.a,{href:"#summary","aria-label":"summary permalink",className:"anchor before"},s.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Summary"),"\n",s.createElement(n.p,null,"Now we know about:",s.createElement(n.br),"\n","☝️ ",s.createElement(n.strong,null,"Data generation (probability theory)"),": Models how data arise, describing them with distributions (discrete or continuous).",s.createElement(n.br),"\n","☝️ ",s.createElement(n.strong,null,"Data collection (sampling)"),": Acquiring representative samples to make inferences about the population.",s.createElement(n.br),"\n","☝️ ",s.createElement(n.strong,null,"Descriptive statistics"),": Summarizing data through measures like mean, median, mode, variance, and visual tools like histograms and box plots.",s.createElement(n.br),"\n","☝️ ",s.createElement(n.strong,null,"Inferential statistics"),": Drawing conclusions about the population through confidence intervals, hypothesis tests, and (soon) regression models.",s.createElement(n.br),"\n","☝️ ",s.createElement(n.strong,null,'A buzzword "machine learning"'),": Applying statistical methods and probability theory to build predictive models, measure uncertainty, and handle complex, high-dimensional data."),"\n",s.createElement(n.p,null,"We're almost ready to dive into machine learning..."))}var p=function(e){void 0===e&&(e={});const{wrapper:n}=Object.assign({},(0,a.RP)(),e.components);return n?s.createElement(n,e,s.createElement(c,e)):c(e)};var m=t(54506),h=t(88864),u=t(58481),d=t.n(u),g=t(5984),f=t(43672),v=t(27042),b=t(72031),E=t(81817),y=t(27105),k=t(17265),w=t(2043),x=t(95751),S=t(94328),_=t(80791),A=t(78137);const H=e=>{let{toc:n}=e;if(!n||!n.items)return null;return s.createElement("nav",{className:_.R},s.createElement("ul",null,n.items.map(((e,n)=>s.createElement("li",{key:n},s.createElement("a",{href:e.url,onClick:n=>((e,n)=>{e.preventDefault();const t=n.replace("#",""),a=document.getElementById(t);a&&a.scrollIntoView({behavior:"smooth",block:"start"})})(n,e.url)},e.title),e.items&&s.createElement(H,{toc:{items:e.items}}))))))};function z(e){let{data:{mdx:n,allMdx:i,allPostImages:l},children:r}=e;const{frontmatter:o,body:c,tableOfContents:p}=n,h=o.index,u=o.slug.split("/")[1],b=i.nodes.filter((e=>e.frontmatter.slug.includes(`/${u}/`))).sort(((e,n)=>e.frontmatter.index-n.frontmatter.index)),_=b.findIndex((e=>e.frontmatter.index===h)),z=b[_+1],C=b[_-1],M=o.slug.replace(/\/$/,""),T=/[^/]*$/.exec(M)[0],I=`posts/${u}/content/${T}/`,{0:V,1:L}=(0,s.useState)(o.flagWideLayoutByDefault),{0:q,1:B}=(0,s.useState)(!1);var N;(0,s.useEffect)((()=>{B(!0);const e=setTimeout((()=>B(!1)),340);return()=>clearTimeout(e)}),[V]),"adventures"===u?N=k.cb:"research"===u?N=k.Qh:"thoughts"===u&&(N=k.T6);const P=d()(c).replace(/import .*? from .*?;/g,"").replace(/<.*?>/g,"").replace(/\{\/\*[\s\S]*?\*\/\}/g,"").trim().split(/\s+/).length,D=function(e){if(e<=10)return"~10 min";if(e<=20)return"~20 min";if(e<=30)return"~30 min";if(e<=40)return"~40 min";if(e<=50)return"~50 min";if(e<=60)return"~1 h";const n=Math.floor(e/60),t=e%60;return t<=30?`~${n}${t>0?".5":""} h`:`~${n+1} h`}(Math.ceil(P/N)+(o.extraReadTimeMin||0)),R=[{flag:o.flagDraft,component:()=>Promise.all([t.e(5850),t.e(9833)]).then(t.bind(t,49833))},{flag:o.flagMindfuckery,component:()=>Promise.all([t.e(5850),t.e(186)]).then(t.bind(t,27805))},{flag:o.flagRewrite,component:()=>Promise.all([t.e(5850),t.e(6535)]).then(t.bind(t,78916))},{flag:o.flagOffensive,component:()=>Promise.all([t.e(5850),t.e(4350)]).then(t.bind(t,49112))},{flag:o.flagProfane,component:()=>Promise.all([t.e(5850),t.e(955)]).then(t.bind(t,83336))},{flag:o.flagMultilingual,component:()=>Promise.all([t.e(5850),t.e(4724)]).then(t.bind(t,62343))},{flag:o.flagUnreliably,component:()=>Promise.all([t.e(5850),t.e(1627)]).then(t.bind(t,11627))},{flag:o.flagPolitical,component:()=>Promise.all([t.e(5850),t.e(6798)]).then(t.bind(t,24417))},{flag:o.flagCognitohazard,component:()=>Promise.all([t.e(5850),t.e(1050)]).then(t.bind(t,18669))},{flag:o.flagHidden,component:()=>Promise.all([t.e(5850),t.e(5743)]).then(t.bind(t,48124))}],{0:O,1:K}=(0,s.useState)([]);return(0,s.useEffect)((()=>{R.forEach((e=>{let{flag:n,component:t}=e;n&&t().then((e=>{K((n=>[].concat((0,m.A)(n),[e.default])))}))}))}),[]),s.createElement(v.P.div,{initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.15}},s.createElement(E.A,{postNumber:o.index,date:o.date,updated:o.updated,readTime:D,difficulty:o.difficultyLevel,title:o.title,desc:o.desc,banner:o.banner,section:u,postKey:T,isMindfuckery:o.flagMindfuckery,mainTag:o.mainTag}),s.createElement("div",{style:{display:"flex",justifyContent:"flex-end",flexWrap:"wrap",maxWidth:"75%",marginLeft:"auto",paddingRight:"1vw",marginTop:"-6vh",marginBottom:"4vh"}},o.otherTags.map(((e,n)=>s.createElement("span",{key:n,className:`noselect ${A.MW}`,style:{margin:"0 5px 5px 0"}},e)))),s.createElement("div",{className:"postBody"},s.createElement(H,{toc:p})),s.createElement("br",null),s.createElement("div",{style:{margin:"0 10% -2vh 30%",textAlign:"right"}},s.createElement(v.P.button,{className:`noselect ${S.pb}`,id:S.xG,onClick:()=>{L(!V)},whileTap:{scale:.93}},s.createElement(v.P.div,{className:x.DJ,key:V,initial:{opacity:0},animate:{opacity:1},exit:{opacity:0},transition:{duration:.3,ease:"easeInOut"}},V?"Switch to default layout":"Switch to wide layout"))),s.createElement("br",null),s.createElement("div",{className:"postBody",style:{margin:V?"0 -14%":"",maxWidth:V?"200%":"",transition:"margin 1s ease, max-width 1s ease, padding 1s ease"}},s.createElement("div",{className:`${S.P_} ${q?S.Xn:S.qG}`},O.map(((e,n)=>s.createElement(e,{key:n}))),o.indexCourse?s.createElement(w.A,{index:o.indexCourse,category:o.courseCategoryName}):"",s.createElement(g.Z.Provider,{value:{images:l.nodes,basePath:I.replace(/\/$/,"")+"/"}},s.createElement(a.xA,{components:{Image:f.A}},r)))),s.createElement(y.A,{nextPost:z,lastPost:C,keyCurrent:T,section:u}))}function C(e){return s.createElement(z,e,s.createElement(p,e))}function M(e){var n,t,a,i,l;let{data:r}=e;const{frontmatter:o}=r.mdx,c=o.titleSEO||o.title,p=o.titleOG||c,m=o.titleTwitter||c,u=o.descSEO||o.desc,d=o.descOG||u,g=o.descTwitter||u,f=o.schemaType||"BlogPosting",v=o.keywordsSEO,E=o.date,y=o.updated||E,k=o.imageOG||(null===(n=o.banner)||void 0===n||null===(t=n.childImageSharp)||void 0===t||null===(a=t.gatsbyImageData)||void 0===a||null===(i=a.images)||void 0===i||null===(l=i.fallback)||void 0===l?void 0:l.src),w=o.imageAltOG||d,x=o.imageTwitter||k,S=o.imageAltTwitter||g,_=o.canonicalURL,A=o.flagHidden||!1,H=o.mainTag||"Posts",z=o.slug.split("/")[1]||"posts",{siteUrl:C}=(0,h.Q)(),M={"@context":"https://schema.org","@type":"BreadcrumbList",itemListElement:[{"@type":"ListItem",position:1,name:"Home",item:C},{"@type":"ListItem",position:2,name:H,item:`${C}/${o.slug.split("/")[1]}`},{"@type":"ListItem",position:3,name:c,item:`${C}${o.slug}`}]};return s.createElement(b.A,{title:c+" - avrtt.blog",titleOG:p,titleTwitter:m,description:u,descriptionOG:d,descriptionTwitter:g,schemaType:f,keywords:v,datePublished:E,dateModified:y,imageOG:k,imageAltOG:w,imageTwitter:x,imageAltTwitter:S,canonicalUrl:_,flagHidden:A,mainTag:H,section:z,type:"article"},s.createElement("script",{type:"application/ld+json"},JSON.stringify(M)))}},90548:function(e,n,t){var a=t(96540),s=t(7978);n.A=e=>{let{text:n}=e;return a.createElement(s.A,null,n)}}}]);
//# sourceMappingURL=component---src-templates-post-tsx-content-file-path-src-pages-posts-research-non-boring-intro-to-statistics-2-mdx-db0f02ff066aeab98701.js.map