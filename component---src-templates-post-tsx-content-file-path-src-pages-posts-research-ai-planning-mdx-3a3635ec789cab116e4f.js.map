{"version":3,"file":"component---src-templates-post-tsx-content-file-path-src-pages-posts-research-ai-planning-mdx-3a3635ec789cab116e4f.js","mappings":"kRAwKA,SAASA,EAAkBC,GACzB,MAAMC,EAAcC,OAAOC,OAAO,CAChCC,EAAG,IACHC,GAAI,KACJC,EAAG,IACHC,KAAM,OACNC,GAAI,KACJC,GAAI,KACJC,OAAQ,SACRC,GAAI,KACJC,GAAI,KACJC,GAAI,OACHC,EAAAA,EAAAA,MAAsBd,EAAMe,aAAa,MAACC,GAASf,EAEtD,OADKe,GAizBP,SAA8BC,EAAIC,GAChC,MAAM,IAAIC,MAAM,aAAeD,EAAY,YAAc,UAAY,KAAOD,EAAK,qEACnF,CAnzBcG,CAAqB,SAAS,GACnCC,EAAAA,cAAoBA,EAAAA,SAAgB,KAAM,KAAMA,EAAAA,cAAoB,MAAO,KAAM,KAAM,KAAMA,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,umBAAwmB,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC7xBY,GAAI,kCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,mCACN,aAAc,4CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,mCAAoC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2wBAA4wB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qnBAAsnB,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACjjDY,GAAI,uCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wCACN,aAAc,iDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+jBAAgkB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,iGAAkG,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mCAAoC,uHAAwH,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,2BAA4B,6FAA8F,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,0EAA2E,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gCAAiC,kHAAmH,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0VAA2V,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACppEY,GAAI,oDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qDACN,aAAc,8DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,uDAAwD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0vBAA6vB,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,soBAAyoB,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACzkDY,GAAI,uDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wDACN,aAAc,iEACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,yDAA0D,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2EAA4EiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,KAAMW,EAAAA,cAAoBO,EAAAA,EAAW,KAAM,8CAA+C,ohBAAqhB,KAAMP,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2ZAA4ZiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,QAAS,KAAMW,EAAAA,cAAoBO,EAAAA,EAAW,KAAM,uCAAwC,MAAO,KAAMP,EAAAA,cAAoBpB,EAAYI,GAAI,CACt+CY,GAAI,2CACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,4CACN,aAAc,qDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,4CAA6C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kIAAmI,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0CAA2C,mMAAoM,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qFAAsF,6JAA8J,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0EAA2E,sQAAuQ,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4CAA6C,uNAAwN,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACrvDY,GAAI,uCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wCACN,aAAc,iDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+TAAgUiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qBAAsB,iTAAkT,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC3zBY,GAAI,+BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,gCACN,aAAc,yCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,gCAAiC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8EAA+E,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qDAAsD,2HAA4H,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,kEAAmE,6JAA8J,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+DAAgE,4NAA6N,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+IAAgJ,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CAC54CM,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CAC/EY,GAAI,mCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,oCACN,aAAc,6CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,oCAAqC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4GAA+G,KAAMiB,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,oBAAqB,mEAAoE,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,iBAAkB,4DAA6D,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,sEAAuE,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,YAAa,mEAAoE,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8EAA+E,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,6BAA8BY,EAAAA,cAAoBQ,EAAAA,EAAO,CACvtCC,KAAM,gBACJ,KAAM,KAAMT,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,uKAAwK,KAAMY,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,oEAAqE,KAAMY,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,qFAAsFY,EAAAA,cAAoBQ,EAAAA,EAAO,CACtfC,KAAM,gBACJ,2DAA4D,MAAO,KAAMT,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kFAAmFiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,cAAe,6HAA8HW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,WAAY,mSAAoS,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC1wBY,GAAI,2BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,4BACN,aAAc,qCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,4BAA6B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0DAA2D,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,4IAA6I,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,qBAAsB,KAAMW,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,iBAAkB,6EAA8E,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,WAAY,qLAA0L,MAAO,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,SAAU,oFAAqF,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,SAAU,sGAAuG,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gCAAiCiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+BAAgC,2EAA4EW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,8BAA+B,kMAAmM,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oGAAqG,KAAMiB,EAAAA,cAAoBQ,EAAAA,EAAO,CAC9pEC,KAAM,oJACJ,KAAMT,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,SAAUiB,EAAAA,cAAoBQ,EAAAA,EAAO,CACtFC,KAAM,cACJ,uEAAwET,EAAAA,cAAoBQ,EAAAA,EAAO,CACrGC,KAAM,cACJ,+DAAgET,EAAAA,cAAoBQ,EAAAA,EAAO,CAC7FC,KAAM,cACJ,iDAAkD,KAAMT,EAAAA,cAAoBpB,EAAYU,GAAI,CAC9FM,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CAC/EY,GAAI,iCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,kCACN,aAAc,2CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,kCAAmC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0DAA2DiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,sBAAuB,6aAA8a,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qBAAsBiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gCAAiC,OAAQW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gCAAiC,KAAM,KAAMW,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,kBAAmB,8LAA+L,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,sNAAuN,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+NAAgO,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC71DY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,uCAAwC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,sDAAuDiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,uaAAwa,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gDAAiD,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,uNAAwN,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,4JAA6J,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qBAAsB,gFAAiF,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gTAAiT,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC37DY,GAAI,wCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,yCACN,aAAc,kDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,yCAA0C,KAAMN,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,0GAA2G,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,aAAc,6TAAgU,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mCAAoC,sKAAuK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,sBAAuB,4WAA6W,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACviDY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mKAAoKiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,8DAA+DW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,OAAQW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,kBAAmBW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,oHAAqH,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CAC1vBM,GAAI,0BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,2BACN,aAAc,oCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,2BAA4B,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACzEY,GAAI,mCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,oCACN,aAAc,6CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,oCAAqC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mFAAoFiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,cAAe,6DAA8DW,EAAAA,cAAoBQ,EAAAA,EAAO,CACjUC,KAAM,eACJ,6QAA8Q,KAAMT,EAAAA,cAAoBpB,EAAYI,GAAI,CAC1TY,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oCAAqCiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,oBAAqB,8VAAiW,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACvkBY,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6UAA8UiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,oBAAqB,sGAAuG,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+GAAgHiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,wOAAyO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAChkCY,GAAI,iCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,kCACN,aAAc,2CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,kCAAmC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+CAAgD,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+BAAgC,mJAAoJ,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,6BAA8B,mOAAsO,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qBAAsB,sLAAuL,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,iCAAkC,yLAA0L,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2DAA4DiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,sBAAuB,mLAAoL,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CACnyDM,GAAI,wBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,yBACN,aAAc,kCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,yBAA0B,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACvEY,GAAI,qDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,sDACN,aAAc,+DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wDAAyD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mEAAoEiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,aAAc,6BAA8BW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4CAA6C,0OAA2O,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4ZAAqa,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC7kCY,GAAI,4BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,6BACN,aAAc,sCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,6BAA8B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yCAA0CiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,WAAY,sTAAuT,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mBAAoBiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,QAAS,8CAA+CW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,SAAU,gOAAiO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACv9BY,GAAI,6BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,8BACN,aAAc,uCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,8BAA+B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6DAA8D,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,sBAAuB,iEAAkE,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,2HAA4H,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,YAAa,0GAA6G,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,sNAAuN,KAAMiB,EAAAA,cAAoBpB,EAAYU,GAAI,CACnnCM,GAAI,kDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,mDACN,aAAc,4DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,mDAAoD,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACjGY,GAAI,iCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,kCACN,aAAc,2CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,kCAAmC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gGAAiGiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4BAA6B,wQAAyQ,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACpjBY,GAAI,sBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,uBACN,aAAc,gCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,uBAAwB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,0EAA2EW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uFAAwF,gXAAiX,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC5vBY,GAAI,kCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,mCACN,aAAc,4CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,OAAQW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,2TAA4T,KAAMW,EAAAA,cAAoBQ,EAAAA,EAAO,CAC1kBC,KAAM,4GACJ,KAAMT,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yHAA0H,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACrNY,GAAI,mDACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,oDACN,aAAc,6DACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,sDAAuD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yHAA0HiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wDAAyD,gKAAiKW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+BAAgC,oIAAqI,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACxuBY,GAAI,sCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,uCACN,aAAc,gDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,uCAAwC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2IAA4I,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,gJAAiJW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,cAAe,UAAW,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,+GAAgH,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mIAAoIiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0BAA2B,gHAAiH,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CACtuCM,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,mCAAoC,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACjFY,GAAI,0BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,2BACN,aAAc,oCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,2BAA4B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kEAAmEiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,QAAS,8GAA+GW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qBAAsB,+KAAgL,KAAMW,EAAAA,cAAoBQ,EAAAA,EAAO,CAC5kBC,KAAM,yGACJ,KAAMT,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uJAAwJ,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACnPY,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,cAAe,4fAA6fW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,2BAA4B,0CAA2C,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAClzBY,GAAI,+BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,gCACN,aAAc,yCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,gCAAiC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,0CAA2CiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qBAAsB,gBAAiB,KAAMW,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,kFAAmF,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,SAAU,gIAAiI,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,qQAAsQ,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC9gCY,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oDAAqDiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,2LAA4LW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,OAAQW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,yCAA0C,oCAAqC,KAAMW,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,aAAc,2CAA4C,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,yDAA0D,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0BAA2B,+DAAgE,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CACjrCM,GAAI,6BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,8BACN,aAAc,uCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,8BAA+B,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CAC5EY,GAAI,uBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wBACN,aAAc,iCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wBAAyB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAMiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,sBAAuB,oYAAqY,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC/jBY,GAAI,qCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,sCACN,aAAc,+CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,+BAAgCiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wBAAyB,+HAAgI,KAAMW,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,MAAO,4GAA6G,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,iBAAkB,6HAA8H,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,WAAY,6FAA8F,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACziCY,GAAI,kCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,mCACN,aAAc,4CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gLAAiLiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,wUAAyU,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACvrBY,GAAI,2BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,4BACN,aAAc,qCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,4BAA6B,KAAMN,EAAAA,cAAoBpB,EAAYW,GAAI,KAAM,KAAMS,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,yBAA0B,iLAAkL,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uCAAwC,sKAAuK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+BAAgC,SAAUW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4CAA6C,0MAA2M,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CACtoCM,GAAI,kCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,mCACN,aAAc,4CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,mCAAoC,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACjFY,GAAI,uCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wCACN,aAAc,iDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wCAAyC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gFAAiFiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,mBAAoB,sYAAuY,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC/pBY,GAAI,8BACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,+BACN,aAAc,wCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,+BAAgC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8CAA+C,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,8BAA+B,uNAAwN,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qCAAsC,mJAAoJ,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+CAAgD,qMAAsM,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACnqCY,GAAI,yCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,0CACN,aAAc,mDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,2CAA4C,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,8bAA+b,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACvkBY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,sCAAuC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,mgBAAogB,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CACvoBY,GAAI,wBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,yBACN,aAAc,kCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,yBAA0B,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6CAA8C,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,+CAAgD,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,oBAAqB,wCAAyC,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,gHAAiH,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,yDAA0D,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC95BY,GAAI,oBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qBACN,aAAc,8BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qBAAsB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,oCAAqCiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4CAA6C,4IAA6IW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0BAA2B,uXAAwX,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CACh0BM,GAAI,sCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,uCACN,aAAc,gDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,uCAAwC,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CACrFY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uBAAwBiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0BAA2B,qVAAsVW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,kBAAmB,mFAAoF,KAAMW,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,gaAAia,KAAMiB,EAAAA,cAAoBpB,EAAYI,GAAI,CAC9pCY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,kDAAmDiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,0BAA2B,mGAAoGW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,SAAU,4FAA6FW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,wPAAyP,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACzyBY,GAAI,uBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,wBACN,aAAc,iCACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,wBAAyB,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yKAA0KiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,iEAAkEW,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,eAAgB,wOAAyO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACvsBY,GAAI,oCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,qCACN,aAAc,8CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,qCAAsC,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,yIAA0I,KAAMiB,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,UAAW,uIAAwI,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,+BAAgC,0LAA2L,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,qCAAsC,8LAA+L,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYU,GAAI,CAChrCM,GAAI,aACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,cACN,aAAc,uBACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,cAAe,KAAMN,EAAAA,cAAoBpB,EAAYI,GAAI,CAC5DY,GAAI,gBACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iBACN,aAAc,0BACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iBAAkB,KAAMN,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,iBAAkBY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,gBAAiB,gMAAiM,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,8LAA+L,KAAMY,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,sBAAuBY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,cAAe,0IAA2I,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAM,gBAAiBY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,yIAA0I,MAAO,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CACvsCY,GAAI,yCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,0CACN,aAAc,mDACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,8CAAiD,KAAMN,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,6VAAgWiB,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,uBAAwB,wNAAyN,KAAMW,EAAAA,cAAoBpB,EAAYI,GAAI,CAC5wBY,GAAI,gCACJK,MAAO,CACLC,SAAU,aAEXF,EAAAA,cAAoBpB,EAAYK,EAAG,CACpCkB,KAAM,iCACN,aAAc,0CACdC,UAAW,iBACVJ,EAAAA,cAAoBpB,EAAYM,KAAM,CACvCmB,wBAAyB,CACvBC,OAAQ,meAEP,iCAAkC,KAAMN,EAAAA,cAAoBpB,EAAYO,GAAI,KAAM,KAAMa,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,wCAAyC,+JAAkK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,yBAA0B,6JAAgK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,kCAAmC,6JAAgK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,4CAA6C,gKAAiK,KAAMW,EAAAA,cAAoBpB,EAAYQ,GAAI,KAAMY,EAAAA,cAAoBpB,EAAYS,OAAQ,KAAM,6CAA8C,6JAA8J,MAAO,KAAMW,EAAAA,cAAoBL,EAAO,CACrjDe,IAAK,kCACLC,KAAM,GACNC,QAAS,0HACTC,KAAM,UACJ,KAAMb,EAAAA,cAAoBpB,EAAYY,IAAK,KAAMQ,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,uSAAwS,KAAMiB,EAAAA,cAAoBc,EAAAA,EAAM,CACpaL,KAAM,siEAyDJ,KAAMT,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,2bAA4b,KAAMiB,EAAAA,cAAoBpB,EAAYG,EAAG,KAAM,4NAChiB,CAKA,MAJA,SAAoBJ,QAAK,IAALA,IAAAA,EAAQ,CAAC,GAC3B,MAAOoC,QAASC,GAAanC,OAAOC,OAAO,CAAC,GAAGW,EAAAA,EAAAA,MAAsBd,EAAMe,YAC3E,OAAOsB,EAAYhB,EAAAA,cAAoBgB,EAAWrC,EAAOqB,EAAAA,cAAoBtB,EAAmBC,IAAUD,EAAkBC,EAC9H,E,gLCp8BA,MAAMsC,EAAkBC,IACtB,IAAI,IAACC,GAAOD,EACZ,IAAKC,IAAQA,EAAIC,MAAO,OAAO,KAY/B,OAAOpB,EAAAA,cAAoB,MAAO,CAChCI,UAAWiB,EAAAA,GACVrB,EAAAA,cAAoB,KAAM,KAAMmB,EAAIC,MAAME,KAAI,CAACC,EAAMC,IAAUxB,EAAAA,cAAoB,KAAM,CAC1FyB,IAAKD,GACJxB,EAAAA,cAAoB,IAAK,CAC1BG,KAAMoB,EAAKG,IACXC,QAASC,GAjBSC,EAACD,EAAGF,KACtBE,EAAEE,iBACF,MAAMC,EAAWL,EAAIM,QAAQ,IAAK,IAC5BC,EAAgBC,SAASC,eAAeJ,GAC1CE,GACFA,EAAcG,eAAe,CAC3BC,SAAU,SACVC,MAAO,SAEX,EAQcT,CAAYD,EAAGL,EAAKG,MACjCH,EAAKgB,OAAQhB,EAAKH,OAASpB,EAAAA,cAAoBiB,EAAiB,CACjEE,IAAK,CACHC,MAAOG,EAAKH,aAEV,EAED,SAASoB,EAAaC,GAC3B,IAAKC,MAAM,IAACC,EAAG,OAAEC,EAAM,cAAEC,GAAc,SAAEC,GAAYL,EACrD,MAAM,YAACM,EAAW,KAAEC,EAAI,gBAAEC,GAAmBN,EACvCnB,EAAQuB,EAAYvB,MAEpB0B,EADOH,EAAYI,KACJC,MAAM,KAAK,GAE1BC,EADQT,EAAOU,MAAMC,QAAOC,GAAQA,EAAKT,YAAYI,KAAKM,SAAS,IAAIP,QACnDQ,MAAK,CAACzE,EAAG0E,IAAM1E,EAAE8D,YAAYvB,MAAQmC,EAAEZ,YAAYvB,QACvEoC,EAAeP,EAAYQ,WAAUL,GAAQA,EAAKT,YAAYvB,QAAUA,IACxEsC,EAAWT,EAAYO,EAAe,GACtCG,EAAWV,EAAYO,EAAe,GACtCI,EAAcjB,EAAYI,KAAKnB,QAAQ,MAAO,IAC9CiC,EAAc,SAAUC,KAAKF,GAAa,GAC1CG,EAAW,SAASjB,aAAmBe,MACtC,EAAGG,EAAc,EAAGC,IAAmBC,EAAAA,EAAAA,UAASvB,EAAYwB,0BAC5D,EAAGC,EAAa,EAAGC,IAAkBH,EAAAA,EAAAA,WAAS,GASrD,IAAII,GALJC,EAAAA,EAAAA,YAAU,KACRF,GAAe,GACf,MAAMG,EAAQC,YAAW,IAAMJ,GAAe,IAAQ,KACtD,MAAO,IAAMK,aAAaF,EAAM,GAC/B,CAACR,IAEY,eAAZlB,EACFwB,EAAiBK,EAAAA,GACI,aAAZ7B,EACTwB,EAAiBM,EAAAA,GACI,aAAZ9B,IACTwB,EAAiBO,EAAAA,IAEnB,MACMC,EADgBC,IAAenC,GAAMhB,QAAQ,wBAAyB,IAAIA,QAAQ,SAAU,IAAIA,QAAQ,wBAAyB,IAAIoD,OAC3GhC,MAAM,OAAOiC,OAIvCC,EA9ER,SAAwBC,GACtB,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,UAC1B,GAAIA,GAAW,GAAI,MAAO,OAC1B,MAAMC,EAAQC,KAAKC,MAAMH,EAAU,IAC7BI,EAAYJ,EAAU,GAC5B,OAAII,GAAa,GACR,IAAIH,IAAQG,EAAY,EAAI,KAAO,OAErC,IAAIH,EAAQ,KACrB,CAiEmBI,CAHWH,KAAKI,KAAKX,EAAYR,IAChC3B,EAAY+C,kBAAoB,IAG5CC,EAAU,CAAC,CACfC,KAAMjD,EAAYkD,UAClBpG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYmD,gBAClBrG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYoD,YAClBtG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYqD,cAClBvG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYsD,YAClBxG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYuD,iBAClBzG,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYwD,eAClB1G,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAYyD,cAClB3G,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAY0D,kBAClB5G,UAAWA,IAAM,0DAChB,CACDmG,KAAMjD,EAAY2D,WAClB7G,UAAWA,IAAM,4DAEZ,EAAG8G,EAAe,EAAGC,IAAoBtC,EAAAA,EAAAA,UAAS,IAWzD,OAVAK,EAAAA,EAAAA,YAAU,KACRoB,EAAQc,SAAQC,IACd,IAAI,KAACd,EAAI,UAAEnG,GAAaiH,EACpBd,GACFnG,IAAYkH,MAAKC,IACfJ,GAAiBK,GAAQ,GAAGC,QAAOC,EAAAA,EAAAA,GAAmBF,GAAO,CAACD,EAAOI,WAAU,GAEnF,GACA,GACD,IACIpH,EAAAA,cAAoBqH,EAAAA,EAAOC,IAAK,CACrCC,QAAS,CACPC,QAAS,GAEXC,QAAS,CACPD,QAAS,GAEXE,KAAM,CACJF,QAAS,GAEXG,WAAY,CACVC,SAAU,MAEX5H,EAAAA,cAAoB6H,EAAAA,EAAY,CACjCC,WAAY/E,EAAYvB,MACxBuG,KAAMhF,EAAYgF,KAClBC,QAASjF,EAAYiF,QACrB1C,SAAUA,EACV2C,WAAYlF,EAAYmF,gBACxB3F,MAAOQ,EAAYR,MACnB4F,KAAMpF,EAAYoF,KAClBC,OAAQrF,EAAYqF,OACpBlF,QAASA,EACTmF,QAASpE,EACTqE,cAAevF,EAAYmD,gBAC3BqC,QAASxF,EAAYwF,UACnBvI,EAAAA,cAAoB,MAAO,CAC7BC,MAAO,CACLuI,QAAS,OACTC,eAAgB,WAChBC,SAAU,OACVC,SAAU,MACVC,WAAY,OACZC,aAAc,MACdC,UAAW,OACXC,aAAc,QAEfhG,EAAYiG,UAAU1H,KAAI,CAAC2H,EAAKzH,IAAUxB,EAAAA,cAAoB,OAAQ,CACvEyB,IAAKD,EACLpB,UAAW,YAAY8I,EAAAA,KACvBjJ,MAAO,CACLkJ,OAAQ,gBAETF,MAAQjJ,EAAAA,cAAoB,MAAO,CACpCI,UAAW,YACVJ,EAAAA,cAAoBiB,EAAiB,CACtCE,IAAK8B,KACFjD,EAAAA,cAAoB,KAAM,MAAOA,EAAAA,cAAoB,MAAO,CAC/DC,MAAO,CACLkJ,OAAQ,iBACRC,UAAW,UAEZpJ,EAAAA,cAAoBqH,EAAAA,EAAOgC,OAAQ,CACpCjJ,UAAW,YAAYkJ,EAAAA,KACvB1J,GAAI0J,EAAAA,GACJ3H,QAvHmB4H,KACnBlF,GAAiBD,EAAa,EAuH9BoF,SAAU,CACRC,MAAO,MAERzJ,EAAAA,cAAoBqH,EAAAA,EAAOC,IAAK,CACjClH,UAAWsJ,EAAAA,GACXjI,IAAK2C,EACLmD,QAAS,CACPC,QAAS,GAEXC,QAAS,CACPD,QAAS,GAEXE,KAAM,CACJF,QAAS,GAEXG,WAAY,CACVC,SAAU,GACV+B,KAAM,cAEPvF,EAAe,2BAA6B,2BAA4BpE,EAAAA,cAAoB,KAAM,MAAOA,EAAAA,cAAoB,MAAO,CACrII,UAAW,WACXH,MAAO,CACLkJ,OAAQ/E,EAAe,SAAW,GAClCuE,SAAUvE,EAAe,OAAS,GAClCuD,WAAY,uDAEb3H,EAAAA,cAAoB,MAAO,CAC5BI,UAAW,GAAGkJ,EAAAA,MAAuC9E,EAAc8E,EAAAA,GAAkCA,EAAAA,MACpG3C,EAAcrF,KAAI,CAACsI,EAAiBpI,IAAUxB,EAAAA,cAAoB4J,EAAiB,CACpFnI,IAAKD,MACFuB,EAAY8G,YAAc7J,EAAAA,cAAoB8J,EAAAA,EAAoB,CACrEtI,MAAOuB,EAAY8G,YACnBE,SAAUhH,EAAYiH,qBACnB,GAAIhK,EAAAA,cAAoBiK,EAAAA,EAAaC,SAAU,CAClDC,MAAO,CACLC,OAAQvH,EAAcS,MACtBa,SAAUA,EAASnC,QAAQ,MAAO,IAAM,MAEzChC,EAAAA,cAAoBqK,EAAAA,GAAa,CAClC3K,WAAY,CACVC,MAAKA,EAAAA,IAENmD,MAAc9C,EAAAA,cAAoBsK,EAAAA,EAAY,CAC/CxG,SAAUA,EACVC,SAAUA,EACVE,WAAYA,EACZf,QAASA,IAEb,CAEe,SAASqH,EAAiB5L,GACvC,OAAOqB,EAAAA,cAAoBwC,EAAc7D,EAAOqB,EAAAA,cAAoBwK,EAAqB7L,GAC3F,CACO,SAAS8L,EAAKC,GACnB,IAAIC,EAAqBC,EAAuBC,EAAwBC,EAAwBC,EAChG,IAAI,KAACrI,GAAQgI,EACb,MAAM,YAAC3H,GAAeL,EAAKC,IACrBJ,EAAQQ,EAAYiI,UAAYjI,EAAYR,MAC5C0I,EAAUlI,EAAYkI,SAAW1I,EACjC2I,EAAenI,EAAYmI,cAAgB3I,EAC3C4I,EAAcpI,EAAYqI,SAAWrI,EAAYoF,KACjDkD,EAAgBtI,EAAYuI,QAAUH,EACtCI,EAAqBxI,EAAYyI,aAAeL,EAChDM,EAAa1I,EAAY0I,YAAc,cACvCC,EAAW3I,EAAY4I,YACvBC,EAAgB7I,EAAYgF,KAC5B8D,EAAe9I,EAAYiF,SAAW4D,EACtCE,EAAU/I,EAAY+I,UAA2D,QAA9CnB,EAAsB5H,EAAYqF,cAA4C,IAAxBuC,GAA4G,QAAjEC,EAAwBD,EAAoBoB,uBAAuD,IAA1BnB,GAAiH,QAApEC,EAAyBD,EAAsBoB,uBAAwD,IAA3BnB,GAA0G,QAA5DC,EAAyBD,EAAuBT,cAA+C,IAA3BU,GAA4G,QAA9DC,EAAyBD,EAAuBmB,gBAAiD,IAA3BlB,OAAlb,EAA+dA,EAAuBmB,KAChnBC,EAAapJ,EAAYoJ,YAAcd,EACvCe,EAAerJ,EAAYqJ,cAAgBN,EAC3CO,EAAkBtJ,EAAYsJ,iBAAmBd,EACjDe,EAAevJ,EAAYwJ,aAC3B7F,EAAa3D,EAAY2D,aAAc,EACvC6B,EAAUxF,EAAYwF,SAAW,QACjCrF,EAAUH,EAAYI,KAAKC,MAAM,KAAK,IAAM,SAE5C,QAACoJ,IAAWC,EAAAA,EAAAA,KACZC,EAAiB,CACrB,WAAY,qBACZ,QAAS,iBACT,gBAAmB,CAAC,CAClB,QAAS,WACT,SAAY,EACZ,KAAQ,OACR,KAAQF,GACP,CACD,QAAS,WACT,SAAY,EACZ,KAAQjE,EACR,KAAQ,GAAGiE,KAAWzJ,EAAYI,KAAKC,MAAM,KAAK,MACjD,CACD,QAAS,WACT,SAAY,EACZ,KAAQb,EACR,KAAQ,GAAGiK,IAAUzJ,EAAYI,UAGrC,OAAOnD,EAAAA,cAAoB2M,EAAAA,EAAK,CAC9BpK,MAAOA,EAAQ,gBACf0I,QAASA,EACTC,aAAcA,EACdC,YAAaA,EACbE,cAAeA,EACfE,mBAAoBA,EACpBE,WAAYA,EACZC,SAAUA,EACVE,cAAeA,EACfC,aAAcA,EACdC,QAASA,EACTK,WAAYA,EACZC,aAAcA,EACdC,gBAAiBA,EACjBC,aAAcA,EACd5F,WAAYA,EACZ6B,QAASA,EACTrF,QAASA,EACT0J,KAzCW,WA0CV5M,EAAAA,cAAoB,SAAU,CAC/B4M,KAAM,uBACLC,KAAKC,UAAUJ,IACpB,C,iDCvSA,IALUxL,IAA2B,IAA1B,KAAET,GAAkBS,EAC7B,OACElB,EAAAA,cAACQ,EAAAA,EAAK,KAAEC,EAAa,C","sources":["webpack://avrtt.blog/./src/pages/posts/research/ai_planning.mdx","webpack://avrtt.blog/./src/templates/post.tsx","webpack://avrtt.blog/./src/components/Latex/index.tsx"],"sourcesContent":["/*@jsxRuntime classic @jsx React.createElement @jsxFrag React.Fragment*/\n/**(intro: a quote, catchphrase, joke, etc.)**/\n/*\n\nArtificial Intelligence: A Modern Approach, Global Edition, 4ed: 11. Automated Planning\n\n*/\n/*\n\n1. Introduction\n- Motivation and Role of Planning\n- Why planning is a core problem in AI\n- Differences between search, planning, and reasoning\n- Historical context: STRIPS and early planning systems\n- Connection to Other Topics in the Series\n- Relationship to AI search and AI logic\n- Planning as a bridge between theory (logic) and practice (acting in environments)\n- Relationship to prior topics: search (as planning often involves state-space search) and logic (for representing actions, preconditions, effects)\n- The role of planning in bridging reasoning with action execution\n- Planning in the Broader AI Landscape\n- From classical symbolic planners to modern automated planning systems\n- Hybrid approaches integrating planning with machine learning\n- Key Questions in AI Planning\n- How to model goals, actions, and states formally\n- Balancing expressiveness with computational tractability\n- Addressing uncertainty, time, and resource constraints\n2. Foundations of Planning in AI\n- Definition of Classical Planning\n- \"Classical\" assumptions (fully observable, deterministic, static environments)\n- Planning vs. scheduling vs. control: clarifying boundaries\n- Planning Representations\n- States, actions (operators), goals, and plans\n- State-space vs. plan-space representations\n- STRIPS-like formalisms (preconditions, effects)\n3. Classical Planning Algorithms\n- State-Space Search in Planning\n- Forward (progression) search vs. backward (regression) search\n- Key differences from typical graph search algorithms in AI search\n- Partial-Order (Plan-Space) Planning\n- Concepts of concurrency and partial ordering of actions\n- Advantages over strictly sequential (linear) planners\n- Notable Classical Planning Algorithms\n- STRIPS-based methods\n- GraphPlan and planning graphs (brief introduction; detailed in heuristics)\n- Progression/Regression planners\n- SAT-based planning\n- Limitations of Classical Planning\n- Scalability issues in large state spaces\n- Inability to handle uncertainty or continuous time\n4. Heuristics for Planning\n- Rationale for Heuristic Planning\n- Limitations of blind (uninformed) planning methods\n- Importance of domain-independent vs. domain-dependent heuristics\n- Automated Planning Heuristics\n(Introductory discussion of why heuristics are needed; details below.)\n- Planning Graphs and GraphPlan\n- Construction of a planning graph\n- Extraction of plans from the graph (backward search on levels)\n- Relationship between GraphPlan's planning graph and heuristic generation\n- Designing Effective Heuristics\n- Relaxation-based heuristics (e.g., ignoring delete effects)\n- Landmark-based heuristics (critical milestones toward the goal)\n- Pattern databases (precomputed subproblem solutions)\n- Admissibility and Consistency (trade-offs between heuristic accuracy and computation)\n- Examples (e.g., Manhattan distance in grid worlds, relaxed plan heuristics)\n5. Hierarchical Planning\n- Overview of Hierarchical Task Network (HTN) Planning\n- Breaking complex tasks into subtasks\n- Abstraction levels: high-level tasks vs. primitive actions\n- Advantages in complex, real-world domains (robotics, enterprise workflows)\n- Algorithms and Formalisms\n- Methods for decomposing tasks\n- Handling constraints across multiple abstraction layers\n- Applications and Use Cases\n- Project management, multi-step manufacturing, game AI scripts\n- Risks of abstraction: incomplete or incorrect task decompositions\n6. Planning and Acting in Nondeterministic Domains\n- Nondeterminism and Uncertainty\n- Why real-world domains often break classical assumptions\n- Expressiveness needed to capture nondeterministic actions\n- Conformant Planning\n- Planning when the initial state or action outcomes are partially unknown\n- Ensuring success despite limited sensing capabilities\n- Contingent (Conditional) Planning\n- Branching plans with conditional actions\n- Sensing actions and dynamic observation of the environment\n- Relationship to Partially Observable MDPs (POMDPs)\n- When planning merges with probabilistic reasoning and RL\n- Replanning and Execution Monitoring\n- Online planning with real-time feedback (replanning upon failure)\n- Probabilistic planning with belief states\n7. Time, Scheduling, and Resources\n- Time-Dependent Planning\n- Extending classical planning to handle temporal constraints\n- Representing durations, deadlines, and concurrent actions\n- Scheduling and Resource Allocation\n- Integrating scheduling techniques within planning\n- Constraint-based scheduling (CSP approaches)\n- Real-world complexities (multiple agents, shared resources)\n- Temporal Planning Algorithms\n- Time modeling approaches: discrete vs. continuous\n- Differences between classical and temporal planners (e.g., TPLAN, OPTIC)\n- Resource-Constrained Planning\n- Managing finite resources (fuel, money, bandwidth)\n- Integration with scheduling algorithms (e.g., job-shop scheduling)\n8. Automated Planning Systems\n- Definition and Scope\n- Automated vs. manual or semi-automated planning\n- Domain-independent planners vs. domain-specific planners\n- Planning Algorithms and Frameworks\n- AI Planning toolkits (e.g., PDDL-based systems)\n- Popular planners (FF, Fast Downward, SATPLAN)\n- Automated Planning Heuristics\n- Heuristic engines powering domain-independent planners\n- Evolution of heuristics (relaxed planning graphs, critical path methods)\n- Practical Considerations\n- Knowledge engineering: representing the domain (in PDDL or other formalisms)\n- Scalability and runtime performance\n- Benchmarks (IPC: International Planning Competition) and measuring performance\n9. Analysis of Planning Approaches\n- Computational Complexity in Planning\n- PSPACE-completeness (classical results)\n- Hardness results and practical implications\n- Trade-offs Among Approaches\n- State-space vs. plan-space vs. hierarchical vs. graph-based\n- Strengths, weaknesses, typical domain suitability\n- Heuristic Accuracy vs. Computation Time\n- Balancing search time with heuristic quality\n- When domain-specific heuristics can drastically improve performance\n- Empirical vs. Theoretical Analysis\n- Case studies from known planners\n- Domains that highlight algorithmic strengths and weaknesses\n- Empirical Comparisons\n- Benchmark domains (e.g., Blocks World, Logistics, Rover Navigation)\n- Metrics: plan quality, time-to-solution, memory usage\n- Hybrid Approaches\n- Integrating planning with machine learning (e.g., learned transition models)\n- Neurosymbolic planning: combining logic with neural networks\n10. Future Directions and Open Problems\n- Integrating Learning and Planning\n- Reinforcement Learning meets classical planning\n- Learning heuristics or domain models automatically\n- Probabilistic and Hybrid Planning\n- Combining deterministic planners with probabilistic reasoning\n- Hybrid symbolic–subsymbolic methods (neuro-symbolic planners)\n- Multi-Agent Planning\n- Coordination and negotiation of plans among agents\n- Game-theoretic aspects of joint plans\n- Ethical and Social Considerations\n- Planning for autonomous systems in safety-critical domains\n- Accountability in automated decision-making processes\n11. Conclusion\n- Key Takeaways\n- Importance of planning as a unifying concept in AI theory\n- Connection to AI search, logic, and reasoning\n- Links to the Next Article (\"AI Reasoning\")\n- How reasoning about plans transitions into broader forms of logical or probabilistic inference\n- Overlap with knowledge representation and inference systems\n- Further Reading and Resources\n- Core planning textbooks and seminal papers\n- Online courses, competitions (IPC), and research challenges\n\n*/\nimport {useMDXComponents as _provideComponents} from \"@mdx-js/react\";\nimport React from \"react\";\nimport Highlight from \"../../../components/Highlight\";\nimport Code from \"../../../components/Code\";\nimport Latex from \"../../../components/Latex\";\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    h3: \"h3\",\n    a: \"a\",\n    span: \"span\",\n    ul: \"ul\",\n    li: \"li\",\n    strong: \"strong\",\n    h2: \"h2\",\n    ol: \"ol\",\n    hr: \"hr\"\n  }, _provideComponents(), props.components), {Image} = _components;\n  if (!Image) _missingMdxReference(\"Image\", true);\n  return React.createElement(React.Fragment, null, \"\\n\", React.createElement(\"br\"), \"\\n\", \"\\n\", \"\\n\", React.createElement(_components.p, null, \"I want to begin by painting a broad picture of what AI planning is and why it is such a crucial pillar in the domain of artificial intelligence. When discussing AI in practical contexts — for instance, a robot's ability to execute a series of tasks in a dynamic environment, or an automated system's capacity to decide on the optimal sequence of actions to achieve a given goal — one inevitably encounters the concept of \\\"planning\\\". Planning lies at the heart of many core AI applications, encompassing everything from robotics to complex workflow management systems, and from game AI to logistics scheduling.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"motivation-and-role-of-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#motivation-and-role-of-planning\",\n    \"aria-label\": \"motivation and role of planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Motivation and role of planning\"), \"\\n\", React.createElement(_components.p, null, \"Planning can be thought of as the process of selecting and ordering a sequence of actions that, when carried out, will achieve a specified set of goals. This idea transcends the boundaries of classical robotics: it is also relevant in business process automation, high-level strategic reasoning in games, autonomous vehicle navigation, and even in generating narratives or storylines in procedural content generation. The motivation for studying planning stems from our need to act effectively in the world. In essence, we do not merely want to predict or classify situations (the realm of machine learning or general AI reasoning tasks); we also want to decide how to progress from an initial state to a desired outcome, possibly juggling multiple constraints along the way.\"), \"\\n\", React.createElement(_components.p, null, \"Planning stands apart from simpler forms of search in that we typically assume we have a set of actions — each with its own set of conditions for applicability (preconditions) and its consequences (effects) — and we want to weave these actions together in a sequence or structure that achieves a particular objective or set of objectives. It is also different from purely reactive systems, where each action is decided based purely on the current state without an overarching notion of a plan. In planning, there is an emphasis on reasoning about the future and anticipating the outcomes of actions before committing to them.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"why-planning-is-a-core-problem-in-ai\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#why-planning-is-a-core-problem-in-ai\",\n    \"aria-label\": \"why planning is a core problem in ai permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Why planning is a core problem in AI\"), \"\\n\", React.createElement(_components.p, null, \"From the early days of AI, researchers have recognized that effectively planning sequences of actions in real or simulated environments is a major challenge that intersects with several other subfields. For one, it intersects with search: one can see planning as a specialized kind of search in the space of possible action sequences or states. It also intersects with logic, because many classical planning frameworks rely on symbolic representations of states, actions, and goals, allowing for logically rigorous ways to express constraints, preconditions, and effects.\"), \"\\n\", React.createElement(_components.p, null, \"But planning is also a standalone subfield with unique challenges. It addresses questions of:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Expressiveness vs. tractability\"), \": How do we represent actions in a way that captures real-world complexities, but does not explode computationally?\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Heuristics and guidance\"), \": How can we guide the search for a plan in large or continuous state spaces efficiently?\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Uncertainty\"), \": How do we handle nondeterministic outcomes or partial observability?\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Time, resources, concurrency\"), \": Many real problems require that we plan under time constraints, with concurrency, or with limited resources.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"With the emergence of more advanced AI planning systems, the subfield remains central to bridging high-level reasoning with actual deployment of AI in real environments. Whether it is NASA planning activities for Mars rovers, or an automated system orchestrating lab experiments, planning is often the backbone that glues everything together.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"differences-between-search-planning-and-reasoning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#differences-between-search-planning-and-reasoning\",\n    \"aria-label\": \"differences between search planning and reasoning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Differences between search, planning, and reasoning\"), \"\\n\", React.createElement(_components.p, null, \"In a conventional sense, \\\"search\\\" often refers to a process of systematically exploring a set of possible configurations (often called states) in order to find a path or solution. Classic search algorithms in AI (such as breadth-first search, depth-first search, A* search, or iterative deepening search) can indeed be used for planning, particularly in small, discrete environments. However, planning problems typically introduce a richer representation of actions, frequently with logic-based descriptions of what each action does, and possibly more elaborate constraints. Furthermore, planning often requires looking beyond a simple path to a goal; it might also require concurrency (multiple actions at once), resource management, or temporal scheduling.\"), \"\\n\", React.createElement(_components.p, null, \"On the other hand, \\\"reasoning\\\" is a broader umbrella term that encompasses the process by which AI systems draw conclusions from existing knowledge, prove theorems, or perform inference over symbolic or probabilistic models. Planning is indeed a form of reasoning (it reasons about the future using abstract models of action), but many topics in reasoning (such as default logic, model checking, or knowledge-based inference) are not necessarily about deciding a sequence of actions. So you can think of planning as a specialized subdiscipline that leverages reasoning and search in synergy, typically for the purpose of goal-directed action.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"historical-context-strips-and-early-planning-systems\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#historical-context-strips-and-early-planning-systems\",\n    \"aria-label\": \"historical context strips and early planning systems permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Historical context: STRIPS and early planning systems\"), \"\\n\", React.createElement(_components.p, null, \"Historically, one of the most influential frameworks in AI planning was \", React.createElement(_components.strong, null, \"STRIPS\"), \" (\", React.createElement(Highlight, null, \"STanford Research Institute Problem Solver\"), \"), introduced by Fikes and Nilsson in 1971. STRIPS formalized the representation of planning problems with the notion of a world state described by logical predicates, and actions described in terms of preconditions and add/delete lists (what changes the action applies to the state). This framework established many of the fundamental ideas behind classical symbolic planning: define an initial state, define a goal state, define operators, and search for a sequence of operators that transition the state from initial to goal.\"), \"\\n\", React.createElement(_components.p, null, \"Early planning systems often used either forward search (starting from the initial state and applying actions) or backward search (regressing from the goal conditions back to the initial state). They suffered from combinatorial explosion, but laid the foundation for subsequent breakthroughs, such as GraphPlan, partial-order planning, heuristic-based planners, and the standardized domain language known as \", React.createElement(_components.strong, null, \"PDDL\"), \" (\", React.createElement(Highlight, null, \"Planning Domain Definition Language\"), \").\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"connection-to-other-topics-in-the-series\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#connection-to-other-topics-in-the-series\",\n    \"aria-label\": \"connection to other topics in the series permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Connection to other topics in the series\"), \"\\n\", React.createElement(_components.p, null, \"This article is part of a broader AI course, and planning intersects strongly with several of the previous or future articles:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Relationship to AI search and AI logic\"), \": We have just seen that planning heavily relies on search techniques to explore possible sequences of actions, and it also uses logic-based formalisms to describe states, actions, and goals.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Planning as a bridge between theory (logic) and practice (acting in environments)\"), \": Once we have a logical model of the world and the agent's capabilities, planning is the step where we figure out a practical strategy to achieve goals.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Relationship to prior topics (search, logic, knowledge representation)\"), \": The formalisms used in planning often revolve around symbolic representations, which tie into topics like propositional or first-order logic. Planning also has synergy with knowledge representation for describing possible states or constraints in a domain.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Bridging reasoning with action execution\"), \": Even the best plan is worthless if it cannot be executed or adapted to real-time changes. Planning thus paves the way toward integrated systems that reason about actions and actually perform them in the world.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"planning-in-the-broader-ai-landscape\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#planning-in-the-broader-ai-landscape\",\n    \"aria-label\": \"planning in the broader ai landscape permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Planning in the broader AI landscape\"), \"\\n\", React.createElement(_components.p, null, \"Planning is a microcosm of many AI challenges. Historically, planning used a strongly symbolic approach with emphasis on domain-independent solutions (as exemplified by the use of PDDL). However, in more recent years, there has been an interest in integrating planning with machine learning, leading to a variety of \", React.createElement(_components.strong, null, \"hybrid approaches\"), \" that try to learn domain models or heuristics automatically. There are also sophisticated planning systems that reason probabilistically about outcomes, or that incorporate deep neural networks (particularly in large, complicated environments like those found in robotics or advanced strategy games).\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"key-questions-in-ai-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#key-questions-in-ai-planning\",\n    \"aria-label\": \"key questions in ai planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Key questions in AI planning\"), \"\\n\", React.createElement(_components.p, null, \"As you dive deeper into planning, several key questions continually arise:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"How to model goals, actions, and states formally?\"), \" This is typically tackled by specifying a language such as PDDL, or by using an ad-hoc domain-specific representation.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"How to balance expressiveness with computational tractability?\"), \" The more expressive your planning language, the more capable your system is, but also the more computationally challenging the planning process becomes.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"How to address uncertainty, time, and resource constraints?\"), \" Real-world planning rarely fits the neat assumptions of classical planning, so advanced frameworks must handle nondeterministic actions, partial observability, real-time deadlines, concurrency, and finite resources.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"All these questions shape the evolution of planning research and drive innovations in both theoretical frameworks and practical algorithms.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"foundations-of-planning-in-ai\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#foundations-of-planning-in-ai\",\n    \"aria-label\": \"foundations of planning in ai permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Foundations of planning in AI\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"definition-of-classical-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#definition-of-classical-planning\",\n    \"aria-label\": \"definition of classical planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Definition of classical planning\"), \"\\n\", React.createElement(_components.p, null, \"\\\"Classical planning\\\" is a term used to delineate a subset of planning problems where the environment is:\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Fully observable\"), \": The agent knows the complete state of the world at all times.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Deterministic\"), \": Actions have predictable outcomes with no uncertainty.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Static\"), \": The world does not change except when the agent takes an action.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Discrete\"), \": States, actions, and time steps are modeled in discrete ways.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Under these assumptions, the planning problem can be stated succinctly as:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"You have an initial state \", React.createElement(Latex, {\n    text: \"\\\\( s_0 \\\\)\"\n  }), \".\"), \"\\n\", React.createElement(_components.li, null, \"You have a set of possible actions, each with preconditions that must be satisfied to apply the action, and effects that modify the state once the action is taken.\"), \"\\n\", React.createElement(_components.li, null, \"You have a goal state description (or a set of goal conditions).\"), \"\\n\", React.createElement(_components.li, null, \"The task is to find a finite sequence of actions that transitions the system from \", React.createElement(Latex, {\n    text: \"\\\\( s_0 \\\\)\"\n  }), \" to a state in which the goal conditions are satisfied.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"One might wonder how classical planning differs from scheduling or control. In \", React.createElement(_components.strong, null, \"scheduling\"), \", we often have a fixed set of tasks (or jobs) that need to be assigned in time or across resources with minimal cost. In \", React.createElement(_components.strong, null, \"control\"), \", we typically rely on feedback loops and real-time sensor data, especially in continuous domains (as in control theory). Classical planning sits in a slightly different space, focusing on symbolically representing and searching for a sequence of actions from an initial to a goal state.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"planning-representations\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#planning-representations\",\n    \"aria-label\": \"planning representations permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Planning representations\"), \"\\n\", React.createElement(_components.p, null, \"In classical (symbolic) planning, we usually describe:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"States\"), \": Typically sets of atomic propositions, or partial assignments to variables, that describe what is true of the world at a given moment.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Actions (operators)\"), \": Each action has:\", \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Preconditions\"), \": What must be true in the current state for the action to be applicable.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Effects\"), \": How the current state is modified. Classically, these are captured by \\\"add lists\\\" and \\\"delete lists\\\" (as in STRIPS), or by more complex conditional effects in modern variants.\"), \"\\n\"), \"\\n\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Goals\"), \": A logical condition that must be satisfied in a final state of any valid plan.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Plans\"), \": A sequence (or partial ordering) of actions that transforms the initial state into a goal state.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"We often distinguish between \", React.createElement(_components.strong, null, \"state-space representations\"), \" (where each node in a search tree corresponds to a complete state) and \", React.createElement(_components.strong, null, \"plan-space representations\"), \" (where each node in the search space is a partial plan that can be successively refined). Both approaches have their pros and cons, with different algorithms having been developed for each.\"), \"\\n\", React.createElement(_components.p, null, \"STRIPS-like formalisms remain influential: in a simplified version, each action is described as:\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\naction\\\\_name: \\npreconditions = \\\\{p_1, p_2, ...\\\\}, \\nadd\\\\_effects = \\\\{e_1, e_2, ...\\\\}, \\ndelete\\\\_effects = \\\\{d_1, d_2, ...\\\\}\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"where \", React.createElement(Latex, {\n    text: \"\\\\(p_i\\\\)\"\n  }), \" are propositions that must be true before the action can be taken, \", React.createElement(Latex, {\n    text: \"\\\\(e_i\\\\)\"\n  }), \" are propositions the action will cause to become true, and \", React.createElement(Latex, {\n    text: \"\\\\(d_i\\\\)\"\n  }), \" are propositions the action will make false.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"classical-planning-algorithms\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#classical-planning-algorithms\",\n    \"aria-label\": \"classical planning algorithms permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Classical planning algorithms\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"state-space-search-in-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#state-space-search-in-planning\",\n    \"aria-label\": \"state space search in planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"State-space search in planning\"), \"\\n\", React.createElement(_components.p, null, \"A straightforward approach to planning is to perform a \", React.createElement(_components.strong, null, \"state-space search\"), \". The idea is to define a directed graph whose nodes represent possible world states, and whose edges represent the application of an action. Since each action is only applicable if its preconditions are met, we only draw edges where the starting node (state) satisfies the action's preconditions. The search then tries to find a path from the node corresponding to the initial state to a node satisfying the goal conditions.\"), \"\\n\", React.createElement(_components.p, null, \"We can do this in \", React.createElement(_components.strong, null, \"forward (progression) search\"), \" or \", React.createElement(_components.strong, null, \"backward (regression) search\"), \":\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Forward search\"), \" starts at the initial state and moves forward by applying actions. This can branch widely if actions are widely applicable, but it is straightforward to keep track of the current state.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Backward search\"), \" starts from the goal description and tries to figure out which states and actions could have led to that goal. This can be more efficient if the goal description is narrower than the initial state description.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Such search-based approaches are conceptually simple but can be very large, and naive blind search is often infeasible for larger problems. That said, they are the foundation for more advanced algorithms and heuristics.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"partial-order-plan-space-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#partial-order-plan-space-planning\",\n    \"aria-label\": \"partial order plan space planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Partial-order (plan-space) planning\"), \"\\n\", React.createElement(_components.p, null, \"An alternative to explicitly enumerating states is \", React.createElement(_components.strong, null, \"plan-space planning\"), \" (also known as partial-order planning). Here, the search space consists of partially specified plans, not states. Instead of specifying a linear (total) order of actions from the start, we keep constraints (such as action ordering or causal links) as flexible as possible. The plan is refined step by step, adding actions or imposing ordering constraints only when needed to satisfy preconditions or prevent conflicts.\"), \"\\n\", React.createElement(_components.p, null, \"Key ideas in partial-order planning include:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Causal links\"), \": For instance, if action A produces a condition C, and action B requires condition C, then we link A to B with a causal link that states A must occur before B, and no intervening action can destroy condition C.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Open conditions\"), \": Conditions in the plan that are not yet satisfied. Refinement consists of adding actions or reusing existing actions to fulfill these open conditions.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Threat resolution\"), \": Dealing with actions that might delete conditions needed by other actions.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"Partial-order planners often produce a plan that is only partially ordered, indicating that some actions can be done concurrently or in any order that satisfies the plan's constraints. This is more general than strict linear sequences and can be advantageous in domains where concurrency is valuable.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"notable-classical-planning-algorithms\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#notable-classical-planning-algorithms\",\n    \"aria-label\": \"notable classical planning algorithms permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Notable classical planning algorithms\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"STRIPS-based methods\"), \": Early systems that directly used the STRIPS representation and performed forward or backward search.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"GraphPlan\"), \": Proposed by Blum and Furst (Proceedings of AAAI, 1995). It constructs a \\\"planning graph\\\" level by level, alternating between layers of states and layers of actions, tracking possible mutual exclusions. GraphPlan uses that structure both to guide a backward search for a valid plan and also to derive heuristics.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Progression/Regression planners\"), \": Various improvements on the straightforward forward or backward search, frequently with better heuristics or data structures for quickly checking preconditions.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"SAT-based planning\"), \": Another powerful approach encodes a bounded planning problem (looking for a plan up to some length L) as a Boolean satisfiability problem. Then, a SAT solver is used to see if a valid plan exists at that length. If not, increment L. This approach can exploit highly optimized SAT solvers and has proven surprisingly competitive for certain kinds of problems.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"limitations-of-classical-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#limitations-of-classical-planning\",\n    \"aria-label\": \"limitations of classical planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Limitations of classical planning\"), \"\\n\", React.createElement(_components.p, null, \"Classical planning focuses on deterministic, fully observable, static environments. Real environments often break these assumptions, which leads to issues with \", React.createElement(_components.strong, null, \"scalability\"), \" (the state space can be huge), and an inability to handle \", React.createElement(_components.strong, null, \"uncertainty\"), \" or \", React.createElement(_components.strong, null, \"dynamic changes\"), \". Furthermore, \", React.createElement(_components.strong, null, \"continuous variables\"), \" (time, geometry, motion, etc.) remain outside the scope of most classical planners unless specifically adapted.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"heuristics-for-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#heuristics-for-planning\",\n    \"aria-label\": \"heuristics for planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Heuristics for planning\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"rationale-for-heuristic-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#rationale-for-heuristic-planning\",\n    \"aria-label\": \"rationale for heuristic planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Rationale for heuristic planning\"), \"\\n\", React.createElement(_components.p, null, \"Given that even relatively small planning problems can explode combinatorially, \", React.createElement(_components.strong, null, \"heuristics\"), \" are critical in guiding the search. A heuristic function \", React.createElement(Latex, {\n    text: \"\\\\(h(n)\\\\)\"\n  }), \" estimates how close or far a node (or partial plan) is from the goal. In domain-independent planning, heuristics attempt to do this without hand-crafted knowledge of the domain; in domain-dependent planning, specialized knowledge can drastically reduce the search.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"automated-planning-heuristics\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#automated-planning-heuristics\",\n    \"aria-label\": \"automated planning heuristics permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Automated planning heuristics\"), \"\\n\", React.createElement(_components.p, null, \"Classical planners often rely on \", React.createElement(_components.strong, null, \"relaxation-based\"), \" heuristics. For example, ignoring the \\\"delete effects\\\" of actions is a common trick that yields an (inadmissible) but effective heuristic. The rationale is that if we never delete conditions, we can make an optimistic assumption: once a literal becomes true, it remains available for future actions, thus typically underestimating the true cost.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"planning-graphs-and-graphplan\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#planning-graphs-and-graphplan\",\n    \"aria-label\": \"planning graphs and graphplan permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Planning graphs and GraphPlan\"), \"\\n\", React.createElement(_components.p, null, \"A planning graph is a layered structure that alternates between a layer of facts (or propositions) and a layer of actions. Each proposition layer contains all propositions that could possibly be true at that step. Each action layer contains all actions that could possibly be applied given the propositions in the previous layer. \", React.createElement(_components.strong, null, \"Mutual exclusion\"), \" (mutex) relations are recorded to indicate pairs of actions or propositions that cannot co-occur.\"), \"\\n\", React.createElement(_components.p, null, \"GraphPlan (Blum and Furst, 1995) uses this planning graph both to detect potential conflicts and to guide a \", React.createElement(_components.strong, null, \"backward search\"), \" for a valid plan. The planning graph can also be used to derive effective heuristics, because the level at which a proposition first appears in the planning graph provides an estimate of how many steps are needed to achieve it.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"designing-effective-heuristics\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#designing-effective-heuristics\",\n    \"aria-label\": \"designing effective heuristics permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Designing effective heuristics\"), \"\\n\", React.createElement(_components.p, null, \"Numerous heuristic design strategies exist:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Relaxation-based heuristics\"), \": The ignoring-delete-lists heuristic is a classic example. Others might ignore certain constraints or simplify the domain in a systematic way.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Landmark-based heuristics\"), \": A \\\"landmark\\\" is a fact or action that must be achieved at some point in every valid plan. Once you identify such landmarks, you can create heuristic estimates based on how many still need to be achieved and in what order.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Pattern databases\"), \": Precompute solutions to subproblems of the planning domain (like smaller or abstracted versions), then use the lookup of partial states to get an estimate for the full problem.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Admissibility and consistency\"), \": Sometimes you need heuristics that never overestimate (admissible) or never generate conflicting estimates (consistent). This is particularly relevant if you want an optimal plan.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"A typical example in simpler grid-world planning is the \", React.createElement(_components.strong, null, \"Manhattan distance\"), \": the heuristic is the sum of the absolute differences in the x and y coordinates to a goal. In more complex planning domains, you have to craft or learn analogous heuristics.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"hierarchical-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#hierarchical-planning\",\n    \"aria-label\": \"hierarchical planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Hierarchical planning\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"overview-of-hierarchical-task-network-htn-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#overview-of-hierarchical-task-network-htn-planning\",\n    \"aria-label\": \"overview of hierarchical task network htn planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Overview of hierarchical task network (HTN) planning\"), \"\\n\", React.createElement(_components.p, null, \"When planning tasks become very complex, it is often helpful to \", React.createElement(_components.strong, null, \"decompose\"), \" them into smaller tasks. \", React.createElement(_components.strong, null, \"Hierarchical Task Network (HTN) planning\"), \" is an influential approach for such hierarchical decomposition. At its core, an HTN planner is given high-level tasks that can be expanded into networks of lower-level tasks, culminating in primitive actions that can be executed.\"), \"\\n\", React.createElement(_components.p, null, \"For instance, a high-level task might be \\\"plan a trip\\\", which can be decomposed into subtasks like \\\"book flight\\\", \\\"book hotel\\\", \\\"pack bags\\\", etc. Each subtask can further be decomposed into smaller tasks, until we reach primitive actions that we can represent in a classical planning style. This structure can significantly reduce search complexity and is often closer to how humans break down complex tasks.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"algorithms-and-formalisms\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#algorithms-and-formalisms\",\n    \"aria-label\": \"algorithms and formalisms permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Algorithms and formalisms\"), \"\\n\", React.createElement(_components.p, null, \"In HTN planning, you typically define \", React.createElement(_components.strong, null, \"methods\"), \" that describe how to decompose a high-level task into smaller tasks or subgoals. During planning, you pick a task at some abstraction level and choose a method to expand it, thereby creating new tasks in the plan. The plan is refined until it contains only primitive actions that can be executed directly.\"), \"\\n\", React.createElement(_components.p, null, \"Formalisms like \", React.createElement(_components.strong, null, \"SHOP\"), \" (Simple Hierarchical Ordered Planner) and \", React.createElement(_components.strong, null, \"SHOP2\"), \" (Nau and gang, 2003) or other related systems are commonly used to implement HTN planning. These systems handle constraints between tasks, enabling concurrency and resource constraints at multiple levels of abstraction.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"applications-and-use-cases\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#applications-and-use-cases\",\n    \"aria-label\": \"applications and use cases permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Applications and use cases\"), \"\\n\", React.createElement(_components.p, null, \"HTN planning has been broadly applied in domains such as:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Project management\"), \": Breaking down large-scale projects into tasks and subtasks.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Game AI scripts\"), \": Many modern video games use hierarchical planning or behavior trees (a related idea) to script complex NPC behaviors.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Robotics\"), \": Where tasks like \\\"fetch an object\\\" might break down into navigation, gripping, and sensing subtasks.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"A key advantage is interpretability — hierarchical plans map well to human notions of tasks and subtasks. However, hierarchical models can be brittle if the decomposition is incomplete or incorrectly specified.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"planning-and-acting-in-nondeterministic-domains\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#planning-and-acting-in-nondeterministic-domains\",\n    \"aria-label\": \"planning and acting in nondeterministic domains permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Planning and acting in nondeterministic domains\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"nondeterminism-and-uncertainty\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#nondeterminism-and-uncertainty\",\n    \"aria-label\": \"nondeterminism and uncertainty permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Nondeterminism and uncertainty\"), \"\\n\", React.createElement(_components.p, null, \"Classical planning assumes a deterministic environment, but many real-world settings involve \", React.createElement(_components.strong, null, \"nondeterministic actions\"), \" (where the outcome is not guaranteed), or partial observability (where we do not fully know the current state). If an action's effects are uncertain, or the initial state is not fully known, classical planners cannot be directly applied without modifications.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"conformant-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#conformant-planning\",\n    \"aria-label\": \"conformant planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Conformant planning\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Conformant planning\"), \" attempts to generate a sequence of actions that will achieve the goal \", React.createElement(_components.strong, null, \"no matter which of the possible initial states or action outcomes is the actual one\"), \", assuming all relevant possibilities are known. Conformant planners typically reason about sets of possible states (belief states), trying to ensure the plan leads to the goal in all these states. This can be computationally expensive, but it is essential in situations where an agent cannot observe the environment changes or has very limited sensing capability.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"contingent-conditional-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#contingent-conditional-planning\",\n    \"aria-label\": \"contingent conditional planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Contingent (conditional) planning\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Contingent planning\"), \" or \", React.createElement(_components.strong, null, \"conditional planning\"), \" introduces the notion of branching plans, where you might have an action that senses some aspect of the environment, then conditionally branch to different subplans depending on the result of that sensing. This approach requires a richer action representation that can include sensing actions and conditionals:\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\nif \\\\; sensor\\\\_reading\\\\_X = true \\\\; then \\\\; do \\\\; subplan\\\\_A ; \\\\; else \\\\; subplan\\\\_B\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"Such planners can better handle uncertainty in the environment, as they adapt the plan's execution based on feedback.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"relationship-to-partially-observable-mdps-pomdps\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#relationship-to-partially-observable-mdps-pomdps\",\n    \"aria-label\": \"relationship to partially observable mdps pomdps permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Relationship to partially observable MDPs (POMDPs)\"), \"\\n\", React.createElement(_components.p, null, \"When we incorporate probabilities into uncertain actions and partial observability, the planning problem can become a \", React.createElement(_components.strong, null, \"Partially Observable Markov Decision Process (POMDP)\"), \". Solving a POMDP yields a policy mapping belief states to actions, which is typically more computationally challenging than classical planning. Research in \", React.createElement(_components.strong, null, \"decision-theoretic planning\"), \" merges classical symbolic techniques with probabilistic or approximate methods for dealing with large or infinite state spaces.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"replanning-and-execution-monitoring\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#replanning-and-execution-monitoring\",\n    \"aria-label\": \"replanning and execution monitoring permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Replanning and execution monitoring\"), \"\\n\", React.createElement(_components.p, null, \"In practice, especially in robotics, one rarely executes a plan from start to finish without deviation. Instead, systems often utilize:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Execution monitoring\"), \": The system observes whether actions have succeeded or if the environment has changed. If the plan no longer matches reality, it triggers a \", React.createElement(_components.strong, null, \"replanning\"), \" step.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Online planning\"), \": Alternatively, plan incrementally or in small horizons, constantly updating the plan as new data arrives.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"This interplay between planning and acting in the real world is an active area of research. Some approaches unify planning with \", React.createElement(_components.strong, null, \"reinforcement learning\"), \" methods, where the agent can learn action policies that are robust to uncertainty or partial observability.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"time-scheduling-and-resources\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#time-scheduling-and-resources\",\n    \"aria-label\": \"time scheduling and resources permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Time, scheduling, and resources\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"time-dependent-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#time-dependent-planning\",\n    \"aria-label\": \"time dependent planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Time-dependent planning\"), \"\\n\", React.createElement(_components.p, null, \"Real-world applications typically require explicit handling of \", React.createElement(_components.strong, null, \"time\"), \". For instance, actions have durations, deadlines might exist, and certain actions can happen in parallel. \", React.createElement(_components.strong, null, \"Temporal planning\"), \" extends classical planning formalisms with time. In a temporal domain, each action has a start time, end time, or duration, and concurrency constraints must be respected.\"), \"\\n\", React.createElement(Latex, {\n    text: \"\\\\[\\naction(A) : duration = 5, \\nstart\\\\_condition = ConditionA, \\nend\\\\_condition = ConditionB\\n\\\\]\"\n  }), \"\\n\", React.createElement(_components.p, null, \"Here, we might say that an action A takes 5 time units to complete, requires ConditionA to be true at its start, and ensures ConditionB at its end.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"scheduling-and-resource-allocation\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#scheduling-and-resource-allocation\",\n    \"aria-label\": \"scheduling and resource allocation permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Scheduling and resource allocation\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Scheduling\"), \" is the process of assigning tasks to time slots (and possibly resources) such that constraints like deadlines or capacities are satisfied. In complex applications, one must integrate scheduling with planning: not only must the sequence of actions be valid, but it must also fit into the resource constraints (e.g., you cannot have two actions simultaneously using the same single robot arm if concurrency is not possible for that resource). Many advanced planners combine planning with scheduling, using \", React.createElement(_components.strong, null, \"constraint satisfaction\"), \" techniques or specialized heuristics.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"temporal-planning-algorithms\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#temporal-planning-algorithms\",\n    \"aria-label\": \"temporal planning algorithms permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Temporal planning algorithms\"), \"\\n\", React.createElement(_components.p, null, \"Several algorithms and systems address \", React.createElement(_components.strong, null, \"temporal planning\"), \", including:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"TPPlan\"), \": An older system that used temporal constraints for scheduling-like planning.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"OPTIC\"), \": A more recent domain-independent temporal planner that builds upon heuristic search techniques and plan-space refinements.\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"In these planners, time is often handled either discretely (where each time step is a small uniform increment) or continuously (where start times can be arbitrary real values). The complexity can be high, so heuristics and domain restrictions are essential.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"resource-constrained-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#resource-constrained-planning\",\n    \"aria-label\": \"resource constrained planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Resource-constrained planning\"), \"\\n\", React.createElement(_components.p, null, \"In addition to time, real-world tasks often face \", React.createElement(_components.strong, null, \"resource constraints\"), \" — for example, limited budget, fuel, or CPU cycles. A plan that uses more resources than available is invalid. Approaches for resource-constrained planning often integrate ideas from \", React.createElement(_components.strong, null, \"job-shop scheduling\"), \" or \", React.createElement(_components.strong, null, \"CSP (Constraint Satisfaction Problem)\"), \" solving. These methods require:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Variables\"), \" representing resource usage over time.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Constraints\"), \" specifying how actions consume or produce resources.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Search or optimization\"), \" procedures to find feasible schedules or to minimize cost.\"), \"\\n\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"automated-planning-systems\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#automated-planning-systems\",\n    \"aria-label\": \"automated planning systems permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Automated planning systems\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"definition-and-scope\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#definition-and-scope\",\n    \"aria-label\": \"definition and scope permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Definition and scope\"), \"\\n\", React.createElement(_components.p, null, React.createElement(_components.strong, null, \"Automated planning\"), \" typically means domain-independent planning, where the system can read a domain description (in, for example, PDDL) and a problem instance (initial state plus goal), and generate a plan without additional domain-specific coding. This contrasts with manual or domain-specific planning approaches, where the developer encodes specialized heuristics or expansions for that domain alone.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"planning-algorithms-and-frameworks\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#planning-algorithms-and-frameworks\",\n    \"aria-label\": \"planning algorithms and frameworks permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Planning algorithms and frameworks\"), \"\\n\", React.createElement(_components.p, null, \"Over the years, a number of \", React.createElement(_components.strong, null, \"AI planning toolkits\"), \" have been developed, many supporting PDDL as a standard input format. Some well-known domain-independent planners include:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"FF\"), \" (Fast Forward): Uses a relaxed planning graph to derive heuristics, known for speed in many benchmarks.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Fast Downward\"), \": A versatile planner that supports a range of heuristics and search strategies, developed at the University of Freiburg.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"SATPlan\"), \": Uses bounded-length transformations into SAT problems, leveraging powerful SAT solvers.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"automated-planning-heuristics-1\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#automated-planning-heuristics-1\",\n    \"aria-label\": \"automated planning heuristics 1 permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Automated planning heuristics\"), \"\\n\", React.createElement(_components.p, null, \"We have touched on heuristics earlier, but in automated planning systems, the choice of heuristic can drastically change performance. Domain-independent heuristics like the \", React.createElement(_components.strong, null, \"FF heuristic\"), \" (which effectively ignores delete lists but tries to compute the length of a relaxed plan) have been central to the success of modern planners. Over the years, new heuristics (landmark-based, pattern-based, or synergy-based) have emerged, each pushing the boundary of what domain-independent planners can solve efficiently.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"practical-considerations\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#practical-considerations\",\n    \"aria-label\": \"practical considerations permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Practical considerations\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Knowledge engineering\"), \": Writing correct, robust domain models is non-trivial. The best planning system in the world is useless if the domain and problem descriptions are incomplete or inaccurate.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Scalability and runtime performance\"), \": Some planning problems are in PSPACE or EXPSPACE complexity classes, so advanced heuristics and domain knowledge are often needed to handle real-world problems.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Benchmarks and competitions\"), \": The \", React.createElement(_components.strong, null, \"International Planning Competition (IPC)\"), \" has historically driven progress in domain-independent planning, providing standardized benchmarks (e.g., Blocks World, Logistics, Rovers, TPP, Satellite domains) and comparing planner performance.\"), \"\\n\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"analysis-of-planning-approaches\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#analysis-of-planning-approaches\",\n    \"aria-label\": \"analysis of planning approaches permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Analysis of planning approaches\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"computational-complexity-in-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#computational-complexity-in-planning\",\n    \"aria-label\": \"computational complexity in planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Computational complexity in planning\"), \"\\n\", React.createElement(_components.p, null, \"It is well-known from classical results that general (classical) planning is \", React.createElement(_components.strong, null, \"PSPACE-complete\"), \". This means that for large problems, we might need to consider exponential or super-polynomial time in the worst case. Many expansions of planning (handling partial observability, time, resources, or uncertainty) push the complexity even higher. Understanding these complexity classes is important in appreciating why heuristic design and domain constraints are so crucial in practice.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"trade-offs-among-approaches\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#trade-offs-among-approaches\",\n    \"aria-label\": \"trade offs among approaches permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Trade-offs among approaches\"), \"\\n\", React.createElement(_components.p, null, \"When deciding on an approach, you balance:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"State-space vs. plan-space\"), \": State-space searches can be simpler to implement but might blow up in large domains. Plan-space (partial-order) planning can handle concurrency gracefully but can be more complex to implement and reason about.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Hierarchical vs. non-hierarchical\"), \": Hierarchical approaches can drastically simplify search if the domain decomposition is well designed, but they require more domain knowledge.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Graph-based (e.g., GraphPlan) vs. SAT-based\"), \": GraphPlan can quickly identify mutual exclusions and provide good heuristics. SAT-based approaches can leverage state-of-the-art solvers but might be more memory intensive for large problems.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"heuristic-accuracy-vs-computation-time\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#heuristic-accuracy-vs-computation-time\",\n    \"aria-label\": \"heuristic accuracy vs computation time permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Heuristic accuracy vs. computation time\"), \"\\n\", React.createElement(_components.p, null, \"A well-designed heuristic can prune huge portions of the search space but might be expensive to compute. Domain-independent planners often rely on more general but less accurate heuristics, while domain-specific planners can exploit specialized heuristics for huge gains in efficiency. For many real-world problems, the knowledge engineering cost of building domain-specific heuristics is offset by the improvements in speed and plan quality.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"empirical-vs-theoretical-analysis\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#empirical-vs-theoretical-analysis\",\n    \"aria-label\": \"empirical vs theoretical analysis permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Empirical vs. theoretical analysis\"), \"\\n\", React.createElement(_components.p, null, \"Because planning problems are so diverse, many breakthroughs come from empirical experimentation with standard benchmarks. The International Planning Competition fosters such experimentation. Developers test their planners on logistics problems, blocks-world puzzles, rover navigation tasks (inspired by NASA missions), and other complex tasks. Theoretical analysis often focuses on the worst-case or average-case complexity, but empirical results can show which algorithms and heuristics work best in practice.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"empirical-comparisons\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#empirical-comparisons\",\n    \"aria-label\": \"empirical comparisons permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Empirical comparisons\"), \"\\n\", React.createElement(_components.p, null, \"Common metrics used to evaluate planners:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Plan quality\"), \": The cost or length of the resulting plan.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Time-to-solution\"), \": How quickly a valid plan is found.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Memory usage\"), \": Some approaches can explode in memory consumption if the state space or intermediate structures are large.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Scalability\"), \": How performance degrades as problem size increases.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"hybrid-approaches\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#hybrid-approaches\",\n    \"aria-label\": \"hybrid approaches permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Hybrid approaches\"), \"\\n\", React.createElement(_components.p, null, \"One promising direction involves \", React.createElement(_components.strong, null, \"combining planning with machine learning\"), \". For instance, an ML component might learn a transition model from data, or learn heuristics from solved examples. Another direction is \", React.createElement(_components.strong, null, \"neurosymbolic planning\"), \", where a neural network might approximate a submodule (like the next feasible action or state representation), while a symbolic planner ensures logical consistency. These approaches, though still in active research, aim to merge the best of both worlds: the interpretability and rigor of symbolic planning with the flexibility and adaptability of learning-based systems.\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"future-directions-and-open-problems\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#future-directions-and-open-problems\",\n    \"aria-label\": \"future directions and open problems permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Future directions and open problems\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"integrating-learning-and-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#integrating-learning-and-planning\",\n    \"aria-label\": \"integrating learning and planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Integrating learning and planning\"), \"\\n\", React.createElement(_components.p, null, \"The synergy between \", React.createElement(_components.strong, null, \"reinforcement learning\"), \" and planning is particularly interesting. While RL typically learns a policy from trial and error, classical planning builds a plan from a symbolic model of the domain. One approach is to use planning to generate or refine policies, or conversely, to learn domain models or heuristics from RL experience. This has led to frameworks like \", React.createElement(_components.strong, null, \"model-based RL\"), \" that fuse classical planning (with the learned model) and policy optimization.\"), \"\\n\", React.createElement(_components.p, null, \"Another frontier is learning domain models automatically from partial observations. Traditional planning requires a fully specified action model, but in real-world settings, writing or verifying these models might be too time-consuming or error-prone. Recent research (e.g., in NeurIPS or ICML workshops) has explored learning approximate STRIPS operators from data logs, then using those operators for planning.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"probabilistic-and-hybrid-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#probabilistic-and-hybrid-planning\",\n    \"aria-label\": \"probabilistic and hybrid planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Probabilistic and hybrid planning\"), \"\\n\", React.createElement(_components.p, null, \"Many real problems have probabilistic effects. \", React.createElement(_components.strong, null, \"Probabilistic planning\"), \" extends classical planning with probability distributions over action outcomes. Tools like the \", React.createElement(_components.strong, null, \"PPDDL\"), \" language attempt to unify classical planning with Markov decision processes. Meanwhile, \", React.createElement(_components.strong, null, \"hybrid\"), \" approaches incorporate numeric or continuous variables with discrete ones, bridging the gap with classical control theory. Such integrated frameworks are still being refined and require advanced reasoning over large or continuous state spaces.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"multi-agent-planning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#multi-agent-planning\",\n    \"aria-label\": \"multi agent planning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Multi-agent planning\"), \"\\n\", React.createElement(_components.p, null, \"In multi-agent systems, we have multiple actors each with their own goals, abilities, and sometimes conflicting constraints. Multi-agent planning includes aspects of \", React.createElement(_components.strong, null, \"coordination\"), \" (ensuring that multiple agents' actions do not conflict) and \", React.createElement(_components.strong, null, \"negotiation\"), \" (resolving conflicting goals). Game-theoretic principles can come into play, especially if agents are self-interested. This domain remains a lively research area, offering a broad set of computational and conceptual challenges.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"ethical-and-social-considerations\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#ethical-and-social-considerations\",\n    \"aria-label\": \"ethical and social considerations permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Ethical and social considerations\"), \"\\n\", React.createElement(_components.p, null, \"As planning technology becomes integrated into real systems (e.g., drones, self-driving cars, automated factories), we must consider:\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Safety\"), \": An AI planner that inadvertently orchestrates harmful actions (or fails to consider certain unintended side effects) poses risks.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Fairness and accountability\"), \": Automated planning in social contexts (e.g., resource distribution) might raise fairness concerns. Who is accountable if the plan leads to harm or is biased against certain groups?\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Transparency and interpretability\"), \": Stakeholders may demand interpretable, justifiable plans. Hierarchical planning can help with interpretability, but if we also incorporate deep learning elements, it can become opaque.\"), \"\\n\"), \"\\n\", React.createElement(_components.h2, {\n    id: \"conclusion\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#conclusion\",\n    \"aria-label\": \"conclusion permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Conclusion\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"key-takeaways\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#key-takeaways\",\n    \"aria-label\": \"key takeaways permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Key takeaways\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"Planning is a \", React.createElement(_components.strong, null, \"foundational\"), \" concept in AI, linking abstract reasoning with concrete action. It is often formalized in a symbolic manner, ensuring that each step is grounded in well-defined preconditions and effects.\"), \"\\n\", React.createElement(_components.li, null, \"We have classical planning, relying on assumptions of determinism and full observability. Then we have expansions to hierarchical, nondeterministic, probabilistic, and temporal contexts.\"), \"\\n\", React.createElement(_components.li, null, \"Effective planning \", React.createElement(_components.strong, null, \"algorithms\"), \" rely on heuristics, partial-order structures, or transformations into other domains (like SAT) to cope with combinatorial complexity.\"), \"\\n\", React.createElement(_components.li, null, \"The field is \", React.createElement(_components.strong, null, \"constantly evolving\"), \", with research exploring hybrid symbolic–subsymbolic planners, multi-agent frameworks, and deeper integration with machine learning.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"links-to-the-next-article-ai-reasoning\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#links-to-the-next-article-ai-reasoning\",\n    \"aria-label\": \"links to the next article ai reasoning permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Links to the next article (\\\"AI reasoning\\\")\"), \"\\n\", React.createElement(_components.p, null, \"Planning is deeply interwoven with other forms of reasoning. The next article on \\\"AI Reasoning\\\" will likely dive into more generic inference mechanisms, including logical and probabilistic reasoning, knowledge representation, and how these are used to derive or verify the constraints under which planning operates. While planning focuses on the \", React.createElement(_components.strong, null, \"sequence of actions\"), \" to achieve goals, broader AI reasoning can involve diagnosing problems, explaining phenomena, or inferring hidden states — tasks that can inform the modeling and feasibility checking at the heart of the planner.\"), \"\\n\", React.createElement(_components.h3, {\n    id: \"further-reading-and-resources\",\n    style: {\n      position: \"relative\"\n    }\n  }, React.createElement(_components.a, {\n    href: \"#further-reading-and-resources\",\n    \"aria-label\": \"further reading and resources permalink\",\n    className: \"anchor before\"\n  }, React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" height=\\\"16\\\" version=\\\"1.1\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\"><path fill-rule=\\\"evenodd\\\" d=\\\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\\\"></path></svg>\"\n    }\n  })), \"Further reading and resources\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Ghallab, M., Nau, D., & Traverso, P.\"), \" (2004). \\\"Automated Planning: Theory and Practice.\\\" This textbook provides a broad introduction to classical, hierarchical, and real-world planning issues.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Blum, A., & Furst, M.\"), \" (1995). \\\"Fast Planning Through Planning Graph Analysis.\\\" This seminal paper introduced GraphPlan, setting the stage for planning-graph-based heuristics.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Fikes, R. E., & Nilsson, N. J.\"), \" (1971). \\\"STRIPS: A new approach to the application of theorem proving to problem solving.\\\" The foundational paper for classical planning representation.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"International Planning Competition (IPC)\"), \": A recurring event that drives state-of-the-art in domain-independent planning. Their website provides benchmarks, results, and links to numerous planners.\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.strong, null, \"Automated Planning and Scheduling (ICAPS)\"), \": A premier conference focusing on planning, scheduling, and combinatorial optimization in AI. Papers there often reveal the leading research directions.\"), \"\\n\"), \"\\n\", React.createElement(Image, {\n    alt: \"Schematic overview of a planner\",\n    path: \"\",\n    caption: \"A high-level schematic of a classical planner that takes a domain description, a problem instance, and produces a plan.\",\n    zoom: \"false\"\n  }), \"\\n\", React.createElement(_components.hr), \"\\n\", React.createElement(_components.p, null, \"Below is a small illustrative snippet in Python that demonstrates, in a highly simplified manner, how one might implement a forward (progression) search for a plan in a toy domain with STRIPS-like operators. This code is only for demonstration and does not handle large or complex scenarios:\"), \"\\n\", React.createElement(Code, {\n    text: `\nclass Action:\n    def __init__(self, name, preconds, add_effects, del_effects):\n        self.name = name\n        self.preconds = set(preconds)\n        self.add_effects = set(add_effects)\n        self.del_effects = set(del_effects)\n\n    def is_applicable(self, state):\n        # Check if all preconditions are in current state\n        return self.preconds.issubset(state)\n\n    def apply(self, state):\n        # Return the new state after applying the action\n        new_state = set(state)\n        new_state.difference_update(self.del_effects)\n        new_state.update(self.add_effects)\n        return new_state\n\ndef forward_search(initial_state, goal, actions):\n    # We'll do a naive BFS for demonstration\n    from collections import deque\n    queue = deque()\n    # Each element is (current_state, plan)\n    queue.append((frozenset(initial_state), []))\n    visited = set([frozenset(initial_state)])\n\n    while queue:\n        current_state, plan = queue.popleft()\n        # Check goal\n        if goal.issubset(current_state):\n            return plan  # Found a plan that satisfies goal\n\n        # Try all applicable actions\n        for act in actions:\n            if act.is_applicable(current_state):\n                next_state = act.apply(current_state)\n                if next_state not in visited:\n                    visited.add(next_state)\n                    new_plan = plan + [act.name]\n                    queue.append((frozenset(next_state), new_plan))\n\n    # If we exhaust the search space, return None\n    return None\n\n# Example usage:\nif __name__ == \"__main__\":\n    init = {\"at_home\", \"car_needs_fuel\"}\n    goal = {\"at_work\"}\n    actions = [\n        Action(\"drive_to_station\", {\"at_home\", \"car_needs_fuel\"}, {\"at_station\"}, {\"at_home\"}),\n        Action(\"fill_tank\", {\"at_station\"}, {\"car_full_tank\"}, {\"car_needs_fuel\"}),\n        Action(\"drive_to_work\", {\"at_station\", \"car_full_tank\"}, {\"at_work\"}, {\"at_station\"})\n    ]\n    plan_found = forward_search(init, goal, actions)\n    print(\"Plan found:\", plan_found)\n`\n  }), \"\\n\", React.createElement(_components.p, null, \"While this code snippet barely scratches the surface of AI planning, it shows in extremely simplified form how you might represent states as sets of facts, actions as transitions with preconditions and effects, and perform a straightforward BFS search. Real-world planning systems are far more intricate, potentially involving specialized heuristics, partial-order plan representations, temporal constraints, resource management, and more.\"), \"\\n\", React.createElement(_components.p, null, \"And with that, I hope this gives you a comprehensive theoretical and practical overview of AI planning — a field that continues to be vibrant and deeply relevant to both academic research and industrial applications.\"));\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? React.createElement(MDXLayout, props, React.createElement(_createMdxContent, props)) : _createMdxContent(props);\n}\nexport default MDXContent;\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","import GATSBY_COMPILED_MDX from \"/home/avrtt/Repos/avrtt.github.io/src/pages/posts/research/ai_planning.mdx\";\nimport _toConsumableArray from \"@babel/runtime/helpers/esm/toConsumableArray\";\nimport React, {useState, useEffect} from 'react';\nimport {useSiteMetadata} from \"../hooks/useSiteMetadata\";\nimport RemoveMarkdown from 'remove-markdown';\nimport {ImageContext} from '../context/ImageContext';\nimport {MDXProvider} from '@mdx-js/react';\nimport Image from '../components/PostImage';\nimport {motion} from 'framer-motion';\nimport SEO from \"../components/seo\";\nimport PostBanner from '../components/PostBanner';\nimport PostBottom from '../components/PostBottom';\nimport {wordsPerMinuteAdventures, wordsPerMinuteResearch, wordsPerMinuteThoughts} from '../data/commonVariables';\nimport PartOfCourseNotice from \"../components/PartOfCourseNotice\";\nimport * as stylesButtonsCommon from \"../styles/buttons_common.module.scss\";\nimport * as stylesCustomPostLayouts from \"../styles/custom_post_layouts.module.scss\";\nimport * as stylesTableOfContents from \"../styles/table_of_contents.module.scss\";\nimport * as stylesTagBadges from \"../styles/tag_badges.module.scss\";\nfunction formatReadTime(minutes) {\n  if (minutes <= 10) return '~10 min';\n  if (minutes <= 20) return '~20 min';\n  if (minutes <= 30) return '~30 min';\n  if (minutes <= 40) return '~40 min';\n  if (minutes <= 50) return '~50 min';\n  if (minutes <= 60) return '~1 h';\n  const hours = Math.floor(minutes / 60);\n  const remainder = minutes % 60;\n  if (remainder <= 30) {\n    return `~${hours}${remainder > 0 ? '.5' : ''} h`;\n  }\n  return `~${hours + 1} h`;\n}\nconst TableOfContents = _ref => {\n  let {toc} = _ref;\n  if (!toc || !toc.items) return null;\n  const handleClick = (e, url) => {\n    e.preventDefault();\n    const targetId = url.replace('#', '');\n    const targetElement = document.getElementById(targetId);\n    if (targetElement) {\n      targetElement.scrollIntoView({\n        behavior: 'smooth',\n        block: 'start'\n      });\n    }\n  };\n  return React.createElement(\"nav\", {\n    className: stylesTableOfContents.toc\n  }, React.createElement(\"ul\", null, toc.items.map((item, index) => React.createElement(\"li\", {\n    key: index\n  }, React.createElement(\"a\", {\n    href: item.url,\n    onClick: e => handleClick(e, item.url)\n  }, item.title), item.items && React.createElement(TableOfContents, {\n    toc: {\n      items: item.items\n    }\n  })))));\n};\nexport function PostTemplate(_ref2) {\n  let {data: {mdx, allMdx, allPostImages}, children} = _ref2;\n  const {frontmatter, body, tableOfContents} = mdx;\n  const index = frontmatter.index;\n  const slug = frontmatter.slug;\n  const section = slug.split('/')[1];\n  const posts = allMdx.nodes.filter(post => post.frontmatter.slug.includes(`/${section}/`));\n  const sortedPosts = posts.sort((a, b) => a.frontmatter.index - b.frontmatter.index);\n  const currentIndex = sortedPosts.findIndex(post => post.frontmatter.index === index);\n  const nextPost = sortedPosts[currentIndex + 1];\n  const lastPost = sortedPosts[currentIndex - 1];\n  const trimmedSlug = frontmatter.slug.replace(/\\/$/, '');\n  const keyCurrent = (/[^/]*$/).exec(trimmedSlug)[0];\n  const basePath = `posts/${section}/content/${keyCurrent}/`;\n  const {0: isWideLayout, 1: setIsWideLayout} = useState(frontmatter.flagWideLayoutByDefault);\n  const {0: isAnimating, 1: setIsAnimating} = useState(false);\n  const toggleLayout = () => {\n    setIsWideLayout(!isWideLayout);\n  };\n  useEffect(() => {\n    setIsAnimating(true);\n    const timer = setTimeout(() => setIsAnimating(false), 340);\n    return () => clearTimeout(timer);\n  }, [isWideLayout]);\n  var wordsPerMinute;\n  if (section === \"adventures\") {\n    wordsPerMinute = wordsPerMinuteAdventures;\n  } else if (section === \"research\") {\n    wordsPerMinute = wordsPerMinuteResearch;\n  } else if (section === \"thoughts\") {\n    wordsPerMinute = wordsPerMinuteThoughts;\n  }\n  const plainTextBody = RemoveMarkdown(body).replace(/import .*? from .*?;/g, '').replace(/<.*?>/g, '').replace(/\\{\\/\\*[\\s\\S]*?\\*\\/\\}/g, '').trim();\n  const wordCount = plainTextBody.split(/\\s+/).length;\n  const baseReadTimeMinutes = Math.ceil(wordCount / wordsPerMinute);\n  const extraTime = frontmatter.extraReadTimeMin || 0;\n  const totalReadTime = baseReadTimeMinutes + extraTime;\n  const readTime = formatReadTime(totalReadTime);\n  const notices = [{\n    flag: frontmatter.flagDraft,\n    component: () => import(\"../components/NotFinishedNotice\")\n  }, {\n    flag: frontmatter.flagMindfuckery,\n    component: () => import(\"../components/MindfuckeryNotice\")\n  }, {\n    flag: frontmatter.flagRewrite,\n    component: () => import(\"../components/RewriteNotice\")\n  }, {\n    flag: frontmatter.flagOffensive,\n    component: () => import(\"../components/OffensiveNotice\")\n  }, {\n    flag: frontmatter.flagProfane,\n    component: () => import(\"../components/ProfanityNotice\")\n  }, {\n    flag: frontmatter.flagMultilingual,\n    component: () => import(\"../components/MultilingualNotice\")\n  }, {\n    flag: frontmatter.flagUnreliably,\n    component: () => import(\"../components/UnreliablyNotice\")\n  }, {\n    flag: frontmatter.flagPolitical,\n    component: () => import(\"../components/PoliticsNotice\")\n  }, {\n    flag: frontmatter.flagCognitohazard,\n    component: () => import(\"../components/CognitohazardNotice\")\n  }, {\n    flag: frontmatter.flagHidden,\n    component: () => import(\"../components/HiddenNotice\")\n  }];\n  const {0: loadedNotices, 1: setLoadedNotices} = useState([]);\n  useEffect(() => {\n    notices.forEach(_ref3 => {\n      let {flag, component} = _ref3;\n      if (flag) {\n        component().then(module => {\n          setLoadedNotices(prev => [].concat(_toConsumableArray(prev), [module.default]));\n        });\n      }\n    });\n  }, []);\n  return React.createElement(motion.div, {\n    initial: {\n      opacity: 0\n    },\n    animate: {\n      opacity: 1\n    },\n    exit: {\n      opacity: 0\n    },\n    transition: {\n      duration: 0.15\n    }\n  }, React.createElement(PostBanner, {\n    postNumber: frontmatter.index,\n    date: frontmatter.date,\n    updated: frontmatter.updated,\n    readTime: readTime,\n    difficulty: frontmatter.difficultyLevel,\n    title: frontmatter.title,\n    desc: frontmatter.desc,\n    banner: frontmatter.banner,\n    section: section,\n    postKey: keyCurrent,\n    isMindfuckery: frontmatter.flagMindfuckery,\n    mainTag: frontmatter.mainTag\n  }), React.createElement(\"div\", {\n    style: {\n      display: \"flex\",\n      justifyContent: \"flex-end\",\n      flexWrap: \"wrap\",\n      maxWidth: \"75%\",\n      marginLeft: \"auto\",\n      paddingRight: \"1vw\",\n      marginTop: \"-6vh\",\n      marginBottom: \"4vh\"\n    }\n  }, frontmatter.otherTags.map((tag, index) => React.createElement(\"span\", {\n    key: index,\n    className: `noselect ${stylesTagBadges.tagPosts}`,\n    style: {\n      margin: \"0 5px 5px 0\"\n    }\n  }, tag))), React.createElement(\"div\", {\n    className: \"postBody\"\n  }, React.createElement(TableOfContents, {\n    toc: tableOfContents\n  })), React.createElement(\"br\", null), React.createElement(\"div\", {\n    style: {\n      margin: \"0 10% -2vh 30%\",\n      textAlign: \"right\"\n    }\n  }, React.createElement(motion.button, {\n    className: `noselect ${stylesCustomPostLayouts.postButton}`,\n    id: stylesCustomPostLayouts.postLayoutSwitchButton,\n    onClick: toggleLayout,\n    whileTap: {\n      scale: 0.93\n    }\n  }, React.createElement(motion.div, {\n    className: stylesButtonsCommon.buttonTextWrapper,\n    key: isWideLayout,\n    initial: {\n      opacity: 0\n    },\n    animate: {\n      opacity: 1\n    },\n    exit: {\n      opacity: 0\n    },\n    transition: {\n      duration: 0.3,\n      ease: \"easeInOut\"\n    }\n  }, isWideLayout ? \"Switch to default layout\" : \"Switch to wide layout\"))), React.createElement(\"br\", null), React.createElement(\"div\", {\n    className: \"postBody\",\n    style: {\n      margin: isWideLayout ? \"0 -14%\" : \"\",\n      maxWidth: isWideLayout ? \"200%\" : \"\",\n      transition: \"margin 1s ease, max-width 1s ease, padding 1s ease\"\n    }\n  }, React.createElement(\"div\", {\n    className: `${stylesCustomPostLayouts.textContent} ${isAnimating ? stylesCustomPostLayouts.fadeOut : stylesCustomPostLayouts.fadeIn}`\n  }, loadedNotices.map((NoticeComponent, index) => React.createElement(NoticeComponent, {\n    key: index\n  })), frontmatter.indexCourse ? React.createElement(PartOfCourseNotice, {\n    index: frontmatter.indexCourse,\n    category: frontmatter.courseCategoryName\n  }) : \"\", React.createElement(ImageContext.Provider, {\n    value: {\n      images: allPostImages.nodes,\n      basePath: basePath.replace(/\\/$/, '') + '/'\n    }\n  }, React.createElement(MDXProvider, {\n    components: {\n      Image\n    }\n  }, children)))), React.createElement(PostBottom, {\n    nextPost: nextPost,\n    lastPost: lastPost,\n    keyCurrent: keyCurrent,\n    section: section\n  }));\n}\nPostTemplate\nexport default function GatsbyMDXWrapper(props) {\n  return React.createElement(PostTemplate, props, React.createElement(GATSBY_COMPILED_MDX, props));\n}\nexport function Head(_ref4) {\n  var _frontmatter$banner, _frontmatter$banner$c, _frontmatter$banner$c2, _frontmatter$banner$c3, _frontmatter$banner$c4;\n  let {data} = _ref4;\n  const {frontmatter} = data.mdx;\n  const title = frontmatter.titleSEO || frontmatter.title;\n  const titleOG = frontmatter.titleOG || title;\n  const titleTwitter = frontmatter.titleTwitter || title;\n  const description = frontmatter.descSEO || frontmatter.desc;\n  const descriptionOG = frontmatter.descOG || description;\n  const descriptionTwitter = frontmatter.descTwitter || description;\n  const schemaType = frontmatter.schemaType || \"BlogPosting\";\n  const keywords = frontmatter.keywordsSEO;\n  const datePublished = frontmatter.date;\n  const dateModified = frontmatter.updated || datePublished;\n  const imageOG = frontmatter.imageOG || ((_frontmatter$banner = frontmatter.banner) === null || _frontmatter$banner === void 0 ? void 0 : (_frontmatter$banner$c = _frontmatter$banner.childImageSharp) === null || _frontmatter$banner$c === void 0 ? void 0 : (_frontmatter$banner$c2 = _frontmatter$banner$c.gatsbyImageData) === null || _frontmatter$banner$c2 === void 0 ? void 0 : (_frontmatter$banner$c3 = _frontmatter$banner$c2.images) === null || _frontmatter$banner$c3 === void 0 ? void 0 : (_frontmatter$banner$c4 = _frontmatter$banner$c3.fallback) === null || _frontmatter$banner$c4 === void 0 ? void 0 : _frontmatter$banner$c4.src);\n  const imageAltOG = frontmatter.imageAltOG || descriptionOG;\n  const imageTwitter = frontmatter.imageTwitter || imageOG;\n  const imageAltTwitter = frontmatter.imageAltTwitter || descriptionTwitter;\n  const canonicalUrl = frontmatter.canonicalURL;\n  const flagHidden = frontmatter.flagHidden || false;\n  const mainTag = frontmatter.mainTag || \"Posts\";\n  const section = frontmatter.slug.split('/')[1] || \"posts\";\n  const type = \"article\";\n  const {siteUrl} = useSiteMetadata();\n  const breadcrumbJSON = {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"BreadcrumbList\",\n    \"itemListElement\": [{\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Home\",\n      \"item\": siteUrl\n    }, {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": mainTag,\n      \"item\": `${siteUrl}/${frontmatter.slug.split('/')[1]}`\n    }, {\n      \"@type\": \"ListItem\",\n      \"position\": 3,\n      \"name\": title,\n      \"item\": `${siteUrl}${frontmatter.slug}`\n    }]\n  };\n  return React.createElement(SEO, {\n    title: title + \" - avrtt.blog\",\n    titleOG: titleOG,\n    titleTwitter: titleTwitter,\n    description: description,\n    descriptionOG: descriptionOG,\n    descriptionTwitter: descriptionTwitter,\n    schemaType: schemaType,\n    keywords: keywords,\n    datePublished: datePublished,\n    dateModified: dateModified,\n    imageOG: imageOG,\n    imageAltOG: imageAltOG,\n    imageTwitter: imageTwitter,\n    imageAltTwitter: imageAltTwitter,\n    canonicalUrl: canonicalUrl,\n    flagHidden: flagHidden,\n    mainTag: mainTag,\n    section: section,\n    type: type\n  }, React.createElement(\"script\", {\n    type: \"application/ld+json\"\n  }, JSON.stringify(breadcrumbJSON)));\n}\nconst query = \"2571018839\";\n","/* \n\nCopyright © 2022  Vladislav Averett (avrtt)\nDistributed under the GNU AGPLv3 license. For details and source code, please refer to <https://github.com/avrtt/avrtt.github.io>.\n\n*/\n\nimport React from \"react\";\nimport Latex from 'react-latex-next';\nimport 'katex/dist/katex.min.css'; \n\ninterface LatexProps {\n  text: string;\n}\n  \nconst L = ({ text }: LatexProps) => {\n  return (\n    <Latex>{text}</Latex>\n  );\n};\nexport default L;\n"],"names":["_createMdxContent","props","_components","Object","assign","p","h3","a","span","ul","li","strong","h2","ol","hr","_provideComponents","components","Image","id","component","Error","_missingMdxReference","React","style","position","href","className","dangerouslySetInnerHTML","__html","Highlight","Latex","text","alt","path","caption","zoom","Code","wrapper","MDXLayout","TableOfContents","_ref","toc","items","stylesTableOfContents","map","item","index","key","url","onClick","e","handleClick","preventDefault","targetId","replace","targetElement","document","getElementById","scrollIntoView","behavior","block","title","PostTemplate","_ref2","data","mdx","allMdx","allPostImages","children","frontmatter","body","tableOfContents","section","slug","split","sortedPosts","nodes","filter","post","includes","sort","b","currentIndex","findIndex","nextPost","lastPost","trimmedSlug","keyCurrent","exec","basePath","isWideLayout","setIsWideLayout","useState","flagWideLayoutByDefault","isAnimating","setIsAnimating","wordsPerMinute","useEffect","timer","setTimeout","clearTimeout","wordsPerMinuteAdventures","wordsPerMinuteResearch","wordsPerMinuteThoughts","wordCount","RemoveMarkdown","trim","length","readTime","minutes","hours","Math","floor","remainder","formatReadTime","ceil","extraReadTimeMin","notices","flag","flagDraft","flagMindfuckery","flagRewrite","flagOffensive","flagProfane","flagMultilingual","flagUnreliably","flagPolitical","flagCognitohazard","flagHidden","loadedNotices","setLoadedNotices","forEach","_ref3","then","module","prev","concat","_toConsumableArray","default","motion","div","initial","opacity","animate","exit","transition","duration","PostBanner","postNumber","date","updated","difficulty","difficultyLevel","desc","banner","postKey","isMindfuckery","mainTag","display","justifyContent","flexWrap","maxWidth","marginLeft","paddingRight","marginTop","marginBottom","otherTags","tag","stylesTagBadges","margin","textAlign","button","stylesCustomPostLayouts","toggleLayout","whileTap","scale","stylesButtonsCommon","ease","NoticeComponent","indexCourse","PartOfCourseNotice","category","courseCategoryName","ImageContext","Provider","value","images","MDXProvider","PostBottom","GatsbyMDXWrapper","GATSBY_COMPILED_MDX","Head","_ref4","_frontmatter$banner","_frontmatter$banner$c","_frontmatter$banner$c2","_frontmatter$banner$c3","_frontmatter$banner$c4","titleSEO","titleOG","titleTwitter","description","descSEO","descriptionOG","descOG","descriptionTwitter","descTwitter","schemaType","keywords","keywordsSEO","datePublished","dateModified","imageOG","childImageSharp","gatsbyImageData","fallback","src","imageAltOG","imageTwitter","imageAltTwitter","canonicalUrl","canonicalURL","siteUrl","useSiteMetadata","breadcrumbJSON","SEO","type","JSON","stringify"],"sourceRoot":""}